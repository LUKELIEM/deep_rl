{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REINFORCE-K\n",
    "\n",
    "We will implement a simple but powerful REINFORCE agent in PyTorch that directly backprop based on the methodology used by Andrej Karpathy. We will bypass PyTorch's recommended method of using torch.distribution's score function to implement reinforcement learning.\n",
    "\n",
    "Wish me Luck!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.6.3\n"
     ]
    }
   ],
   "source": [
    "# As usual, a bit of setup\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import platform\n",
    "import gym\n",
    "import pickle as pickle\n",
    "import pympler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Categorical\n",
    "import gc\n",
    "\n",
    "# For memory tracking\n",
    "from pympler import summary\n",
    "from pympler import muppy\n",
    "\n",
    "cpu_dtype = torch.FloatTensor\n",
    "gpu_dtype = torch.cuda.FloatTensor\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"Python version: \", platform.python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REINFORCE-Karpathy for \"Pong\"\n",
    "\n",
    "The following code uses the basic policy gradient method (REINFORCE) to train a 2 layer NN to play Pong.\n",
    "\n",
    "The time needed to train 10 episodes is 13 sec with Intel I7 (4-cores). The forward pass takes 4 seconds. So implementing this in PyTorch and using GPU will speed things up by 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Trains an agent with (stochastic) Policy Gradients on Pong. Uses OpenAI Gym. \"\"\"\n",
    "import numpy as np\n",
    "import pickle as pickle\n",
    "import gym\n",
    "\n",
    "# hyperparameters\n",
    "H = 200 # number of hidden layer neurons\n",
    "batch_size = 10 # every how many episodes to do a param update?\n",
    "\n",
    "learning_rate  = 1e-3\n",
    "epoch_reward_history=[]\n",
    "    \n",
    "gamma = 0.99 # discount factor for reward\n",
    "decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n",
    "resume = False # resume from previous checkpoint?\n",
    "render = False\n",
    "\n",
    "# model initialization\n",
    "D = 80 * 80 # input dimensionality: 80x80 grid\n",
    "if resume:\n",
    "  model = pickle.load(open('save.p', 'rb'))\n",
    "else:\n",
    "  model = {}\n",
    "  model['W1'] = np.random.randn(H,D) / np.sqrt(D) # \"Xavier\" initialization\n",
    "  model['W2'] = np.random.randn(H) / np.sqrt(H)\n",
    "\n",
    "grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } # update buffers that add up gradients over a batch\n",
    "rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } # rmsprop memory\n",
    "\n",
    "def sigmoid(x): \n",
    "  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n",
    "\n",
    "def prepro(I):\n",
    "  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n",
    "  I = I[35:195] # crop\n",
    "  I = I[::2,::2,0] # downsample by factor of 2\n",
    "  I[I == 144] = 0 # erase background (background type 1)\n",
    "  I[I == 109] = 0 # erase background (background type 2)\n",
    "  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
    "  return I.astype(np.float).ravel()\n",
    "\n",
    "def discount_rewards(r):\n",
    "  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
    "  discounted_r = np.zeros_like(r)\n",
    "  running_add = 0\n",
    "  for t in reversed(range(0, r.size)):\n",
    "    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n",
    "    running_add = running_add * gamma + r[t]\n",
    "    discounted_r[t] = running_add\n",
    "  return discounted_r\n",
    "\n",
    "def policy_forward(x):\n",
    "  h = np.dot(model['W1'], x)\n",
    "  h[h<0] = 0 # ReLU nonlinearity\n",
    "  logp = np.dot(model['W2'], h)\n",
    "  p = sigmoid(logp)\n",
    "  return p, h # return probability of taking action 2, and hidden state\n",
    "\n",
    "def policy_backward(eph, epdlogp):\n",
    "  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n",
    "  dW2 = np.dot(eph.T, epdlogp).ravel()\n",
    "  dh = np.outer(epdlogp, model['W2'])\n",
    "  dh[eph <= 0] = 0 # backpro prelu\n",
    "  dW1 = np.dot(dh.T, epx)\n",
    "  return {'W1':dW1, 'W2':dW2}\n",
    "\n",
    "env = gym.make(\"Pong-v0\")\n",
    "observation = env.reset()\n",
    "prev_x = None # used in computing the difference frame\n",
    "xs,hs,dlogps,drs = [],[],[],[]\n",
    "running_reward = None\n",
    "verbose = False\n",
    "print_every = 20\n",
    "reward_sum = 0\n",
    "episode_number = 0\n",
    "forward_time=0\n",
    "backward_time=0\n",
    "other_time = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "while episode_number < 30000:\n",
    "  if render: env.render()\n",
    "\n",
    "  # preprocess the observation, set input to network to be difference image\n",
    "  cur_x = prepro(observation)\n",
    "  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
    "  prev_x = cur_x\n",
    "\n",
    "  # forward the policy network and sample an action from the returned probability\n",
    "  t1 = time.time()\n",
    "  aprob, h = policy_forward(x)\n",
    "  action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n",
    "  t2 = time.time()\n",
    "  forward_time += t2-t1\n",
    "\n",
    "  # record various intermediates (needed later for backprop)\n",
    "  xs.append(x) # observation\n",
    "  hs.append(h) # hidden state\n",
    "  y = 1 if action == 2 else 0 # a \"fake label\"\n",
    "  dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n",
    "\n",
    "  # step the environment and get new measurements\n",
    "  t5 = time.time()  \n",
    "  # step the environment and get new measurements\n",
    "  observation, reward, done, info = env.step(action)\n",
    "  reward_sum += reward\n",
    "\n",
    "  t6 = time.time()\n",
    "  other_time += t6-t5\n",
    "\n",
    "  drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n",
    "\n",
    "  if done: # an episode finished\n",
    "    episode_number += 1\n",
    "\n",
    "    # stack together all inputs, hidden states, action gradients, and rewards for this episode\n",
    "    epx = np.vstack(xs)\n",
    "    eph = np.vstack(hs)\n",
    "    epdlogp = np.vstack(dlogps)\n",
    "    epr = np.vstack(drs)\n",
    "    xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n",
    "\n",
    "    # compute the discounted reward backwards through time\n",
    "    discounted_epr = discount_rewards(epr)\n",
    "    # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n",
    "    discounted_epr -= np.mean(discounted_epr)\n",
    "    discounted_epr /= np.std(discounted_epr)\n",
    "\n",
    "    epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n",
    "    \n",
    "    t3 = time.time()    \n",
    "    grad = policy_backward(eph, epdlogp)\n",
    "    t4 = time.time()\n",
    "    backward_time += t4-t3    \n",
    "    \n",
    "    for k in model: \n",
    "        grad_buffer[k] += grad[k] # accumulate grad over batch\n",
    "\n",
    "    # perform rmsprop parameter update every batch_size episodes\n",
    "    if episode_number % batch_size == 0:\n",
    "      for k,v in model.items():\n",
    "        g = grad_buffer[k] # gradient\n",
    "        rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n",
    "        model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n",
    "        grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n",
    "\n",
    "    # boring book-keeping\n",
    "    running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "    if episode_number % print_every == 0:     \n",
    "        print ('Episode %d - reward total was %f. running mean: %f' % (episode_number, reward_sum, running_reward))\n",
    "\n",
    "    epoch_reward_history.append([reward_sum, running_reward])\n",
    "    if episode_number % 100 == 0: pickle.dump(model, open('save.p', 'wb'))\n",
    "    reward_sum = 0\n",
    "    observation = env.reset() # reset env\n",
    "    prev_x = None\n",
    "\n",
    "  if reward != 0 and verbose: # Pong has either +1 or -1 reward exactly when game ends.\n",
    "    print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))\n",
    "    \n",
    "end = time.time()\n",
    "print (\"Time to complete\", end-start)\n",
    "print (\"Time to forward pass\", forward_time)\n",
    "print (\"Time to backward pass\", backward_time)\n",
    "print (\"Time to other stuffs\", other_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REINFORCE-K\n",
    "\n",
    "After the great professor and mentor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        weight_shape = list(m.weight.data.size())\n",
    "        fan_in = weight_shape[1]\n",
    "        m.weight.data.normal_(0, math.sqrt(2. / fan_in))  # Xavier for ReLU\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "# The function approximator of the Policy is a 2 layer NN. \n",
    "# - The policy takes in the state of Pong (a resampled 40x40 diff image of 2 successive frames )\n",
    "# - The action is the softmax output (Left or Right)\n",
    "# - there are 200 hidden units in the NN\n",
    "class Policy(nn.Module):\n",
    "            \n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        self.affine1 = nn.Linear(6400, 200)\n",
    "        self.affine2 = nn.Linear(200, 2)  \n",
    "        self.apply(weights_init)\n",
    "        \n",
    "        self.saved_log_probs = []\n",
    "        self.rewards = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.affine1(x))\n",
    "        action_scores = self.affine2(x)\n",
    "        return action_scores   # output logit\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro80(I):\n",
    "    \"\"\" \n",
    "    prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \n",
    "    \"\"\"\n",
    "    I = I[35:195] # crop\n",
    "    I = I[::2,::2,0] # downsample by factor of 2\n",
    "    I[I == 144] = 0 # erase background (background type 1)\n",
    "    I[I == 109] = 0 # erase background (background type 2)\n",
    "    I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
    "    return I.astype(np.float).ravel()\n",
    "\n",
    "\n",
    "def estimate_Q(r, gamma):\n",
    "  \"\"\" \n",
    "  take 1D float array of rewards and compute discounted reward --> Estimating Q(s,a)\n",
    "  \"\"\"\n",
    "  r = np.array(r)  # convert list to numpy\n",
    "\n",
    "  discounted_r = np.zeros_like(r)\n",
    "  running_add = 0\n",
    "  for t in reversed(range(0, r.size)):\n",
    "    if r[t] != 0:   # reset the sum, since this was a game boundary specific to Pong.\n",
    "        running_add = 0 \n",
    "    running_add = running_add * gamma + r[t]\n",
    "    discounted_r[t] = running_add\n",
    "  return discounted_r\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    \"\"\" \n",
    "    Use Policy to select an action based on state returned by Pong. The output expected by the PONG \n",
    "    is:\n",
    "    ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n",
    "    \n",
    "    So we need to return 2 (UP/RIGHT) and 3(DOWN/LEFT)\n",
    "    \"\"\"\n",
    "    \n",
    "    state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "    \n",
    "    # Use Policy to generate probability for action\n",
    "    logit = policy(Variable(state.type(gpu_dtype), requires_grad=False))\n",
    "\n",
    "    # Replace PyTorch recommended RL implementation\n",
    "    # Sample action stochastically    \n",
    "    # m = Categorical(probs)\n",
    "    # action = m.sample()\n",
    "\n",
    "    prob = F.softmax(logit, dim=1)\n",
    "    log_prob = F.log_softmax(logit, dim=1)\n",
    "    action = prob.multinomial().data   # action is sampled here\n",
    "    \n",
    "    if verbose:\n",
    "        print (\"Pong's state output:\", state.shape)\n",
    "        print (\"NN output:\", logit)\n",
    "        print (\"Pong Action:\", action)\n",
    "        print (\"log_prob(action):\", log_prob)\n",
    "        \n",
    "    log_prob = log_prob.gather(1, Variable(action))\n",
    "        \n",
    "    # Store log_prob (score function) into a list for calculating policy gradient    \n",
    "    policy.saved_log_probs.append(log_prob)\n",
    "    \n",
    "    if verbose:\n",
    "        print (\"Stacked log_prob:\", policy.saved_log_probs)\n",
    "    \n",
    "    return action\n",
    "\n",
    "def finish_batch():\n",
    "    \"\"\" \n",
    "    Based on REINFORCE, policy gradient is computed at the end of a batch (instead of an\n",
    "    episode). It is then used to update the Policy's weights\n",
    "    \"\"\"\n",
    "\n",
    "    R = 0\n",
    "    policy_loss = []\n",
    "    rewards = []   # This is v_t\n",
    "    \n",
    "    if verbose:    \n",
    "        print (\"Rewards:\", policy.rewards)\n",
    "            \n",
    "    # In the main loop, reward for each time step is stored in the list policy.rewards[].\n",
    "    # At the end of the episode, this is used to generate v_t for each time step.\n",
    "    for r in policy.rewards[::-1]:\n",
    "        if r != 0:  # reset the sum, since this was a game boundary (pong specific!)\n",
    "            R = 0\n",
    "        R = r + gamma * R\n",
    "        rewards.insert(0, R)\n",
    "        \n",
    "    if verbose:    \n",
    "        print (\"Discounted Rewards:\", rewards)\n",
    "       \n",
    "    rewards = torch.Tensor(rewards)\n",
    "    \n",
    "    # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n",
    "    rewards = (rewards - rewards.mean()) / (rewards.std() + np.finfo(np.float32).eps)\n",
    "\n",
    "    if verbose:\n",
    "        print (\"v_t:\", rewards)   \n",
    "\n",
    "    # Calculate policy gradient ∇_θ log (π_θ ( s_t , a_t ) )v_t\n",
    "    for log_prob, reward in zip(policy.saved_log_probs, rewards):\n",
    "        policy_loss.append(-log_prob * reward)   # negative because gradient descent\n",
    "\n",
    "    if verbose:\n",
    "        print (\"Policy Gradient:\", policy_loss)  \n",
    "        \n",
    "    optimizer.zero_grad()  # zero the gradients before running the optimizer\n",
    "    \n",
    "    # Sum policy gradients for all time steps in the episode\n",
    "    policy_loss = torch.cat(policy_loss).sum()   \n",
    "    if verbose:\n",
    "        print (\"Policy loss (after cat and sum):\", policy_loss)  \n",
    "        \n",
    "    # The TRICK: backward() on policy_loss instead of policy\n",
    "    # Policy's parameters are updated here.\n",
    "    policy_loss.backward()  \n",
    "    optimizer.step()\n",
    "    \n",
    "    del policy.rewards[:]\n",
    "    del policy.saved_log_probs[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\tLast Reward: -14.00\tRunning Reward: -14.99\n",
      "Episode 10\tLast Reward: -14.00\tRunning Reward: -14.75\n",
      "Episode 20\tLast Reward: -12.00\tRunning Reward: -14.51\n",
      "Episode 30\tLast Reward: -13.00\tRunning Reward: -14.25\n",
      "Episode 40\tLast Reward: -13.00\tRunning Reward: -14.04\n",
      "Episode 50\tLast Reward: -12.00\tRunning Reward: -13.89\n",
      "Episode 60\tLast Reward: -9.00\tRunning Reward: -13.68\n",
      "Episode 70\tLast Reward: -11.00\tRunning Reward: -13.57\n",
      "Episode 80\tLast Reward: -5.00\tRunning Reward: -13.38\n",
      "Episode 90\tLast Reward: -12.00\tRunning Reward: -13.29\n",
      "Episode 100\tLast Reward: -12.00\tRunning Reward: -13.18\n",
      "Episode 110\tLast Reward: -14.00\tRunning Reward: -13.11\n",
      "Episode 120\tLast Reward: -11.00\tRunning Reward: -13.05\n",
      "Episode 130\tLast Reward: -10.00\tRunning Reward: -12.96\n",
      "Episode 140\tLast Reward: -14.00\tRunning Reward: -12.92\n",
      "Episode 150\tLast Reward: -12.00\tRunning Reward: -12.79\n",
      "Episode 160\tLast Reward: -13.00\tRunning Reward: -12.71\n",
      "Episode 170\tLast Reward: -14.00\tRunning Reward: -12.68\n",
      "Episode 180\tLast Reward: -11.00\tRunning Reward: -12.60\n",
      "Episode 190\tLast Reward: -14.00\tRunning Reward: -12.54\n",
      "Episode 200\tLast Reward: -14.00\tRunning Reward: -12.58\n",
      "Episode 210\tLast Reward: -14.00\tRunning Reward: -12.55\n",
      "Episode 220\tLast Reward: -14.00\tRunning Reward: -12.55\n",
      "Episode 230\tLast Reward: -14.00\tRunning Reward: -12.56\n",
      "Episode 240\tLast Reward: -12.00\tRunning Reward: -12.54\n",
      "Episode 250\tLast Reward: -14.00\tRunning Reward: -12.60\n",
      "Episode 260\tLast Reward: -10.00\tRunning Reward: -12.46\n",
      "Episode 270\tLast Reward: -14.00\tRunning Reward: -12.49\n",
      "Episode 280\tLast Reward: -14.00\tRunning Reward: -12.47\n",
      "Episode 290\tLast Reward: -8.00\tRunning Reward: -12.35\n",
      "Episode 300\tLast Reward: -14.00\tRunning Reward: -12.33\n",
      "Episode 310\tLast Reward: -11.00\tRunning Reward: -12.34\n",
      "Episode 320\tLast Reward: -10.00\tRunning Reward: -12.36\n",
      "Episode 330\tLast Reward: -12.00\tRunning Reward: -12.29\n",
      "Episode 340\tLast Reward: -12.00\tRunning Reward: -12.17\n",
      "Episode 350\tLast Reward: -9.00\tRunning Reward: -12.17\n",
      "Episode 360\tLast Reward: -14.00\tRunning Reward: -12.20\n",
      "Episode 370\tLast Reward: -10.00\tRunning Reward: -12.16\n",
      "Episode 380\tLast Reward: -12.00\tRunning Reward: -12.13\n",
      "Episode 390\tLast Reward: -14.00\tRunning Reward: -12.21\n",
      "Episode 400\tLast Reward: -10.00\tRunning Reward: -12.22\n",
      "Episode 410\tLast Reward: -14.00\tRunning Reward: -12.20\n",
      "Episode 420\tLast Reward: -14.00\tRunning Reward: -12.22\n",
      "Episode 430\tLast Reward: -14.00\tRunning Reward: -12.25\n",
      "Episode 440\tLast Reward: -10.00\tRunning Reward: -12.02\n",
      "Episode 450\tLast Reward: -14.00\tRunning Reward: -12.08\n",
      "Episode 460\tLast Reward: -9.00\tRunning Reward: -12.07\n",
      "Episode 470\tLast Reward: -12.00\tRunning Reward: -12.10\n",
      "Episode 480\tLast Reward: -12.00\tRunning Reward: -12.12\n",
      "Episode 490\tLast Reward: -10.00\tRunning Reward: -12.11\n",
      "Episode 500\tLast Reward: -10.00\tRunning Reward: -12.15\n",
      "Episode 510\tLast Reward: -9.00\tRunning Reward: -12.12\n",
      "Episode 520\tLast Reward: -10.00\tRunning Reward: -12.11\n",
      "Episode 530\tLast Reward: -14.00\tRunning Reward: -12.05\n",
      "Episode 540\tLast Reward: -11.00\tRunning Reward: -12.05\n",
      "Episode 550\tLast Reward: -10.00\tRunning Reward: -12.07\n",
      "Episode 560\tLast Reward: -11.00\tRunning Reward: -12.11\n",
      "Episode 570\tLast Reward: -10.00\tRunning Reward: -12.13\n",
      "Episode 580\tLast Reward: -12.00\tRunning Reward: -12.21\n",
      "Episode 590\tLast Reward: -12.00\tRunning Reward: -12.19\n",
      "Episode 600\tLast Reward: -5.00\tRunning Reward: -12.00\n",
      "Episode 610\tLast Reward: -13.00\tRunning Reward: -12.02\n",
      "Episode 620\tLast Reward: -14.00\tRunning Reward: -12.03\n",
      "Episode 630\tLast Reward: -13.00\tRunning Reward: -11.99\n",
      "Episode 640\tLast Reward: -14.00\tRunning Reward: -11.96\n",
      "Episode 650\tLast Reward: -12.00\tRunning Reward: -11.91\n",
      "Episode 660\tLast Reward: -14.00\tRunning Reward: -11.97\n",
      "Episode 670\tLast Reward: -13.00\tRunning Reward: -12.10\n",
      "Episode 680\tLast Reward: -12.00\tRunning Reward: -12.05\n",
      "Episode 690\tLast Reward: -9.00\tRunning Reward: -12.04\n",
      "Episode 700\tLast Reward: -14.00\tRunning Reward: -12.07\n",
      "Episode 710\tLast Reward: -14.00\tRunning Reward: -12.10\n",
      "Episode 720\tLast Reward: -14.00\tRunning Reward: -12.16\n",
      "Episode 730\tLast Reward: -9.00\tRunning Reward: -12.20\n",
      "Episode 740\tLast Reward: -9.00\tRunning Reward: -12.18\n",
      "Episode 750\tLast Reward: -14.00\tRunning Reward: -11.97\n",
      "Episode 760\tLast Reward: -14.00\tRunning Reward: -11.95\n",
      "Episode 770\tLast Reward: -14.00\tRunning Reward: -12.03\n",
      "Episode 780\tLast Reward: -14.00\tRunning Reward: -12.03\n",
      "Episode 790\tLast Reward: -9.00\tRunning Reward: -12.00\n",
      "Episode 800\tLast Reward: -13.00\tRunning Reward: -12.05\n",
      "Episode 810\tLast Reward: -14.00\tRunning Reward: -12.13\n",
      "Episode 820\tLast Reward: -14.00\tRunning Reward: -12.22\n",
      "Episode 830\tLast Reward: -5.00\tRunning Reward: -12.07\n",
      "Episode 840\tLast Reward: -14.00\tRunning Reward: -12.09\n",
      "Episode 850\tLast Reward: -14.00\tRunning Reward: -12.03\n",
      "Episode 860\tLast Reward: -11.00\tRunning Reward: -11.97\n",
      "Episode 870\tLast Reward: -14.00\tRunning Reward: -11.97\n",
      "Episode 880\tLast Reward: -14.00\tRunning Reward: -12.02\n",
      "Episode 890\tLast Reward: -11.00\tRunning Reward: -12.07\n",
      "Episode 900\tLast Reward: -12.00\tRunning Reward: -12.09\n",
      "Episode 910\tLast Reward: -14.00\tRunning Reward: -12.10\n",
      "Episode 920\tLast Reward: -14.00\tRunning Reward: -12.12\n",
      "Episode 930\tLast Reward: -9.00\tRunning Reward: -12.06\n",
      "Episode 940\tLast Reward: -6.00\tRunning Reward: -11.98\n",
      "Episode 950\tLast Reward: -14.00\tRunning Reward: -12.01\n",
      "Episode 960\tLast Reward: -7.00\tRunning Reward: -12.06\n",
      "Episode 970\tLast Reward: -12.00\tRunning Reward: -12.03\n",
      "Episode 980\tLast Reward: -10.00\tRunning Reward: -12.00\n",
      "Episode 990\tLast Reward: -11.00\tRunning Reward: -12.01\n",
      "Episode 1000\tLast Reward: -10.00\tRunning Reward: -11.97\n",
      "Time taken: -1887.0265192985535\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "gamma=0.99\n",
    "render=False\n",
    "verbose=False  # To step through the code and understand what is going on\n",
    "log_interval=10\n",
    "play_steps = 800  # number of game steps before we calculate policy gradient\n",
    "gradient_batch = 10   # number of policy gradients to batch before updating the policy\n",
    "lr = 1e-4 \n",
    "\n",
    "reinforce=[]\n",
    "env = gym.make(\"Pong-v0\")\n",
    "\n",
    "# D_in is input dimension; H is hidden dimension; D_out is output dimension.\n",
    "D_in, H, D_out = 6400, 200, 2\n",
    "\n",
    "# Randomly initialize weights\n",
    "if torch.cuda.is_available():\n",
    "    W1 = torch.randn(D_in, H).type(gpu_dtype)/math.sqrt(2./D_in)\n",
    "    W2 = torch.randn(H, D_out).type(gpu_dtype)/math.sqrt(2./H)\n",
    "else:\n",
    "    W1 = torch.randn(D_in, H).type(cpu_dtype)/math.sqrt(2./D_in)\n",
    "    W2 = torch.randn(H, D_out).type(cpu_dtype)/math.sqrt(2./H) \n",
    "\n",
    "dW1_buffer = None\n",
    "dW2_buffer = None\n",
    "\n",
    "        \n",
    "# Main loop\n",
    "prev_x = None\n",
    "running_reward = -15\n",
    "start = time.time()\n",
    "\n",
    "for i_episode in range(1000+1): # run 30000 episode    \n",
    "    state = env.reset()\n",
    "    reward_sum = 0\n",
    "    \n",
    "    # Clear out the stacked local gradients\n",
    "    eph = None\n",
    "    epdlogp = None\n",
    "    epx = None\n",
    "    epr = None\n",
    "    rewards = []\n",
    "    \n",
    "    for t in range(10000):  # Don't infinite loop while learning\n",
    "        \n",
    "        # Downsample 210x160x3 frame into 6400 (80x80) 1D float vector\n",
    "        cur_x = prepro80(state)\n",
    "        state = cur_x - prev_x if prev_x is not None else np.zeros(6400)\n",
    "        prev_x = cur_x\n",
    "        \n",
    "        \"\"\"\n",
    "        Sample an action from Policy based on state provided by env\n",
    "        (Entering Torch(GPU/CPU) Land!!!)\n",
    "        \"\"\"\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0)   # state: numpy-->Tensor\n",
    "\n",
    "        # 2-layer Neural Network - Forward Pass\n",
    "        #  Input - state\n",
    "        #  Output - logp\n",
    "    \n",
    "        # Stage 1 - Matrix Multiplication                               #[1]    \n",
    "        h = state.mm(W1)\n",
    "        # Stage 2 - ReLU                                                #[2]    \n",
    "        h_relu = h.clamp(min=0)\n",
    "        # Stage 3 - Matrix Multiplication                               #[3]    \n",
    "        logp = h_relu.mm(W2)\n",
    "\n",
    "        # A Pong action is sampled from the Softmax Classifier\n",
    "        prob = F.softmax(Variable(logp), dim=1)\n",
    "        sample = prob.multinomial().data  \n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Softmax prob:\", prob)\n",
    "            print(\"Sampled output:\", sample)\n",
    "        \"\"\"\n",
    "        Stack local gradients for policy update at the end of episode/batch\n",
    "        \"\"\"\n",
    "        \n",
    "        y = torch.zeros(1, D_out).scatter_(1,torch.LongTensor(sample) ,1)\n",
    "        dlogp = y - prob.data\n",
    "\n",
    "        epdlogp =  torch.cat((epdlogp, dlogp), 0) if epdlogp is not None else dlogp\n",
    "        eph = torch.cat((eph, h), 0) if eph is not None else h\n",
    "        epx = torch.cat((epx, state), 0) if epx is not None else state\n",
    "        \n",
    "        if verbose: \n",
    "            print(\"y-prob: \", dlogp)\n",
    "            print(\"Stacked y-prob: \", epdlogp.size())    \n",
    "            print(\"Stacked h: \",eph.size())    \n",
    "            print(\"Stacked x: \",epx.size()) \n",
    "            \n",
    "        \"\"\"\n",
    "        Advance one step in the Pong env using action sampled \n",
    "        (Exit Torch(GPU/CPU) Land. Now in Numpy-CPU Land!!!)\n",
    "        \"\"\"\n",
    "        \n",
    "        action = sample.cpu().numpy() + 2   # action: Tensor --> numpy\n",
    "        \n",
    "        # step env through the sampled action\n",
    "        state, reward, done, _ = env.step(action)  # UP=2, DOWN=3\n",
    "        reward_sum += reward\n",
    "        if render:\n",
    "            env.render() \n",
    "            \n",
    "        \"\"\"\n",
    "        Stack rewards for policy update at the end of episode/batch\n",
    "        \"\"\"\n",
    "        rewards.append(reward)     \n",
    "        if verbose: \n",
    "            print(\"Pong action: \",action)\n",
    "            print(\"Stacked rewards: \",rewards) \n",
    "        \n",
    "        # Time to update policy - episode done or game steps exceed a preset value\n",
    "        if done or t > update_interval:\n",
    "            break\n",
    "            \n",
    "    \"\"\" \n",
    "    In REINFORCE, policy gradient is computed at the end of a batch/episode and then \n",
    "    used to update the Policy's weights\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print (\"We have finished a batch/episode. We now calculate policy gradient. \\n\")  \n",
    "    \n",
    "    \"\"\"\n",
    "    While the agent is playing, reward for each time step is stored in rewards[].\n",
    "    At the end of the episode, this is used to generate Q(s,a) for each time step.\n",
    "    (Exit Numpy-CPU Land. Now in Torch(GPU/CPU) Land!!!)\n",
    "    \"\"\"\n",
    "    \n",
    "    Q = estimate_Q(rewards, gamma)\n",
    "    epq = torch.from_numpy(Q).float().view(-1,1)  # reshape to Nx1 where N = # play steps\n",
    "   \n",
    "    # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n",
    "    epq = (epq - epq.mean()) / (epq.std() + np.finfo(np.float32).eps)\n",
    "    \n",
    "    epdlogp *= epq  # modulate the gradient with advantage (PG magic happens right here.) \n",
    "    \n",
    "    if verbose:\n",
    "        print (\"Stacked Q(s,a): \",epq) \n",
    "        print (\"Stacked Q(s,a)*(y-prob): \", epdlogp) \n",
    "\n",
    "    # 2-layer Neural Network - Backward Pass\n",
    "    #  Input - epdlogp\n",
    "    #  Output - dW1, dW2\n",
    "\n",
    "    # Stage 3 - BackProp Matrix Multiplication                               #[3]\n",
    "    # logp = h_relu.mm(W2)\n",
    "    dW2 = torch.transpose(eph, 0, 1).mm(epdlogp)\n",
    "    dh = epdlogp.mm(torch.transpose(W2,0,1))\n",
    "    \n",
    "    # Stage 2 - Backprop ReLU                                                #[2]    \n",
    "    # h_relu = h.clamp(min=0)\n",
    "    dh[eph <= 0] = 0 \n",
    "\n",
    "    # Stage 1 - Matrix Multiplication                               #[1]    \n",
    "    # h = state.mm(W1)\n",
    "    dW1 = torch.transpose(epx, 0, 1).mm(dh)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"dW2: \",dW2.size())\n",
    "        print(\"dh_relu: \",dh.size())\n",
    "        print(\"dh: \",dh.size())\n",
    "        print(\"dW1: \",dW1.size())\n",
    "        \n",
    "    dW1_buffer = torch.add(dW1_buffer, dW1) if dW1_buffer is not None else dW1\n",
    "    dW2_buffer = torch.add(dW2_buffer, dW2) if dW2_buffer is not None else dW2\n",
    "\n",
    "    # After a number of gradients have been batched, update policy weights using gradient descent\n",
    "    if (i_episode+1) % gradient_batch == 0:\n",
    "        W1 += lr * dW1_buffer\n",
    "        W2 += lr * dW2_buffer\n",
    "        dW1_buffer = None\n",
    "        dW2_buffer = None\n",
    "\n",
    "\n",
    "    # Keep track of running reward\n",
    "    running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "    reinforce.append([reward_sum, running_reward])\n",
    "    \n",
    "    # print out and show sign of life\n",
    "    if i_episode % log_interval == 0:\n",
    "        print('Episode {}\\tLast Reward: {:.2f}\\tRunning Reward: {:.2f}'.format(\n",
    "                i_episode, reward_sum, running_reward))\n",
    "    \n",
    "    # save model every 4000 episodes\n",
    "    if i_episode % 4000 == 0:\n",
    "        model = {}\n",
    "        model['W1'] = W1\n",
    "        model['W2'] = W2\n",
    "        pickle.dump(model, open('save.p', 'wb'))\n",
    "\n",
    "end = time.time()\n",
    "print (\"Time taken:\", start-end)\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'reinforce-k-lr=1e-3'\n",
    "history_file = './results/reinforce/pong_'+name+'ep='+str(i_episode+1)+'history.p'\n",
    "pickle.dump(reinforce, open(history_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f75b8ca39b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data1 = pickle.load(open('./results/reinforce/pong_reinforce-k-lr=1e-3ep=1001history.p', 'rb'))\n",
    "data2 = pickle.load(open('./results/pg-numpy/reward_history-pg-numpy-30000ep-lr-1e-3.p', 'rb'))\n",
    "\n",
    "# Plot out reward and running reward over training episodes\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "\n",
    "plt.plot(list(range(1,len(data1)+1)), np.array(data1)[:,1], label='reinforce-k lr=1e-3')\n",
    "plt.plot(list(range(1,len(data2)+1)), np.array(data2)[:,1], label='REINFORCE-Karpathy')\n",
    "plt.title('reinforce-k vs REINFORCE(Karpathy) - Pong')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Running Wins over Pong AI')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.]\n",
      "\n",
      " 2\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      " 2\n",
      " 2\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = np.array([2.0])\n",
    "print (x)\n",
    "\n",
    "y = torch.from_numpy(x).float()\n",
    "print (y)\n",
    "\n",
    "y = torch.cat((y,y),0)\n",
    "\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-1.1776e+01 -5.4662e+01 -6.4076e+01  ...   2.2455e+00  8.0946e+00  4.8980e+01\n",
      "-3.8046e+01 -9.9706e+01 -1.6747e+00  ...  -6.9307e+00  5.2662e+00  6.4510e+01\n",
      "-3.3685e+01 -1.4248e+01  5.1007e+01  ...   1.3964e+02 -2.8429e+01 -1.7248e+01\n",
      "                ...                   ⋱                   ...                \n",
      " 1.6935e+01 -6.1469e+01  2.1259e+01  ...   4.1310e+01 -3.9917e+01 -6.9136e+01\n",
      " 1.0329e+01 -2.1218e+01 -4.6218e+01  ...  -1.9701e+01  4.9976e+01  1.7643e+01\n",
      "-7.0451e+01 -3.4414e+00  1.3894e-01  ...   8.3061e+01  1.5964e+01 -2.4826e+00\n",
      "[torch.FloatTensor of size 6400x200]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open('save.p', 'rb'))\n",
    "\n",
    "print (model['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
