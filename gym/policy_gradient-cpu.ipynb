{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Gradient \n",
    "\n",
    "This Notebook reimplements Karpathy's basic policy gradient agent in PyTorch without GPU acceleration.\n",
    "\n",
    "It is meant to be run on the laptop for code development. After code is stable, it will be translated to the AI Workstation with GPU acceleration for long training sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.6.3\n"
     ]
    }
   ],
   "source": [
    "# As usual, a bit of setup\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import platform\n",
    "import gym\n",
    "import torch\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"Python version: \", platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Karpathy Basic Policy Gradient \"Pong\"\n",
    "\n",
    "The following code uses a basic policy gradient method to train a 2 layer NN to play Pong.\n",
    "\n",
    "The time needed to train 10 episodes is 13 sec with CPU.\n",
    "\n",
    "The forward pass takes 4 seconds. So implementing this in PyTorch and using GPU will speed things up by 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 20 - reward total was -21.000000. running mean: -20.964255\n",
      "Episode 40 - reward total was -21.000000. running mean: -20.840709\n",
      "Episode 60 - reward total was -20.000000. running mean: -20.752657\n",
      "Episode 80 - reward total was -20.000000. running mean: -20.652472\n",
      "Episode 100 - reward total was -21.000000. running mean: -20.499510\n",
      "Episode 120 - reward total was -19.000000. running mean: -20.352835\n",
      "Episode 140 - reward total was -21.000000. running mean: -20.343211\n",
      "Episode 160 - reward total was -20.000000. running mean: -20.267170\n",
      "Episode 180 - reward total was -21.000000. running mean: -20.196141\n",
      "Episode 200 - reward total was -18.000000. running mean: -20.157837\n",
      "Episode 220 - reward total was -19.000000. running mean: -20.119638\n",
      "Episode 240 - reward total was -21.000000. running mean: -20.131668\n",
      "Episode 260 - reward total was -21.000000. running mean: -20.177770\n",
      "Episode 280 - reward total was -20.000000. running mean: -20.144430\n",
      "Episode 300 - reward total was -19.000000. running mean: -20.118163\n",
      "Episode 320 - reward total was -18.000000. running mean: -20.020993\n",
      "Episode 340 - reward total was -19.000000. running mean: -20.030501\n",
      "Episode 360 - reward total was -18.000000. running mean: -19.906581\n",
      "Episode 380 - reward total was -19.000000. running mean: -19.857508\n",
      "Episode 400 - reward total was -19.000000. running mean: -19.827148\n",
      "Episode 420 - reward total was -19.000000. running mean: -19.850231\n",
      "Episode 440 - reward total was -19.000000. running mean: -19.779100\n",
      "Episode 460 - reward total was -20.000000. running mean: -19.738896\n",
      "Episode 480 - reward total was -20.000000. running mean: -19.702466\n",
      "Episode 500 - reward total was -20.000000. running mean: -19.753691\n",
      "Episode 520 - reward total was -20.000000. running mean: -19.800994\n",
      "Episode 540 - reward total was -17.000000. running mean: -19.735496\n",
      "Episode 560 - reward total was -21.000000. running mean: -19.665549\n",
      "Episode 580 - reward total was -16.000000. running mean: -19.603134\n",
      "Episode 600 - reward total was -19.000000. running mean: -19.596861\n",
      "Episode 620 - reward total was -21.000000. running mean: -19.613519\n",
      "Episode 640 - reward total was -19.000000. running mean: -19.665823\n",
      "Episode 660 - reward total was -16.000000. running mean: -19.570549\n",
      "Episode 680 - reward total was -16.000000. running mean: -19.443354\n",
      "Episode 700 - reward total was -20.000000. running mean: -19.338390\n",
      "Episode 720 - reward total was -20.000000. running mean: -19.239452\n",
      "Episode 740 - reward total was -19.000000. running mean: -19.123814\n",
      "Episode 760 - reward total was -19.000000. running mean: -19.066986\n",
      "Episode 780 - reward total was -17.000000. running mean: -19.080781\n",
      "Episode 800 - reward total was -21.000000. running mean: -19.103882\n",
      "Episode 820 - reward total was -18.000000. running mean: -19.143792\n",
      "Episode 840 - reward total was -20.000000. running mean: -19.047490\n",
      "Episode 860 - reward total was -19.000000. running mean: -19.092417\n",
      "Episode 880 - reward total was -20.000000. running mean: -19.070818\n",
      "Episode 900 - reward total was -17.000000. running mean: -18.814363\n",
      "Episode 920 - reward total was -17.000000. running mean: -18.848091\n",
      "Episode 940 - reward total was -19.000000. running mean: -18.791823\n",
      "Episode 960 - reward total was -17.000000. running mean: -18.804260\n",
      "Episode 980 - reward total was -17.000000. running mean: -18.749659\n",
      "Episode 1000 - reward total was -15.000000. running mean: -18.567613\n",
      "Time to complete 2408.3758277893066\n",
      "Time to forward pass 1016.5728771686554\n",
      "Time to backward pass 82.62841272354126\n",
      "Time to other stuffs 1074.6741683483124\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Trains an agent with (stochastic) Policy Gradients on Pong. Uses OpenAI Gym. \"\"\"\n",
    "import numpy as np\n",
    "import pickle as pickle\n",
    "import gym\n",
    "\n",
    "# hyperparameters\n",
    "H = 200 # number of hidden layer neurons\n",
    "batch_size = 10 # every how many episodes to do a param update?\n",
    "\n",
    "learning_rate  = 1e-3\n",
    "epoch_reward_history=[]\n",
    "    \n",
    "gamma = 0.99 # discount factor for reward\n",
    "decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n",
    "resume = False # resume from previous checkpoint?\n",
    "render = False\n",
    "\n",
    "# model initialization\n",
    "D = 80 * 80 # input dimensionality: 80x80 grid\n",
    "if resume:\n",
    "  model = pickle.load(open('save.p', 'rb'))\n",
    "else:\n",
    "  model = {}\n",
    "  model['W1'] = np.random.randn(H,D) / np.sqrt(D) # \"Xavier\" initialization\n",
    "  model['W2'] = np.random.randn(H) / np.sqrt(H)\n",
    "\n",
    "grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } # update buffers that add up gradients over a batch\n",
    "rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } # rmsprop memory\n",
    "\n",
    "def sigmoid(x): \n",
    "  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n",
    "\n",
    "def prepro(I):\n",
    "  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n",
    "  I = I[35:195] # crop\n",
    "  I = I[::2,::2,0] # downsample by factor of 2\n",
    "  I[I == 144] = 0 # erase background (background type 1)\n",
    "  I[I == 109] = 0 # erase background (background type 2)\n",
    "  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
    "  return I.astype(np.float).ravel()\n",
    "\n",
    "def discount_rewards(r):\n",
    "  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
    "  discounted_r = np.zeros_like(r)\n",
    "  running_add = 0\n",
    "  for t in reversed(range(0, r.size)):\n",
    "    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n",
    "    running_add = running_add * gamma + r[t]\n",
    "    discounted_r[t] = running_add\n",
    "  return discounted_r\n",
    "\n",
    "def policy_forward(x):\n",
    "  h = np.dot(model['W1'], x)\n",
    "  h[h<0] = 0 # ReLU nonlinearity\n",
    "  logp = np.dot(model['W2'], h)\n",
    "  p = sigmoid(logp)\n",
    "  return p, h # return probability of taking action 2, and hidden state\n",
    "\n",
    "def policy_backward(eph, epdlogp):\n",
    "  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n",
    "  dW2 = np.dot(eph.T, epdlogp).ravel()\n",
    "  dh = np.outer(epdlogp, model['W2'])\n",
    "  dh[eph <= 0] = 0 # backpro prelu\n",
    "  dW1 = np.dot(dh.T, epx)\n",
    "  return {'W1':dW1, 'W2':dW2}\n",
    "\n",
    "env = gym.make(\"Pong-v0\")\n",
    "observation = env.reset()\n",
    "prev_x = None # used in computing the difference frame\n",
    "xs,hs,dlogps,drs = [],[],[],[]\n",
    "running_reward = None\n",
    "verbose = False\n",
    "print_every = 20\n",
    "reward_sum = 0\n",
    "episode_number = 0\n",
    "forward_time=0\n",
    "backward_time=0\n",
    "other_time=0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "while episode_number < 1000:\n",
    "  if render: env.render()\n",
    "\n",
    "  # preprocess the observation, set input to network to be difference image\n",
    "  cur_x = prepro(observation)\n",
    "  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
    "  prev_x = cur_x\n",
    "\n",
    "  # forward the policy network and sample an action from the returned probability\n",
    "  t1 = time.time()\n",
    "  aprob, h = policy_forward(x)\n",
    "  action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n",
    "  t2 = time.time()\n",
    "  forward_time += t2-t1\n",
    "\n",
    "  # record various intermediates (needed later for backprop)\n",
    "  xs.append(x) # observation\n",
    "  hs.append(h) # hidden state\n",
    "  y = 1 if action == 2 else 0 # a \"fake label\"\n",
    "  dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken \n",
    "  # (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n",
    "\n",
    "  # step the environment and get new measurements\n",
    "  t5 = time.time()  \n",
    "  # step the environment and get new measurements\n",
    "  observation, reward, done, info = env.step(action)\n",
    "  reward_sum += reward\n",
    "\n",
    "  t6 = time.time()\n",
    "  other_time += t6-t5\n",
    "\n",
    "  drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n",
    "\n",
    "  if done: # an episode finished\n",
    "    episode_number += 1\n",
    "\n",
    "    # stack together all inputs, hidden states, action gradients, and rewards for this episode\n",
    "    epx = np.vstack(xs)\n",
    "    eph = np.vstack(hs)\n",
    "    epdlogp = np.vstack(dlogps)\n",
    "    epr = np.vstack(drs)\n",
    "    xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n",
    "\n",
    "    # compute the discounted reward backwards through time\n",
    "    discounted_epr = discount_rewards(epr)\n",
    "    # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n",
    "    discounted_epr -= np.mean(discounted_epr)\n",
    "    discounted_epr /= np.std(discounted_epr)\n",
    "\n",
    "    epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n",
    "    \n",
    "    t3 = time.time()    \n",
    "    grad = policy_backward(eph, epdlogp)\n",
    "    t4 = time.time()\n",
    "    backward_time += t4-t3    \n",
    "    \n",
    "    for k in model: \n",
    "        grad_buffer[k] += grad[k] # accumulate grad over batch\n",
    "\n",
    "    # perform rmsprop parameter update every batch_size episodes\n",
    "    if episode_number % batch_size == 0:\n",
    "      for k,v in model.items():\n",
    "        g = grad_buffer[k] # gradient\n",
    "        rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n",
    "        model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n",
    "        grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n",
    "\n",
    "    # boring book-keeping\n",
    "    running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "    if episode_number % print_every == 0:     \n",
    "        print ('Episode %d - reward total was %f. running mean: %f' % (episode_number, reward_sum, running_reward))\n",
    "\n",
    "    epoch_reward_history.append([reward_sum, running_reward])\n",
    "    if episode_number % 100 == 0: pickle.dump(model, open('save-cpu-lr1e-3-1000ep.p', 'wb'))\n",
    "    reward_sum = 0\n",
    "    observation = env.reset() # reset env\n",
    "    prev_x = None\n",
    "\n",
    "  if reward != 0 and verbose: # Pong has either +1 or -1 reward exactly when game ends.\n",
    "    print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))\n",
    "    \n",
    "end = time.time()\n",
    "print (\"Time to complete\", end-start)\n",
    "print (\"Time to forward pass\", forward_time)\n",
    "print (\"Time to backward pass\", backward_time)\n",
    "print (\"Time to other stuffs\", other_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations (Laptop CPU)\n",
    "\n",
    "Time to train 1000 episodes is 2400 seconds or 40 minutes. Over 1100 seconds are consumed by OpenAI Gym stepping through its environment (1 second per step).  \n",
    "\n",
    "The agent achieved under -19.0 running reward and highs of -13 reward sum after 1000 episodes.\n",
    "\n",
    "The trained model is in save-cpu-lr1e-3-1000ep.p\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff04da620f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = np.array(epoch_reward_history)\n",
    "\n",
    "# Plot out the accuracies\n",
    "plt.title('Reward for Learning Rate '+str(learning_rate))\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(history[:,0], '-ro', label=\"reward sum\")\n",
    "plt.plot(history[:,1], '-bo', label=\"running reward\")\n",
    "plt.legend(loc='best', ncol=4)\n",
    "\n",
    " \n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variability of Training\n",
    "\n",
    "How well a model train is variable. For the training session below, the agent achieved close to -16 running reward and highs of -6 reward sum after the same 1000 episodes, which is much better than the training session before it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdda4b10a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = np.array(epoch_reward_history)\n",
    "\n",
    "# Plot out the accuracies\n",
    "plt.title('Reward for Learning Rate '+str(learning_rate))\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(history[:,0], '-ro', label=\"reward sum\")\n",
    "plt.plot(history[:,1], '-bo', label=\"running reward\")\n",
    "plt.legend(loc='best', ncol=4)\n",
    "\n",
    " \n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()\n",
    "\n",
    "pickle.dump(model, open('reward_lr_1e-3_1000ep_numpy.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch - Policy Gradient on Cartpole\n",
    "\n",
    "The following code is PyTorch's official example for reinforcement learning. It trains a RL agent to master the simple game of Cartpole: \n",
    "\n",
    "https://github.com/pytorch/examples/blob/master/reinforcement_learning/reinforce.py\n",
    "\n",
    "We need to better understand it so that we can port the Karpathy numpy code over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "This is CartPole's state output: \n",
      "1.00000e-02 *\n",
      "  0.2602  2.6891 -1.3696 -2.0036\n",
      "[torch.FloatTensor of size 1x4]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5007  0.4993\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action sampled: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      " 0\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6917\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is CartPole's state output: \n",
      " 0.0031 -0.1680 -0.0141  0.2683\n",
      "[torch.FloatTensor of size 1x4]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5096  0.4904\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action sampled: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      " 0\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6741\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is CartPole's state output: \n",
      "-0.0002 -0.3629 -0.0087  0.5565\n",
      "[torch.FloatTensor of size 1x4]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5233  0.4767\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action sampled: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      " 0\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6475\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is CartPole's state output: \n",
      "-0.0075 -0.5579  0.0024  0.8464\n",
      "[torch.FloatTensor of size 1x4]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5356  0.4644\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action sampled: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      " 1\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7669\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is CartPole's state output: \n",
      "-0.0186 -0.3629  0.0193  0.5545\n",
      "[torch.FloatTensor of size 1x4]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5247  0.4753\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action sampled: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      " 0\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6449\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is CartPole's state output: \n",
      "-0.0259 -0.5582  0.0304  0.8532\n",
      "[torch.FloatTensor of size 1x4]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5370  0.4630\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action sampled: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      " 1\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7699\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is CartPole's state output: \n",
      "-0.0371 -0.3636  0.0475  0.5702\n",
      "[torch.FloatTensor of size 1x4]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5267  0.4733\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action sampled: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      " 0\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6412\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is CartPole's state output: \n",
      "-0.0443 -0.5593  0.0589  0.8775\n",
      "[torch.FloatTensor of size 1x4]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5392  0.4608\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action sampled: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      " 0\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6178\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is CartPole's state output: \n",
      "-0.0555 -0.7552  0.0764  1.1881\n",
      "[torch.FloatTensor of size 1x4]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5486  0.4514\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action sampled: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      " 0\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6003\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is CartPole's state output: \n",
      "-0.0706 -0.9512  0.1002  1.5037\n",
      "[torch.FloatTensor of size 1x4]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5542  0.4458\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action sampled: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      " 0\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.5903\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is CartPole's state output: \n",
      "-0.0896 -1.1474  0.1303  1.8259\n",
      "[torch.FloatTensor of size 1x4]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5615  0.4385\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action sampled: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      " 0\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.5772\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is CartPole's state output: \n",
      "-0.1126 -1.3437  0.1668  2.1561\n",
      "[torch.FloatTensor of size 1x4]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5695  0.4305\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action sampled: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      " 0\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.5630\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Rewards stored by policy: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Gamma-discounted rewards: \n",
      " 11.3615\n",
      " 10.4662\n",
      "  9.5618\n",
      "  8.6483\n",
      "  7.7255\n",
      "  6.7935\n",
      "  5.8520\n",
      "  4.9010\n",
      "  3.9404\n",
      "  2.9701\n",
      "  1.9900\n",
      "  1.0000\n",
      "[torch.FloatTensor of size 12]\n",
      "\n",
      "Normalized gamma-discounted rewards: \n",
      " 1.4999\n",
      " 1.2363\n",
      " 0.9700\n",
      " 0.7010\n",
      " 0.4293\n",
      " 0.1549\n",
      "-0.1224\n",
      "-0.4024\n",
      "-0.6852\n",
      "-0.9709\n",
      "-1.2595\n",
      "-1.5510\n",
      "[torch.FloatTensor of size 12]\n",
      "\n",
      "Policy loss: [Variable containing:\n",
      " 1.0375\n",
      "[torch.FloatTensor of size 1]\n",
      ", Variable containing:\n",
      " 0.8334\n",
      "[torch.FloatTensor of size 1]\n",
      ", Variable containing:\n",
      " 0.6281\n",
      "[torch.FloatTensor of size 1]\n",
      ", Variable containing:\n",
      " 0.5376\n",
      "[torch.FloatTensor of size 1]\n",
      ", Variable containing:\n",
      " 0.2769\n",
      "[torch.FloatTensor of size 1]\n",
      ", Variable containing:\n",
      " 0.1192\n",
      "[torch.FloatTensor of size 1]\n",
      ", Variable containing:\n",
      "1.00000e-02 *\n",
      " -7.8454\n",
      "[torch.FloatTensor of size 1]\n",
      ", Variable containing:\n",
      "-0.2486\n",
      "[torch.FloatTensor of size 1]\n",
      ", Variable containing:\n",
      "-0.4114\n",
      "[torch.FloatTensor of size 1]\n",
      ", Variable containing:\n",
      "-0.5731\n",
      "[torch.FloatTensor of size 1]\n",
      ", Variable containing:\n",
      "-0.7269\n",
      "[torch.FloatTensor of size 1]\n",
      ", Variable containing:\n",
      "-0.8732\n",
      "[torch.FloatTensor of size 1]\n",
      "]\n",
      "Policy loss (after cat and sum): Variable containing:\n",
      " 0.5211\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Episode 0\tLast length:    11\tAverage length: 10.01\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import gym\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "gamma=0.99\n",
    "seed=543\n",
    "render=False\n",
    "log_interval=50\n",
    "verbose=True  # To step through the code and understand what is going on\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "env.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# A 2-layer NN with 128 hidden units\n",
    "class Policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        self.affine1 = nn.Linear(4, 128)\n",
    "        self.affine2 = nn.Linear(128, 2)\n",
    "\n",
    "        self.saved_log_probs = []\n",
    "        self.rewards = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.affine1(x))\n",
    "        action_scores = self.affine2(x)\n",
    "        return F.softmax(action_scores, dim=1)\n",
    "\n",
    "\n",
    "policy = Policy()\n",
    "optimizer = optim.Adam(policy.parameters(), lr=1e-2)\n",
    "\n",
    "def select_action(state):\n",
    "    \"\"\" Use policy to determine an action based on state provided \"\"\"\n",
    "    \n",
    "    state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "    if verbose:\n",
    "        print (\"This is CartPole's state output:\", state)\n",
    "    probs = policy(Variable(state))\n",
    "    if verbose:\n",
    "        print (\"This is softmax output from NN:\", probs)\n",
    "\n",
    "    m = Categorical(probs)\n",
    "    action = m.sample()\n",
    "    if verbose:\n",
    "        print (\"Action sampled:\", action, action.data[0])\n",
    "        print (\"log_prob(action) saved by policy:\", m.log_prob(action))\n",
    "    \n",
    "    policy.saved_log_probs.append(m.log_prob(action))\n",
    "    return action.data[0]\n",
    "\n",
    "\n",
    "def finish_episode():\n",
    "    R = 0\n",
    "    policy_loss = []\n",
    "    rewards = []\n",
    "    \n",
    "    if verbose:\n",
    "        print (\"Rewards stored by policy:\", policy.rewards)\n",
    "    \n",
    "    # Generate a list of gamma-discounted rewards based on rewards[] list stored by policy \n",
    "    for r in policy.rewards[::-1]:\n",
    "        R = r + gamma * R\n",
    "        rewards.insert(0, R)\n",
    "    rewards = torch.Tensor(rewards)\n",
    "    if verbose:\n",
    "        print (\"Gamma-discounted rewards:\", rewards)\n",
    "\n",
    "    rewards = (rewards - rewards.mean()) / (rewards.std() + np.finfo(np.float32).eps)\n",
    "    if verbose:\n",
    "        print (\"Normalized gamma-discounted rewards:\", rewards)   \n",
    "\n",
    "    # Generate policy_loss list\n",
    "    for log_prob, reward in zip(policy.saved_log_probs, rewards):\n",
    "        policy_loss.append(-log_prob * reward)\n",
    "\n",
    "    if verbose:\n",
    "        print (\"Policy loss:\", policy_loss)  \n",
    "        \n",
    "    optimizer.zero_grad()  # zero the gradients before running the optimizer\n",
    "    \n",
    "    policy_loss = torch.cat(policy_loss).sum()\n",
    "    \n",
    "    if verbose:\n",
    "        print (\"Policy loss (after cat and sum):\", policy_loss)  \n",
    "    \n",
    "    policy_loss.backward()  # The TRICK: backward() on policy_loss instead of policy\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    del policy.rewards[:]\n",
    "    del policy.saved_log_probs[:]\n",
    "\n",
    "\n",
    "# Main loop\n",
    "running_reward = 10\n",
    "# for i_episode in count(1):\n",
    "for i_episode in range(1): # just run 1 episode    \n",
    "    state = env.reset()\n",
    "    \n",
    "    for t in range(10000):  # Don't infinite loop while learning\n",
    "        \n",
    "        # select an action based on the state provided by env\n",
    "        action = select_action(state)\n",
    "        \n",
    "        # step the environment through the action\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        if render:\n",
    "            env.render()\n",
    "            \n",
    "        # append reward to policy's reward[] list   \n",
    "        policy.rewards.append(reward)\n",
    "        \n",
    "        # break if episode is done\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    running_reward = running_reward * 0.99 + t * 0.01   # calculate running reward\n",
    "    \n",
    "    # this is where the heavy lifting (back prop) is done \n",
    "    finish_episode()\n",
    "    \n",
    "    # print out and show sign of life\n",
    "    if i_episode % log_interval == 0:\n",
    "        print('Episode {}\\tLast length: {:5d}\\tAverage length: {:.2f}'.format(\n",
    "                i_episode, t, running_reward))\n",
    "    if running_reward > env.spec.reward_threshold:\n",
    "        print(\"Solved! Running reward is now {} and \"\n",
    "                  \"the last episode runs to {} time steps!\".format(running_reward, t))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Episode 50\tLast length:    28\tAverage length: 10.84\n",
      "Episode 100\tLast length:    42\tAverage length: 20.58\n",
      "Episode 150\tLast length:    72\tAverage length: 30.69\n",
      "Episode 200\tLast length:    40\tAverage length: 41.11\n",
      "Episode 250\tLast length:    74\tAverage length: 39.69\n",
      "Episode 300\tLast length:   132\tAverage length: 52.62\n",
      "Episode 350\tLast length:   108\tAverage length: 69.47\n",
      "Episode 400\tLast length:    85\tAverage length: 79.72\n",
      "Episode 450\tLast length:   171\tAverage length: 108.03\n",
      "Episode 500\tLast length:   199\tAverage length: 143.93\n",
      "Episode 550\tLast length:   199\tAverage length: 165.50\n",
      "Episode 600\tLast length:   199\tAverage length: 178.73\n",
      "Episode 650\tLast length:   199\tAverage length: 186.74\n",
      "Episode 700\tLast length:   124\tAverage length: 187.69\n",
      "Episode 750\tLast length:   199\tAverage length: 184.40\n",
      "Episode 800\tLast length:   199\tAverage length: 153.96\n",
      "Episode 850\tLast length:   107\tAverage length: 166.67\n",
      "Episode 900\tLast length:    70\tAverage length: 139.36\n",
      "Episode 950\tLast length:    59\tAverage length: 107.31\n",
      "Episode 1000\tLast length:    62\tAverage length: 98.70\n",
      "Episode 1050\tLast length:   123\tAverage length: 89.78\n",
      "Episode 1100\tLast length:    48\tAverage length: 86.80\n",
      "Episode 1150\tLast length:   153\tAverage length: 116.23\n",
      "Episode 1200\tLast length:    93\tAverage length: 98.70\n",
      "Episode 1250\tLast length:   114\tAverage length: 94.69\n",
      "Episode 1300\tLast length:   112\tAverage length: 106.76\n",
      "Episode 1350\tLast length:   124\tAverage length: 116.30\n",
      "Episode 1400\tLast length:   172\tAverage length: 136.08\n",
      "Episode 1450\tLast length:   190\tAverage length: 153.91\n",
      "Episode 1500\tLast length:   199\tAverage length: 171.19\n",
      "Episode 1550\tLast length:   199\tAverage length: 181.51\n",
      "Episode 1600\tLast length:   199\tAverage length: 188.38\n",
      "Episode 1650\tLast length:   199\tAverage length: 192.57\n",
      "Episode 1700\tLast length:   108\tAverage length: 178.75\n",
      "Episode 1750\tLast length:   110\tAverage length: 157.95\n",
      "Episode 1800\tLast length:   122\tAverage length: 139.46\n",
      "Episode 1850\tLast length:   199\tAverage length: 155.57\n",
      "Episode 1900\tLast length:   199\tAverage length: 172.72\n",
      "Episode 1950\tLast length:   199\tAverage length: 183.10\n",
      "Episode 2000\tLast length:   199\tAverage length: 188.97\n",
      "Episode 2050\tLast length:   199\tAverage length: 187.97\n",
      "Episode 2100\tLast length:   199\tAverage length: 189.72\n",
      "Episode 2150\tLast length:   199\tAverage length: 193.39\n",
      "Solved! Running reward is now 195.0102551491341 and the last episode runs to 199 time steps!\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import gym\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "gamma=0.99\n",
    "seed=543\n",
    "render=False\n",
    "log_interval=50\n",
    "verbose=False  # To step through the code and understand what is going on\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "env.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# A 2-layer NN with 128 hidden units\n",
    "class Policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        self.affine1 = nn.Linear(4, 128)\n",
    "        self.affine2 = nn.Linear(128, 2)\n",
    "\n",
    "        self.saved_log_probs = []\n",
    "        self.rewards = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.affine1(x))\n",
    "        action_scores = self.affine2(x)\n",
    "        return F.softmax(action_scores, dim=1)\n",
    "\n",
    "policy = Policy()\n",
    "optimizer = optim.Adam(policy.parameters(), lr=1e-2)\n",
    "\n",
    "def select_action(state):\n",
    "    state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "    probs = policy(Variable(state))\n",
    "    m = Categorical(probs)\n",
    "    action = m.sample()\n",
    "    policy.saved_log_probs.append(m.log_prob(action))\n",
    "    return action.data[0]\n",
    "\n",
    "\n",
    "def finish_episode():\n",
    "    R = 0\n",
    "    policy_loss = []\n",
    "    rewards = []\n",
    "    for r in policy.rewards[::-1]:\n",
    "        R = r + gamma * R\n",
    "        rewards.insert(0, R)\n",
    "    rewards = torch.Tensor(rewards)\n",
    "    rewards = (rewards - rewards.mean()) / (rewards.std() + np.finfo(np.float32).eps)\n",
    "    for log_prob, reward in zip(policy.saved_log_probs, rewards):\n",
    "        policy_loss.append(-log_prob * reward)\n",
    "    optimizer.zero_grad()\n",
    "    policy_loss = torch.cat(policy_loss).sum()\n",
    "    policy_loss.backward()\n",
    "    optimizer.step()\n",
    "    del policy.rewards[:]\n",
    "    del policy.saved_log_probs[:]\n",
    "\n",
    "\n",
    "# Main loop\n",
    "running_reward = 10\n",
    "for i_episode in count(1):\n",
    "    state = env.reset()\n",
    "    for t in range(10000):  # Don't infinite loop while learning\n",
    "        action = select_action(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        if render:\n",
    "            env.render()\n",
    "        policy.rewards.append(reward)\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    running_reward = running_reward * 0.99 + t * 0.01\n",
    "    finish_episode()\n",
    "    \n",
    "    if i_episode % log_interval == 0:\n",
    "        print('Episode {}\\tLast length: {:5d}\\tAverage length: {:.2f}'.format(\n",
    "                i_episode, t, running_reward))\n",
    "    if running_reward > env.spec.reward_threshold:\n",
    "        print(\"Solved! Running reward is now {} and \"\n",
    "                  \"the last episode runs to {} time steps!\".format(running_reward, t))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch - Policy Gradient on Pong\n",
    "\n",
    "Here we go now!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5144  0.4856\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6647\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5145  0.4855\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6645\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5118  0.4882\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6699\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5195  0.4805\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6548\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5099  0.4901\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6735\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5208  0.4792\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7357\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5155  0.4845\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7246\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5167  0.4833\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7271\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5107  0.4893\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7147\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5167  0.4833\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7270\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5220  0.4780\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6501\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5050  0.4950\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7032\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5216  0.4784\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6509\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5132  0.4868\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7199\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5178  0.4822\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6582\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5136  0.4864\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6663\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5150  0.4850\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6637\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5120  0.4880\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7174\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5182  0.4818\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7302\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5103  0.4897\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7140\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5214  0.4786\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6512\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5121  0.4879\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6692\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5137  0.4863\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7209\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5114  0.4886\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6706\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5169  0.4831\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7275\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5133  0.4867\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6668\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5181  0.4819\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6576\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5097  0.4903\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6740\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5207  0.4793\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7354\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5079  0.4921\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7090\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5213  0.4787\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6514\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5106  0.4894\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6722\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5179  0.4821\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6580\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5197  0.4803\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7334\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5135  0.4865\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7205\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5153  0.4847\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6631\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5063  0.4937\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7059\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5139  0.4861\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6658\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5185  0.4815\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7309\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5211  0.4789\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6519\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5146  0.4854\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6643\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5136  0.4864\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7207\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5171  0.4829\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6595\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6614\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5175  0.4825\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7287\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5099  0.4901\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7132\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5182  0.4818\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6573\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5020  0.4980\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6892\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5165  0.4835\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6608\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5100  0.4900\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7133\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5251  0.4749\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7446\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5191  0.4809\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6557\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5097  0.4903\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7127\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5112  0.4888\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6710\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5180  0.4820\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7297\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5184  0.4816\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6570\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5124  0.4876\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7182\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5099  0.4901\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7132\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5254  0.4746\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7453\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5153  0.4847\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6631\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5183  0.4817\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6572\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5121  0.4879\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7177\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5174  0.4826\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7286\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5214  0.4786\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7369\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5047  0.4953\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6837\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5122  0.4878\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6690\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5146  0.4854\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7228\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5117  0.4883\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7169\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5112  0.4888\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6710\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5181  0.4819\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6577\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5127  0.4873\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7189\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5248  0.4752\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7439\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5112  0.4888\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7159\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5178  0.4822\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6582\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5158  0.4842\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7252\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5146  0.4854\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6643\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5158  0.4842\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7252\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5183  0.4817\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7304\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5163  0.4837\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6611\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5120  0.4880\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6695\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5177  0.4823\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6584\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5100  0.4900\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6733\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5083  0.4917\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7099\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5063  0.4937\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6806\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7258\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5221  0.4779\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7383\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5120  0.4880\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6693\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5137  0.4863\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6660\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5061  0.4939\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6811\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5244  0.4756\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6454\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5121  0.4879\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6692\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5196  0.4804\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6548\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5156  0.4844\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6623\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5212  0.4788\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7366\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5130  0.4870\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6674\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5151  0.4849\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7238\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5202  0.4798\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6536\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5102  0.4898\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7137\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5223  0.4777\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6496\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5145  0.4855\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7226\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5171  0.4829\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7279\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5140  0.4860\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7215\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5182  0.4818\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7303\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5208  0.4792\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7357\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5085  0.4915\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6762\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5249  0.4751\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7443\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5118  0.4882\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6698\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5117  0.4883\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6701\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5113  0.4887\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7160\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5138  0.4862\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6660\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5170  0.4830\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6597\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5151  0.4849\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7238\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5194  0.4806\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6550\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5091  0.4909\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7114\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5125  0.4875\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7185\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5192  0.4808\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7323\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5140  0.4860\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7215\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5180  0.4820\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7297\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5114  0.4886\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6706\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5209  0.4791\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6521\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5105  0.4895\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6724\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5138  0.4862\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6660\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5243  0.4757\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7431\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5070  0.4930\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7073\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5175  0.4825\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6588\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5184  0.4816\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7306\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5137  0.4863\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7209\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5190  0.4810\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6559\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5170  0.4830\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6596\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5128  0.4872\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7192\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5115  0.4885\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6704\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5093  0.4907\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6747\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5154  0.4846\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7244\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5192  0.4808\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7323\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5184  0.4816\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6570\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5218  0.4782\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7376\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5141  0.4859\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6653\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5097  0.4903\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6739\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5158  0.4842\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7252\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5157  0.4843\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7250\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5153  0.4847\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7243\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5093  0.4907\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7118\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5173  0.4827\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6591\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5119  0.4881\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7173\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5147  0.4853\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6643\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5210  0.4790\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7361\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5145  0.4855\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7225\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5038  0.4962\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6855\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5192  0.4808\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6555\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5092  0.4908\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6748\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5162  0.4838\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6612\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5179  0.4821\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6580\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5154  0.4846\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7244\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5168  0.4832\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7273\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5137  0.4863\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7208\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5040  0.4960\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7012\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5211  0.4789\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6519\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5111  0.4889\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6712\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5085  0.4915\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7104\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5151  0.4849\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7238\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5197  0.4803\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6545\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5185  0.4815\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7309\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5088  0.4912\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6757\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5172  0.4828\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6593\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5126  0.4874\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7186\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5055  0.4945\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6822\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5148  0.4852\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7232\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5215  0.4785\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6511\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5153  0.4847\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7243\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5142  0.4858\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7219\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5190  0.4810\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6558\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5105  0.4895\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7143\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5171  0.4829\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6596\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5126  0.4874\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6683\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5196  0.4804\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7332\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5214  0.4786\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6512\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5145  0.4855\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7225\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5177  0.4823\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7291\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5136  0.4864\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6663\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5148  0.4852\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7232\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5142  0.4858\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6651\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5103  0.4897\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6728\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5104  0.4896\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7141\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5128  0.4872\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6680\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5125  0.4875\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6685\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5173  0.4827\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7284\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5124  0.4876\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6687\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5116  0.4884\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7166\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5210  0.4790\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6520\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5085  0.4915\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6763\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5201  0.4799\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6537\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5121  0.4879\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7177\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5165  0.4835\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7268\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5130  0.4870\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7196\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5183  0.4817\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7305\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5189  0.4811\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7317\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5162  0.4838\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7261\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5132  0.4868\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7200\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5162  0.4838\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6614\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5157  0.4843\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6622\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5175  0.4825\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7288\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5199  0.4801\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6541\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5167  0.4833\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7271\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5153  0.4847\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6631\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5130  0.4870\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7194\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5155  0.4845\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6625\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5113  0.4887\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7161\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5189  0.4811\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6560\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5143  0.4857\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6650\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5053  0.4947\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6826\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5202  0.4798\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6535\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5183  0.4817\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6571\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5191  0.4809\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6556\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5119  0.4881\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7173\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5080  0.4920\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6772\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5158  0.4842\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6621\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5179  0.4821\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7296\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5201  0.4799\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7341\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5102  0.4898\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7137\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5195  0.4805\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7329\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5126  0.4874\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6682\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5196  0.4804\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7331\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5070  0.4930\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7072\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5165  0.4835\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6606\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5122  0.4878\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6689\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5164  0.4836\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7264\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5162  0.4838\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7261\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5220  0.4780\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6501\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5123  0.4877\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6688\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5178  0.4822\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6582\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5142  0.4858\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6652\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5134  0.4866\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7202\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5145  0.4855\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7226\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5223  0.4777\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7387\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5119  0.4881\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6696\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5239  0.4761\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6464\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5086  0.4914\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7105\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5248  0.4752\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7440\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5067  0.4933\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7067\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5196  0.4804\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7331\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5112  0.4888\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7159\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5181  0.4819\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7300\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5106  0.4894\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6723\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5081  0.4919\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7095\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5191  0.4809\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7322\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5159  0.4841\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7255\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5187  0.4813\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7313\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5100  0.4900\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7133\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5164  0.4836\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6609\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5165  0.4835\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6606\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5099  0.4901\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6736\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5114  0.4886\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6706\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5269  0.4731\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6407\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5108  0.4892\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7149\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5136  0.4864\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7208\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5158  0.4842\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7253\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5075  0.4925\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6783\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5115  0.4885\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7165\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5101  0.4899\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6732\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5171  0.4829\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6596\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5184  0.4816\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7306\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5196  0.4804\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6547\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5163  0.4837\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7264\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5156  0.4844\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7248\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5135  0.4865\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6665\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5123  0.4877\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7181\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5194  0.4806\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6551\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5151  0.4849\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6635\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5098  0.4902\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6738\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5223  0.4777\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6495\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5073  0.4927\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6787\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5192  0.4808\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7324\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5145  0.4855\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7226\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5209  0.4791\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7359\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5061  0.4939\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6811\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5153  0.4847\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6630\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5204  0.4796\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6532\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5179  0.4821\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6580\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5142  0.4858\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7220\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5099  0.4901\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6734\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5160  0.4840\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7257\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5156  0.4844\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7248\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5168  0.4832\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7272\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5186  0.4814\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7311\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5171  0.4829\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7280\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5059  0.4941\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6814\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5163  0.4837\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7263\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5137  0.4863\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6660\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5141  0.4859\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6653\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5260  0.4740\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7466\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5141  0.4859\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6654\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5145  0.4855\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6645\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5021  0.4979\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6889\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5224  0.4776\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6493\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5141  0.4859\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7218\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5157  0.4843\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6623\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5140  0.4860\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7216\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5189  0.4811\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6560\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5158  0.4842\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6620\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5136  0.4864\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6664\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5120  0.4880\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7174\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5149  0.4851\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6638\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5156  0.4844\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6624\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5131  0.4869\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7197\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5168  0.4832\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7273\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5172  0.4828\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7282\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5203  0.4797\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6533\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5148  0.4852\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6641\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5190  0.4810\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6558\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5159  0.4841\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7255\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5128  0.4872\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6678\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5185  0.4815\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7309\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5090  0.4910\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7113\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5153  0.4847\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6630\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5198  0.4802\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7336\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5167  0.4833\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7271\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5197  0.4803\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7334\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5066  0.4934\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7065\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5239  0.4761\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6464\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5159  0.4841\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7255\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5189  0.4811\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7317\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5170  0.4830\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7277\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5025  0.4975\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6982\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5105  0.4895\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6724\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5140  0.4860\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7216\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5109  0.4891\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6715\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5155  0.4845\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7246\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5135  0.4865\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6664\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5179  0.4821\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7297\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5138  0.4862\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7211\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5168  0.4832\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6601\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5113  0.4887\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6708\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5145  0.4855\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6646\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5128  0.4872\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7190\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5124  0.4876\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6686\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5169  0.4831\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6598\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5171  0.4829\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6595\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5226  0.4774\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7394\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5172  0.4828\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6592\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5148  0.4852\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7232\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5094  0.4906\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6745\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5146  0.4854\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6644\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5141  0.4859\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6654\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5176  0.4824\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7289\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5053  0.4947\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7038\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5195  0.4805\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6548\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5134  0.4866\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7203\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5142  0.4858\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7220\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5240  0.4760\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6463\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5144  0.4856\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7225\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5132  0.4868\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6671\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5178  0.4822\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7295\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5074  0.4926\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6785\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5223  0.4777\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6495\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5151  0.4849\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7238\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5051  0.4949\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7034\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5200  0.4800\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7339\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5188  0.4812\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7315\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5196  0.4804\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7332\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5129  0.4871\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6677\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5098  0.4902\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7129\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5134  0.4866\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6668\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5142  0.4858\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7220\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5124  0.4876\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6687\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5220  0.4780\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7380\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5129  0.4871\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6676\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5170  0.4830\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6596\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5164  0.4836\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7265\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5113  0.4887\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6709\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5089  0.4911\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6755\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5102  0.4898\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7137\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5210  0.4790\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7361\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5174  0.4826\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7286\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5173  0.4827\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7285\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5190  0.4810\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7318\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5057  0.4943\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7046\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5199  0.4801\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7337\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5125  0.4875\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6685\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5073  0.4927\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7079\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5121  0.4879\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6692\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5230  0.4770\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6481\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5160  0.4840\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7257\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5245  0.4755\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6453\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5167  0.4833\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6604\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5141  0.4859\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7218\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5155  0.4845\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6626\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5141  0.4859\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6653\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5163  0.4837\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6610\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5095  0.4905\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6743\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5126  0.4874\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7187\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5145  0.4855\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7225\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5159  0.4841\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6619\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5168  0.4832\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6602\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5149  0.4851\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6637\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5124  0.4876\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7182\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5171  0.4829\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7279\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5131  0.4869\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7197\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5240  0.4760\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7423\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5144  0.4856\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7225\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5101  0.4899\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6732\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5217  0.4783\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7376\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5106  0.4894\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7147\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5167  0.4833\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6603\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5186  0.4814\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7310\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5085  0.4915\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6763\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5164  0.4836\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7266\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5129  0.4871\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7192\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5210  0.4790\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7360\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5171  0.4829\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7279\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5139  0.4861\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7212\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5099  0.4901\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6735\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5121  0.4879\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6693\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5177  0.4823\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6585\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5150  0.4850\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6637\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5207  0.4793\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7354\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5108  0.4892\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7151\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5149  0.4851\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7235\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5129  0.4871\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6678\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5100  0.4900\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7134\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5222  0.4778\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7386\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5090  0.4910\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6754\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5162  0.4838\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7260\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5156  0.4844\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6624\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5173  0.4827\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7283\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5118  0.4882\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6699\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5150  0.4850\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6636\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5137  0.4863\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6661\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5081  0.4919\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7094\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5212  0.4788\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7366\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5057  0.4943\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6818\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5158  0.4842\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6620\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5168  0.4832\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7273\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5193  0.4807\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7324\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5084  0.4916\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6765\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5232  0.4768\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7406\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6614\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5097  0.4903\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7128\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5132  0.4868\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7198\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5158  0.4842\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7253\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5150  0.4850\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6636\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5140  0.4860\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6655\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5182  0.4818\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7303\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5141  0.4859\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6653\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5172  0.4828\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7282\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5129  0.4871\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7194\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5184  0.4816\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6570\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5148  0.4852\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7232\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5137  0.4863\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7210\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5124  0.4876\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6687\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5133  0.4867\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6669\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5276  0.4724\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7498\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5130  0.4870\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7195\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5148  0.4852\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6640\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5149  0.4851\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7233\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5133  0.4867\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6669\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5172  0.4828\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7281\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5123  0.4877\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6688\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5241  0.4759\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7426\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5073  0.4927\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6787\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5176  0.4824\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6586\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5124  0.4876\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6686\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5166  0.4834\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6606\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5121  0.4879\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7176\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5081  0.4919\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6771\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5168  0.4832\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6601\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5171  0.4829\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7279\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5167  0.4833\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6604\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5166  0.4834\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7269\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5065  0.4935\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7061\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5250  0.4750\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7445\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5181  0.4819\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6576\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5099  0.4901\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7132\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5124  0.4876\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6687\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5137  0.4863\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6661\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5159  0.4841\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7254\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5147  0.4853\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6641\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5119  0.4881\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6696\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5167  0.4833\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6602\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5153  0.4847\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6630\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5046  0.4954\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7024\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5172  0.4828\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6593\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5203  0.4797\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7345\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5110  0.4890\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7155\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5121  0.4879\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6692\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5158  0.4842\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6620\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5177  0.4823\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6583\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5093  0.4907\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6748\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5223  0.4777\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7387\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5217  0.4783\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7376\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5132  0.4868\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7200\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5164  0.4836\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7265\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5099  0.4901\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7131\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5236  0.4764\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6470\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5140  0.4860\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6655\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5089  0.4911\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6756\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5211  0.4789\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7362\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5079  0.4921\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7091\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5164  0.4836\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6609\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5178  0.4822\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6583\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5149  0.4851\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7235\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5183  0.4817\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6572\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5152  0.4848\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6632\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5237  0.4763\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6469\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5102  0.4898\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6730\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5132  0.4868\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6671\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5138  0.4862\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7211\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5144  0.4856\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6647\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5189  0.4811\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7316\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5157  0.4843\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7250\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5137  0.4863\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6662\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5204  0.4796\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6532\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5152  0.4848\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7240\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5170  0.4830\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6596\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5138  0.4862\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6659\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5153  0.4847\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6630\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5155  0.4845\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7247\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5159  0.4841\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7255\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5135  0.4865\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6665\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5188  0.4812\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6563\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5144  0.4856\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6648\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5180  0.4820\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6578\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5166  0.4834\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7270\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5108  0.4892\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6719\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5145  0.4855\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7226\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5163  0.4837\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6611\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5154  0.4846\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7244\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5192  0.4808\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6556\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5160  0.4840\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6616\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5195  0.4805\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7329\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5147  0.4853\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6642\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5149  0.4851\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6638\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5199  0.4801\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6541\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5153  0.4847\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6630\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5131  0.4869\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6672\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5190  0.4810\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7319\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5142  0.4858\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7219\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5209  0.4791\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6522\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5130  0.4870\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7196\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5140  0.4860\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7216\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5175  0.4825\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6587\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5115  0.4885\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7164\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5124  0.4876\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7184\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5201  0.4799\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6537\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5140  0.4860\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7215\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5179  0.4821\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6580\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5143  0.4857\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7223\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5219  0.4781\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7379\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5071  0.4929\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6791\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5142  0.4858\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7219\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5113  0.4887\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7160\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5174  0.4826\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6590\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5118  0.4882\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6697\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5181  0.4819\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7301\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5048  0.4952\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6836\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5244  0.4756\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6455\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5152  0.4848\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6632\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5056  0.4944\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7044\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5168  0.4832\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7272\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5227  0.4773\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7395\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5110  0.4890\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6714\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5276  0.4724\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7499\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5155  0.4845\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7247\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5147  0.4853\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6641\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5076  0.4924\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7085\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5199  0.4801\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7337\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5119  0.4881\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7172\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5123  0.4877\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7180\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5125  0.4875\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6684\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5133  0.4867\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7202\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5154  0.4846\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7245\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5207  0.4793\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7355\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5124  0.4876\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6686\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7260\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5122  0.4878\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6690\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5252  0.4748\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7448\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5088  0.4912\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6756\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5100  0.4900\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6733\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5140  0.4860\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7216\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5078  0.4922\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6776\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5154  0.4846\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7244\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5131  0.4869\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6672\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5187  0.4813\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6564\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5065  0.4935\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7062\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5130  0.4870\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6675\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5128  0.4872\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6678\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5255  0.4745\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7455\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5180  0.4820\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6577\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5132  0.4868\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7199\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5045  0.4955\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7021\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5156  0.4844\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6624\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5224  0.4776\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7390\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5174  0.4826\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7287\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5156  0.4844\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7249\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5153  0.4847\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6630\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5154  0.4846\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7245\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5123  0.4877\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6689\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5156  0.4844\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7248\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5118  0.4882\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7169\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5177  0.4823\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7292\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5195  0.4805\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6550\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5150  0.4850\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6637\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5191  0.4809\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7321\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5122  0.4878\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6691\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5152  0.4848\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7241\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5129  0.4871\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7193\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5176  0.4824\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6585\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5116  0.4884\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7166\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5180  0.4820\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6578\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5137  0.4863\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6661\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5202  0.4798\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7343\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5162  0.4838\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6613\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5155  0.4845\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7246\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5152  0.4848\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7240\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5117  0.4883\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7168\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5180  0.4820\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6578\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5169  0.4831\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7276\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5175  0.4825\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6587\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5156  0.4844\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7248\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5166  0.4834\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6605\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5176  0.4824\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7290\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5169  0.4831\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7275\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5145  0.4855\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7226\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5163  0.4837\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7262\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5166  0.4834\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6605\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5167  0.4833\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6604\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5176  0.4824\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6586\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5127  0.4873\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6680\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5195  0.4805\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7329\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5133  0.4867\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7201\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5146  0.4854\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6643\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5175  0.4825\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7289\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5081  0.4919\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7094\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5195  0.4805\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6549\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5166  0.4834\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7268\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5218  0.4782\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7377\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5138  0.4862\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7212\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5091  0.4909\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6752\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5186  0.4814\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7310\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5159  0.4841\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6619\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5117  0.4883\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6700\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5150  0.4850\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6635\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5170  0.4830\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7278\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5177  0.4823\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7293\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5118  0.4882\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6698\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5135  0.4865\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7206\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5138  0.4862\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7211\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5070  0.4930\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6793\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5205  0.4795\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7351\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5134  0.4866\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6667\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5199  0.4801\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7338\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5176  0.4824\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7289\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5140  0.4860\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7215\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5158  0.4842\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7252\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5189  0.4811\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6560\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5135  0.4865\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7205\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5150  0.4850\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7237\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5143  0.4857\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6650\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5167  0.4833\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7272\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5126  0.4874\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7188\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5168  0.4832\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7273\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5172  0.4828\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7282\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5156  0.4844\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7248\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5166  0.4834\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7269\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5176  0.4824\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7290\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5173  0.4827\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6592\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5160  0.4840\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6616\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5192  0.4808\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6555\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5123  0.4877\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6688\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5110  0.4890\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6714\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5230  0.4770\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7403\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5119  0.4881\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6697\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5166  0.4834\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6605\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5099  0.4901\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6736\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5158  0.4842\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7253\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5127  0.4873\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6680\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5183  0.4817\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7304\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5204  0.4796\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6532\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5157  0.4843\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7250\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5139  0.4861\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6657\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5126  0.4874\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6683\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5237  0.4763\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6468\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5094  0.4906\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7121\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5226  0.4774\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6490\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5145  0.4855\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7226\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5259  0.4741\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6427\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5134  0.4866\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6666\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5157  0.4843\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7250\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5148  0.4852\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7232\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5149  0.4851\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7234\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5155  0.4845\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6626\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5081  0.4919\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7095\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5132  0.4868\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6671\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5203  0.4797\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7346\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5213  0.4787\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6514\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5167  0.4833\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6603\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5100  0.4900\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6733\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5083  0.4917\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7100\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5170  0.4830\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6597\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5115  0.4885\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6705\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5233  0.4767\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6476\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5126  0.4874\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7186\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5152  0.4848\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6631\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5104  0.4896\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6726\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5175  0.4825\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6587\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5192  0.4808\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6554\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5154  0.4846\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7244\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5139  0.4861\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6657\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5126  0.4874\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6683\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5163  0.4837\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7263\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5152  0.4848\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7239\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5190  0.4810\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6559\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5121  0.4880\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7175\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5096  0.4904\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7126\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5209  0.4791\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6522\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5170  0.4830\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6598\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5196  0.4804\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7331\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5211  0.4789\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6518\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5163  0.4837\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7263\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5127  0.4873\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7189\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5147  0.4853\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6643\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5110  0.4890\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6713\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5117  0.4883\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7168\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5143  0.4857\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7222\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5160  0.4840\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7256\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5195  0.4805\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6548\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5147  0.4853\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6641\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5171  0.4829\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7280\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5184  0.4816\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7306\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5167  0.4833\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6604\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5103  0.4897\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7139\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5174  0.4826\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6590\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5165  0.4835\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7268\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5173  0.4827\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6591\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5139  0.4861\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6657\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5176  0.4824\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6585\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5086  0.4914\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6761\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5113  0.4887\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6708\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5057  0.4943\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6818\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5123  0.4877\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6688\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5186  0.4814\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6567\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5179  0.4821\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7297\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5150  0.4850\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6636\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5148  0.4852\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7231\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5164  0.4836\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7265\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5172  0.4828\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6594\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5154  0.4846\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6629\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5208  0.4792\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6523\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is softmax output from NN: Variable containing:\n",
      " 0.5142  0.4858\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6651\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5147  0.4853\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6642\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5147  0.4853\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6641\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5164  0.4836\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6609\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5154  0.4846\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6628\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5121  0.4879\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7177\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5163  0.4837\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7263\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5179  0.4821\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6580\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5179  0.4821\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7297\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5181  0.4819\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6576\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5150  0.4850\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7237\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5160  0.4840\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6617\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5126  0.4874\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7187\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5153  0.4847\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6630\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5142  0.4858\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7220\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5140  0.4860\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7216\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5229  0.4771\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6483\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5186  0.4814\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6566\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5179  0.4821\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6580\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5099  0.4901\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7132\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5168  0.4832\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6602\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5118  0.4882\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6698\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5140  0.4860\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6656\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5182  0.4818\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7303\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5181  0.4819\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7301\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5173  0.4827\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7285\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5208  0.4792\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6524\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5112  0.4888\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6709\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5131  0.4869\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6673\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5133  0.4867\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6669\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5117  0.4883\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7168\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5142  0.4858\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6651\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5181  0.4819\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6575\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5170  0.4830\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7278\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5128  0.4872\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7192\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5180  0.4820\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7298\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5181  0.4819\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6575\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5106  0.4894\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6721\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5213  0.4787\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6513\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5166  0.4834\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7269\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5167  0.4833\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7272\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5148  0.4852\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7232\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5109  0.4891\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6716\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5183  0.4817\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6572\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5145  0.4855\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6646\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5196  0.4804\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7331\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5102  0.4898\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6730\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5209  0.4791\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7359\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5183  0.4817\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7305\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5152  0.4848\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7239\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5092  0.4908\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7117\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5126  0.4874\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7188\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5111  0.4889\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7156\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5192  0.4808\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6554\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5173  0.4827\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6592\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5154  0.4846\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6627\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5150  0.4850\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6637\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5115  0.4885\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7165\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5135  0.4865\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6665\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5145  0.4855\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7226\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5163  0.4837\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7263\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5147  0.4853\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7229\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5168  0.4832\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6601\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5157  0.4843\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7250\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5193  0.4807\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7326\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5091  0.4909\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7115\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5207  0.4793\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6526\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5152  0.4848\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7240\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5119  0.4881\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6696\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5159  0.4841\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7254\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5154  0.4846\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7245\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5154  0.4846\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6629\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5190  0.4810\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7320\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5128  0.4872\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7191\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5185  0.4815\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7308\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5181  0.4819\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6575\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5120  0.4880\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7173\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5142  0.4858\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6652\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5112  0.4888\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7157\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5150  0.4850\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6635\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5146  0.4854\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7228\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5172  0.4828\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7282\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5235  0.4765\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6471\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5145  0.4855\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7225\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5176  0.4824\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7291\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5089  0.4911\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7111\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5192  0.4808\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7323\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5166  0.4834\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6605\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5136  0.4864\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7207\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5191  0.4809\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7321\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5149  0.4851\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7234\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5140  0.4860\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7216\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5168  0.4832\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6600\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5175  0.4825\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6587\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5114  0.4886\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6706\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5178  0.4822\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7294\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5092  0.4908\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7116\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5217  0.4783\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7376\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5184  0.4816\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6569\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5120  0.4880\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6694\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5163  0.4837\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6611\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5117  0.4883\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6700\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5249  0.4751\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6445\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5150  0.4850\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6636\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5141  0.4859\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7217\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5160  0.4840\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6617\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5151  0.4849\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6633\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5104  0.4896\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7141\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5181  0.4819\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6576\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5162  0.4838\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7261\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5181  0.4819\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6576\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5169  0.4831\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6598\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5113  0.4887\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7161\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5123  0.4877\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7181\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5192  0.4808\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6555\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5115  0.4885\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6704\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5120  0.4880\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6694\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5137  0.4863\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6662\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5122  0.4878\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6690\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5194  0.4806\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7328\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5231  0.4769\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6479\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5113  0.4887\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7159\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5166  0.4834\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6604\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5176  0.4824\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6586\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5045  0.4955\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7022\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5183  0.4817\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6572\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5235  0.4765\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6472\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5007  0.4993\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6918\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5266  0.4734\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6414\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5142  0.4858\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6652\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5120  0.4880\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7174\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5155  0.4845\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7247\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5145  0.4855\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6646\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5116  0.4884\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7166\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5159  0.4841\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7254\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5206  0.4794\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6529\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5111  0.4889\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6712\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5183  0.4817\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7305\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5114  0.4886\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6706\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5238  0.4762\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7420\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5098  0.4902\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7129\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5180  0.4820\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6578\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5187  0.4813\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7314\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5036  0.4964\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6859\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5163  0.4837\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7262\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5329  0.4671\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7612\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5129  0.4871\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7192\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5077  0.4923\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6779\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5184  0.4816\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7306\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5190  0.4810\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6559\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5148  0.4852\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7232\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5200  0.4800\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6540\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5207  0.4793\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6527\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5144  0.4856\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6647\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5166  0.4834\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6605\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5132  0.4868\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7199\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5132  0.4868\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7199\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5113  0.4887\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7159\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5192  0.4808\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7322\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5186  0.4814\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6566\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5208  0.4792\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7356\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5158  0.4842\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7252\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5119  0.4881\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7173\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5129  0.4871\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6677\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5118  0.4882\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7170\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5214  0.4786\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6511\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5142  0.4858\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7219\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5158  0.4842\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6620\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5189  0.4811\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6560\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5158  0.4842\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7252\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5197  0.4803\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7332\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5091  0.4909\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7116\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5175  0.4825\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7288\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5132  0.4868\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7198\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5067  0.4933\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6799\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5229  0.4771\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7400\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5144  0.4856\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7223\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5214  0.4786\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7369\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5183  0.4817\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7305\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5141  0.4859\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6653\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5158  0.4842\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6620\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5100  0.4900\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6734\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5160  0.4840\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6617\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5172  0.4828\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6594\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5122  0.4878\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6691\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5200  0.4800\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7339\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5121  0.4879\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7177\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5147  0.4853\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7230\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5177  0.4823\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6584\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5123  0.4877\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6689\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5186  0.4814\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6567\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5096  0.4904\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7126\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5164  0.4836\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6609\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6614\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5168  0.4832\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7273\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5222  0.4778\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7386\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5106  0.4894\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7146\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5136  0.4864\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6663\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5146  0.4854\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7227\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5137  0.4863\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6661\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5155  0.4845\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6627\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5179  0.4821\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7297\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5158  0.4842\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6621\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5149  0.4851\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7233\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5181  0.4819\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6575\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5111  0.4889\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6711\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5108  0.4892\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7150\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5125  0.4875\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7185\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5180  0.4820\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6577\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5126  0.4874\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6683\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5180  0.4820\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7298\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5172  0.4828\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7282\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5187  0.4813\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7313\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5105  0.4895\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7143\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5185  0.4815\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6569\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5133  0.4867\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7201\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5162  0.4838\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7261\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5109  0.4891\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7152\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5194  0.4806\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6550\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5140  0.4860\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6655\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5166  0.4834\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7269\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5151  0.4849\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6634\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5128  0.4872\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7190\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5241  0.4759\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6460\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5128  0.4872\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7192\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5150  0.4850\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7236\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5102  0.4898\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7137\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5168  0.4832\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6601\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5226  0.4774\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7395\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5093  0.4907\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7119\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5196  0.4804\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6547\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5069  0.4931\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7070\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5175  0.4825\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7288\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5146  0.4854\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6643\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5148  0.4852\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7231\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is softmax output from NN: Variable containing:\n",
      " 0.5085  0.4915\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7103\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5199  0.4801\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6541\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5223  0.4777\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7388\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5174  0.4826\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7285\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5094  0.4906\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6746\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5119  0.4881\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7173\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5065  0.4935\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7062\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5155  0.4845\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7246\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5165  0.4835\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7267\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5163  0.4837\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7264\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5172  0.4828\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6594\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5152  0.4848\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6631\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5208  0.4792\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7356\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5168  0.4832\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6601\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5108  0.4892\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7149\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5136  0.4864\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6663\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5240  0.4760\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6463\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5140  0.4860\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7215\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5100  0.4900\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7133\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5294  0.4706\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7537\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5113  0.4887\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7160\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5166  0.4834\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6605\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5160  0.4840\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6616\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5160  0.4840\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7257\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5129  0.4871\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6677\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5198  0.4802\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7335\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5166  0.4834\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7269\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5165  0.4835\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6607\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5137  0.4863\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6662\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5166  0.4834\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7270\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5166  0.4834\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6605\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5165  0.4835\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6607\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5205  0.4795\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6529\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5127  0.4873\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6681\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5115  0.4885\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7164\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5184  0.4816\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7306\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5147  0.4853\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6642\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6614\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5054  0.4946\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7041\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5134  0.4866\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6667\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5162  0.4838\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6613\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5151  0.4849\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6633\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5087  0.4913\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6760\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5169  0.4831\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6599\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5087  0.4913\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7107\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5224  0.4776\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6493\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5094  0.4906\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7121\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5139  0.4861\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7213\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5155  0.4845\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7247\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5172  0.4828\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6592\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5160  0.4840\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6617\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5227  0.4773\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6488\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5137  0.4863\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7210\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5127  0.4873\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6681\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5106  0.4894\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6722\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5153  0.4847\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6630\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5172  0.4828\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6593\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5184  0.4816\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6571\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5152  0.4848\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6633\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5147  0.4853\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6643\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5132  0.4868\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6670\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5157  0.4843\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6623\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5123  0.4877\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6689\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5179  0.4821\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6579\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5169  0.4831\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6598\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5174  0.4826\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7285\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5186  0.4814\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6566\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5165  0.4835\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7267\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5173  0.4827\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6592\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5167  0.4833\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7272\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5145  0.4855\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7226\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5170  0.4830\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7277\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5131  0.4869\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6673\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5180  0.4820\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6578\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5151  0.4849\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6634\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5215  0.4785\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7370\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5135  0.4865\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7205\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5135  0.4865\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6665\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5211  0.4789\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7362\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5188  0.4812\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6563\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5146  0.4854\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6643\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5171  0.4829\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6595\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5090  0.4910\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7113\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5187  0.4813\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7313\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5160  0.4840\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7256\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5193  0.4807\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7324\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5053  0.4947\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6826\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5141  0.4859\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7218\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5121  0.4879\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7176\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5189  0.4811\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7316\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5063  0.4937\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6806\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5234  0.4766\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6474\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5093  0.4907\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6748\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5198  0.4802\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6543\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5204  0.4796\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6532\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5062  0.4938\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7056\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5197  0.4803\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7334\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5140  0.4860\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7216\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5180  0.4820\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7298\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5057  0.4943\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6818\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5174  0.4826\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7285\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5152  0.4848\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6631\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5156  0.4844\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6623\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5109  0.4891\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6716\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5169  0.4831\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7276\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5200  0.4800\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6539\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5050  0.4950\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6833\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5212  0.4788\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7364\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5156  0.4844\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6623\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5116  0.4884\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6701\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5194  0.4806\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7327\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5051  0.4949\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6830\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5215  0.4785\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7370\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5148  0.4852\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6640\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5183  0.4817\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6573\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5142  0.4858\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7219\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5128  0.4872\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6678\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5186  0.4814\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7310\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5197  0.4803\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7333\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5159  0.4841\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6618\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5204  0.4796\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7348\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5184  0.4816\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6571\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5124  0.4876\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6687\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5193  0.4807\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7325\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5122  0.4878\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7178\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5090  0.4910\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7113\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5188  0.4812\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7314\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5131  0.4869\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7196\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5140  0.4860\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7215\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5023  0.4977\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6886\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5193  0.4807\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6553\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5164  0.4836\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7266\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5167  0.4833\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7270\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5224  0.4776\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7389\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5145  0.4855\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7225\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5120  0.4880\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7174\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5133  0.4867\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7200\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5183  0.4817\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7305\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5139  0.4861\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7214\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5149  0.4851\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7234\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5154  0.4846\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7245\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5152  0.4848\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6631\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5182  0.4818\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7301\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5146  0.4854\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7228\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5199  0.4801\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6542\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5120  0.4880\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6695\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5107  0.4893\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7148\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5086  0.4914\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6761\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5185  0.4815\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6569\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5167  0.4833\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7271\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5176  0.4824\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6586\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5126  0.4874\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7187\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5154  0.4846\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7245\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5121  0.4879\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6692\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5242  0.4758\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7427\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5150  0.4850\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6636\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5111  0.4889\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7156\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5167  0.4833\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7270\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5166  0.4834\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7269\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5160  0.4840\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7257\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5156  0.4844\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6624\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5164  0.4836\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7265\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5149  0.4851\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6638\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5128  0.4872\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6678\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5124  0.4876\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6687\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5180  0.4820\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6578\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5087  0.4913\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6759\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5069  0.4931\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7071\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5184  0.4816\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7305\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5136  0.4864\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6664\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5172  0.4828\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6593\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5117  0.4883\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7168\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5110  0.4890\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6714\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5132  0.4868\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7198\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5126  0.4874\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7187\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5149  0.4851\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6637\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5152  0.4848\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6633\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5147  0.4853\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7230\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5162  0.4838\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7260\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5153  0.4847\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7242\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5089  0.4911\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7110\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5209  0.4791\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6523\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5109  0.4891\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6717\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5178  0.4822\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7294\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5117  0.4883\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6700\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5126  0.4874\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7186\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5163  0.4837\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7262\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5182  0.4818\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6575\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5219  0.4781\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6503\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5078  0.4922\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6776\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5223  0.4777\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6495\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5092  0.4908\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7117\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5129  0.4871\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6676\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5116  0.4884\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6701\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5170  0.4830\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7277\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5131  0.4869\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7198\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5169  0.4831\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7275\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5125  0.4875\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7185\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5186  0.4814\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6567\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5148  0.4852\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6640\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5130  0.4870\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7194\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5143  0.4857\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7221\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5150  0.4850\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7235\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5137  0.4863\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6660\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5071  0.4929\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7075\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5174  0.4826\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7286\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5122  0.4878\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7179\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5174  0.4826\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6590\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5150  0.4850\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7235\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5164  0.4836\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6608\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5160  0.4840\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7258\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6614\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5146  0.4854\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7228\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5172  0.4828\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7282\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5162  0.4838\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6613\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5072  0.4928\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7077\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5216  0.4784\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7374\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5170  0.4830\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7278\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5134  0.4866\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7203\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5146  0.4854\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7227\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5119  0.4881\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7173\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5131  0.4869\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6672\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5107  0.4893\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6719\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5148  0.4852\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6640\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5171  0.4829\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6595\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5164  0.4836\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7265\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5220  0.4780\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6502\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5164  0.4836\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7266\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5112  0.4888\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6710\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5067  0.4933\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7067\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5171  0.4829\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7279\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5087  0.4913\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7107\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5210  0.4790\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6520\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5148  0.4852\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7233\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5134  0.4866\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6666\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5124  0.4876\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6687\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5242  0.4758\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6458\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5149  0.4851\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6638\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5125  0.4875\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7184\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5164  0.4836\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6608\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5151  0.4849\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7238\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5128  0.4872\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7190\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5200  0.4800\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6539\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5130  0.4870\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7196\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5180  0.4820\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6578\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5183  0.4817\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7304\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5135  0.4865\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6664\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5180  0.4820\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7299\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5132  0.4868\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7200\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5188  0.4812\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7315\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5146  0.4854\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6643\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5114  0.4886\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7162\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5132  0.4868\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7200\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5121  0.4879\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6692\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5188  0.4812\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7314\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5174  0.4826\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6589\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5194  0.4806\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6551\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5124  0.4876\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7182\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5076  0.4924\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7084\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5245  0.4755\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6453\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5147  0.4853\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6642\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5117  0.4883\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7168\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5134  0.4866\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6666\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5168  0.4832\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7273\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5197  0.4803\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6545\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5177  0.4823\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7293\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5196  0.4804\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6548\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5140  0.4860\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6655\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5111  0.4889\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7156\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5116  0.4884\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6702\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5119  0.4881\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6697\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5104  0.4896\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6726\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5144  0.4856\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7224\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5217  0.4783\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7375\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5085  0.4915\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6762\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5130  0.4870\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6675\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5148  0.4852\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6639\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5070  0.4930\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6793\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5233  0.4767\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6476\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5181  0.4819\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6575\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5157  0.4843\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6622\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5152  0.4848\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7239\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5142  0.4858\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7219\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5144  0.4856\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6647\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5194  0.4806\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6551\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5151  0.4849\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7238\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5140  0.4860\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6656\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5123  0.4877\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6689\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5179  0.4821\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7297\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5178  0.4822\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6581\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5185  0.4815\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7309\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5190  0.4810\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7319\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5155  0.4845\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6626\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5198  0.4802\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6543\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5149  0.4851\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6637\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5142  0.4858\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6651\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5122  0.4878\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7177\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5186  0.4814\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7311\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is softmax output from NN: Variable containing:\n",
      " 0.5210  0.4790\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7360\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5070  0.4930\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7072\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5211  0.4789\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7363\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5133  0.4867\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6669\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5157  0.4843\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6623\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5078  0.4922\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7089\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5064  0.4936\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7059\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5172  0.4828\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7282\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5287  0.4713\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7522\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5101  0.4899\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6732\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5153  0.4847\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6630\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5120  0.4880\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6694\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5071  0.4929\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6790\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5118  0.4882\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7171\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5164  0.4836\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7266\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5160  0.4840\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6616\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5149  0.4851\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6639\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5218  0.4782\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6505\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5088  0.4912\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7109\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5151  0.4849\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7238\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5232  0.4768\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6478\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5129  0.4871\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6678\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5192  0.4808\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6555\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5166  0.4834\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6605\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5090  0.4910\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6753\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5238  0.4762\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6466\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5212  0.4788\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6517\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5138  0.4862\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6659\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5176  0.4824\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7290\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5135  0.4865\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6665\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5132  0.4868\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7200\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5160  0.4840\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6616\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5159  0.4841\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6618\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5131  0.4869\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6674\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5192  0.4808\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6555\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5174  0.4826\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6590\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5180  0.4820\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6579\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5147  0.4853\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7230\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5128  0.4872\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6678\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5186  0.4814\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7310\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5157  0.4843\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7250\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5090  0.4910\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6753\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5097  0.4903\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7128\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5156  0.4844\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7248\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5225  0.4775\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7392\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5097  0.4903\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7128\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5208  0.4792\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6524\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5088  0.4912\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7108\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5144  0.4856\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7224\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5152  0.4848\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7240\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5075  0.4925\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7083\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5136  0.4864\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7206\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5122  0.4878\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7178\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5188  0.4812\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7314\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5182  0.4818\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6575\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5109  0.4891\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6716\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5180  0.4820\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7297\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5157  0.4843\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6622\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5119  0.4881\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7173\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5159  0.4841\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6618\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5114  0.4886\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6706\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5240  0.4760\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6462\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5153  0.4847\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6630\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5132  0.4868\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7198\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5147  0.4853\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7229\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5171  0.4829\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6595\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5090  0.4910\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7114\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5124  0.4876\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6687\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5160  0.4840\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7256\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5158  0.4842\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7252\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5079  0.4921\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7091\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5245  0.4755\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6453\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5171  0.4829\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6596\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5169  0.4831\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7276\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5218  0.4782\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6505\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5133  0.4867\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6669\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5159  0.4841\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6619\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5131  0.4869\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6672\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5119  0.4881\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7172\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5131  0.4869\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7196\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5158  0.4842\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6620\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5144  0.4856\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7223\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5195  0.4805\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7329\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5174  0.4826\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7286\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5139  0.4861\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6658\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5103  0.4897\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7140\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6615\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5210  0.4790\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6520\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5167  0.4833\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6603\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5075  0.4925\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7083\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5192  0.4808\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6554\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5099  0.4901\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6734\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5167  0.4833\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6603\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5155  0.4845\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6626\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5170  0.4830\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6597\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5121  0.4879\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7176\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5170  0.4830\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7277\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5154  0.4846\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7245\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5161  0.4839\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7259\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5168  0.4832\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7273\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5165  0.4835\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6607\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5101  0.4899\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6732\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5123  0.4877\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7180\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5211  0.4789\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7363\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5078  0.4922\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7089\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5237  0.4763\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7418\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5088  0.4912\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7108\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5151  0.4849\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7238\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5172  0.4828\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7282\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5101  0.4899\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7135\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5214  0.4786\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6513\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5101  0.4899\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 3\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.7136\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5114  0.4886\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6706\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5166  0.4834\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6605\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5099  0.4901\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6735\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "This is Pong's state output: torch.Size([1, 6400]) \n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 1x6400]\n",
      "\n",
      "This is softmax output from NN: Variable containing:\n",
      " 0.5127  0.4873\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Action generated by NN: Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Action to PONG: 2\n",
      "log_prob(action) saved by policy: Variable containing:\n",
      "-0.6680\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Episode 0\tLast length:  1445\tAverage length: -6.34\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import gym\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "gamma=0.99\n",
    "seed=543\n",
    "render=False\n",
    "log_interval=50\n",
    "verbose=True  # To step through the code and understand what is going on\n",
    "\n",
    "env = gym.make(\"Pong-v0\")\n",
    "env.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# A 2-layer NN with 200 hidden units and output of 2 actions (different from Karpathy)\n",
    "class Policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        self.affine1 = nn.Linear(6400, 200)\n",
    "        self.affine2 = nn.Linear(200, 2)  \n",
    "        \n",
    "        # Not sure what these are\n",
    "        self.saved_log_probs = []\n",
    "        self.rewards = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.affine1(x))\n",
    "        action_scores = self.affine2(x)\n",
    "        return F.softmax(action_scores, dim=1)\n",
    "\n",
    "policy = Policy()\n",
    "optimizer = optim.Adam(policy.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "def prepro(I):\n",
    "    \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n",
    "    I = I[35:195] # crop\n",
    "    I = I[::2,::2,0] # downsample by factor of 2\n",
    "    I[I == 144] = 0 # erase background (background type 1)\n",
    "    I[I == 109] = 0 # erase background (background type 2)\n",
    "    I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
    "    return I.astype(np.float).ravel()\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    \"\"\" \n",
    "    Use policy to determine an action based on state provided. While the NN will generate softmax output\n",
    "    for action 0 and 1. \n",
    "    \n",
    "    The output expected by the PONG environment is:\n",
    "    ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n",
    "    \n",
    "    So we need to return 2 (UP/RIGHT) and 3(DOWN/LEFT)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "    if verbose:\n",
    "        print (\"This is Pong's state output:\", state.shape, state)\n",
    "    probs = policy(Variable(state))\n",
    "    if verbose:\n",
    "        print (\"This is softmax output from NN:\", probs)\n",
    "\n",
    "    m = Categorical(probs)\n",
    "    action = m.sample()\n",
    "    if verbose:\n",
    "        print (\"Action generated by NN:\", action)\n",
    "        print (\"Action to PONG:\", action.data[0]+2)\n",
    "        print (\"log_prob(action) saved by policy:\", m.log_prob(action))\n",
    "    \n",
    "    policy.saved_log_probs.append(m.log_prob(action))\n",
    "    return action.data[0]+2  # UP=2, DOWN=3 \n",
    "\n",
    "prev_x = None\n",
    "\n",
    "# Main loop\n",
    "running_reward = -21\n",
    "# for i_episode in count(1):\n",
    "for i_episode in range(1): # just run 1 episode    \n",
    "    state = env.reset()\n",
    "    \n",
    "    for t in range(10000):  # Don't infinite loop while learning\n",
    "        \n",
    "        cur_x = prepro(state)\n",
    "        state = cur_x - prev_x if prev_x is not None else np.zeros(6400)\n",
    "        prev_x = cur_x\n",
    "        \n",
    "        # select an action based on the state provided by env\n",
    "        action = select_action(state)\n",
    "       \n",
    "        # step the environment through the action\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        if render:\n",
    "            env.render()\n",
    "            \n",
    "        # append reward to policy's reward[] list   \n",
    "        policy.rewards.append(reward)\n",
    "        \n",
    "        # break if episode is done\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    running_reward = running_reward * 0.99 + t * 0.01   # calculate running reward\n",
    "    \n",
    "    # this is where the heavy lifting (back prop) is done \n",
    "    # finish_episode()\n",
    "    \n",
    "    # print out and show sign of life\n",
    "    if i_episode % log_interval == 0:\n",
    "        print('Episode {}\\tLast length: {:5d}\\tAverage length: {:.2f}'.format(\n",
    "                i_episode, t, running_reward))\n",
    "    if i_episode > 10000:\n",
    "        print(\"Taking too long, Exit.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "env = gym.make(\"Pong-v0\")\n",
    "\n",
    "for i_episode in range(1): # just run 1 episode    \n",
    "    state = env.reset()\n",
    "    \n",
    "    for t in range(10000):  # Don't infinite loop while learning\n",
    "      \n",
    "        # step the environment through the action\n",
    "        state, reward, done, _ = env.step(3)\n",
    "        env.render()\n",
    "        sleep(0.02)    \n",
    "        \n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6400, 1])\n",
      "torch.Size([2, 6400])\n"
     ]
    }
   ],
   "source": [
    "print (x_tensor.size())\n",
    "xs = torch.cat((x_tensor.view(1,-1), x_tensor.view(1,-1)),0)\n",
    "print (xs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: input is not contiguous at /opt/conda/conda-bld/pytorch_1512386481460/work/torch/lib/THC/generic/THCTensor.c:227",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-186-de3c39a31787>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: input is not contiguous at /opt/conda/conda-bld/pytorch_1512386481460/work/torch/lib/THC/generic/THCTensor.c:227"
     ]
    }
   ],
   "source": [
    "print(I.view(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 5\n",
      "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "\n",
      " 7\n",
      "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "\n",
      " 5\n",
      " 5\n",
      "[torch.cuda.FloatTensor of size 2x1 (GPU 0)]\n",
      "\n",
      "\n",
      " 1\n",
      "-1\n",
      "[torch.cuda.FloatTensor of size 2x1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dlogps_tensor = torch.zeros(1, 1).type(dtype)\n",
    "dlogps_tensor[0,0] = 5\n",
    "\n",
    "print(dlogps_tensor)\n",
    "        \n",
    "drs_tensor = torch.zeros(1, 1).type(dtype)\n",
    "drs_tensor [0,0] = 1\n",
    "print(drs_tensor)        \n",
    "        \n",
    "a = torch.zeros(1, 1).type(dtype)\n",
    "a[0,0] = 7\n",
    "print(a)\n",
    "dlogps_tensor = torch.cat((dlogps_tensor, dlogps_tensor),0) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n",
    "print(dlogps_tensor)\n",
    "\n",
    "a[0,0] = -1 \n",
    "drs_tensor = torch.cat((drs_tensor, a),0) # record reward (has to be done after we call step() to get reward for previous action)\n",
    "print(drs_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 6400)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "H = 200 # number of hidden layer neurons\n",
    "D = 80 * 80 # input dimensionality: 80x80 grid\n",
    "\n",
    "model = {}\n",
    "model['W1'] = np.random.randn(H,D) / np.sqrt(D) # \"Xavier\" initialization\n",
    "model['W2'] = np.random.randn(H) / np.sqrt(H)\n",
    "\n",
    "print (model['W1'].shape)\n",
    "print (model['W2'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200])\n"
     ]
    }
   ],
   "source": [
    "w2 = torch.randn(H).type(dtype)/math.sqrt(H)\n",
    "print (w2.shape)\n",
    "\n",
    "a = torch.randn(200,1).type(dtype)\n",
    "b = torch.mm(w2.view(1,-1), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
