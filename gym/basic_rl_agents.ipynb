{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Basic RL Agents\n",
    "\n",
    "This Notebook will create some generic agents to work with Gym's environments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.6.4\n"
     ]
    }
   ],
   "source": [
    "# As usual, a bit of setup\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import platform\n",
    "import gym\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"Python version: \", platform.python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Agent\n",
    "\n",
    "The agent simply take the action space passed to it as a parameter and randomly sample from it whenever an action is requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "\n",
    "\n",
    "class RandomAgent(object):\n",
    "    \"\"\"The world's simplest agent! - Randomly sample from the action space \"\"\"\n",
    "    def __init__(self, action_space):\n",
    "        self.action_space = action_space    # Action space is passed to the agent as a parameter\n",
    "\n",
    "    def act(self, observation, reward, done):\n",
    "        return self.action_space.sample()   # Randomly sample from action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Episode reward total was 14.000000. running mean: 0.140000\n",
      "Episode reward total was 12.000000. running mean: 0.258600\n",
      "Episode reward total was 12.000000. running mean: 0.376014\n",
      "Episode reward total was 20.000000. running mean: 0.572254\n",
      "Episode reward total was 25.000000. running mean: 0.816531\n",
      "Episode reward total was 10.000000. running mean: 0.908366\n",
      "Episode reward total was 18.000000. running mean: 1.079282\n",
      "Episode reward total was 12.000000. running mean: 1.188490\n",
      "Episode reward total was 11.000000. running mean: 1.286605\n",
      "Episode reward total was 15.000000. running mean: 1.423739\n",
      "Episode reward total was 56.000000. running mean: 1.969501\n",
      "Episode reward total was 18.000000. running mean: 2.129806\n",
      "Episode reward total was 11.000000. running mean: 2.218508\n",
      "Episode reward total was 23.000000. running mean: 2.426323\n",
      "Episode reward total was 70.000000. running mean: 3.102060\n",
      "Episode reward total was 10.000000. running mean: 3.171039\n",
      "Episode reward total was 16.000000. running mean: 3.299329\n",
      "Episode reward total was 17.000000. running mean: 3.436336\n",
      "Episode reward total was 20.000000. running mean: 3.601972\n",
      "Episode reward total was 17.000000. running mean: 3.735952\n",
      "Episode reward total was 11.000000. running mean: 3.808593\n",
      "Episode reward total was 29.000000. running mean: 4.060507\n",
      "Episode reward total was 17.000000. running mean: 4.189902\n",
      "Episode reward total was 36.000000. running mean: 4.508003\n",
      "Episode reward total was 39.000000. running mean: 4.852923\n",
      "Episode reward total was 22.000000. running mean: 5.024394\n",
      "Episode reward total was 12.000000. running mean: 5.094150\n",
      "Episode reward total was 32.000000. running mean: 5.363208\n",
      "Episode reward total was 22.000000. running mean: 5.529576\n",
      "Episode reward total was 15.000000. running mean: 5.624280\n",
      "Episode reward total was 36.000000. running mean: 5.928038\n",
      "Episode reward total was 22.000000. running mean: 6.088757\n",
      "Episode reward total was 13.000000. running mean: 6.157870\n",
      "Episode reward total was 23.000000. running mean: 6.326291\n",
      "Episode reward total was 14.000000. running mean: 6.403028\n",
      "Episode reward total was 32.000000. running mean: 6.658998\n",
      "Episode reward total was 17.000000. running mean: 6.762408\n",
      "Episode reward total was 22.000000. running mean: 6.914784\n",
      "Episode reward total was 16.000000. running mean: 7.005636\n",
      "Episode reward total was 31.000000. running mean: 7.245579\n",
      "Episode reward total was 30.000000. running mean: 7.473124\n",
      "Episode reward total was 28.000000. running mean: 7.678392\n",
      "Episode reward total was 15.000000. running mean: 7.751609\n",
      "Episode reward total was 29.000000. running mean: 7.964092\n",
      "Episode reward total was 32.000000. running mean: 8.204452\n",
      "Episode reward total was 25.000000. running mean: 8.372407\n",
      "Episode reward total was 29.000000. running mean: 8.578683\n",
      "Episode reward total was 18.000000. running mean: 8.672896\n",
      "Episode reward total was 27.000000. running mean: 8.856167\n",
      "Episode reward total was 18.000000. running mean: 8.947605\n",
      "Episode reward total was 40.000000. running mean: 9.258129\n",
      "Episode reward total was 39.000000. running mean: 9.555548\n",
      "Episode reward total was 49.000000. running mean: 9.949993\n",
      "Episode reward total was 19.000000. running mean: 10.040493\n",
      "Episode reward total was 17.000000. running mean: 10.110088\n",
      "Episode reward total was 11.000000. running mean: 10.118987\n",
      "Episode reward total was 37.000000. running mean: 10.387797\n",
      "Episode reward total was 12.000000. running mean: 10.403919\n",
      "Episode reward total was 16.000000. running mean: 10.459880\n",
      "Episode reward total was 36.000000. running mean: 10.715281\n",
      "Episode reward total was 26.000000. running mean: 10.868128\n",
      "Episode reward total was 26.000000. running mean: 11.019447\n",
      "Episode reward total was 11.000000. running mean: 11.019253\n",
      "Episode reward total was 16.000000. running mean: 11.069060\n",
      "Episode reward total was 15.000000. running mean: 11.108369\n",
      "Episode reward total was 18.000000. running mean: 11.177286\n",
      "Episode reward total was 56.000000. running mean: 11.625513\n",
      "Episode reward total was 31.000000. running mean: 11.819258\n",
      "Episode reward total was 22.000000. running mean: 11.921065\n",
      "Episode reward total was 26.000000. running mean: 12.061854\n",
      "Episode reward total was 52.000000. running mean: 12.461236\n",
      "Episode reward total was 21.000000. running mean: 12.546624\n",
      "Episode reward total was 14.000000. running mean: 12.561157\n",
      "Episode reward total was 28.000000. running mean: 12.715546\n",
      "Episode reward total was 37.000000. running mean: 12.958390\n",
      "Episode reward total was 16.000000. running mean: 12.988806\n",
      "Episode reward total was 37.000000. running mean: 13.228918\n",
      "Episode reward total was 10.000000. running mean: 13.196629\n",
      "Episode reward total was 16.000000. running mean: 13.224663\n",
      "Episode reward total was 13.000000. running mean: 13.222416\n",
      "Episode reward total was 24.000000. running mean: 13.330192\n",
      "Episode reward total was 19.000000. running mean: 13.386890\n",
      "Episode reward total was 15.000000. running mean: 13.403021\n",
      "Episode reward total was 21.000000. running mean: 13.478991\n",
      "Episode reward total was 40.000000. running mean: 13.744201\n",
      "Episode reward total was 18.000000. running mean: 13.786759\n",
      "Episode reward total was 13.000000. running mean: 13.778892\n",
      "Episode reward total was 26.000000. running mean: 13.901103\n",
      "Episode reward total was 15.000000. running mean: 13.912092\n",
      "Episode reward total was 31.000000. running mean: 14.082971\n",
      "Episode reward total was 25.000000. running mean: 14.192141\n",
      "Episode reward total was 23.000000. running mean: 14.280220\n",
      "Episode reward total was 17.000000. running mean: 14.307417\n",
      "Episode reward total was 11.000000. running mean: 14.274343\n",
      "Episode reward total was 13.000000. running mean: 14.261600\n",
      "Episode reward total was 17.000000. running mean: 14.288984\n",
      "Episode reward total was 18.000000. running mean: 14.326094\n",
      "Episode reward total was 23.000000. running mean: 14.412833\n",
      "Episode reward total was 15.000000. running mean: 14.418705\n",
      "Episode reward total was 12.000000. running mean: 14.394518\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "# You provide the directory to write to (can be an existing\n",
    "# directory, including one with existing data -- all monitor files\n",
    "# will be namespaced). You can also dump to a tempdir if you'd\n",
    "# like: tempfile.mkdtemp().\n",
    "outdir = '/tmp/random-agent-results'\n",
    "env = wrappers.Monitor(env, directory=outdir, force=True)  # Delete previous content in directory \n",
    "\n",
    "env.seed(0)\n",
    "agent = RandomAgent(env.action_space)   # Select RandomAgent as agent\n",
    "\n",
    "episode_count = 100\n",
    "reward = 0\n",
    "running_reward = 0   # Reward Stat - a running average of the episode reward total\n",
    "done = False\n",
    "\n",
    "for i in range(episode_count):\n",
    "    ob = env.reset()\n",
    "    reward_sum = 0  \n",
    "    while True:\n",
    "        action = agent.act(ob, reward, done)\n",
    "        ob, reward, done, _ = env.step(action)\n",
    "        reward_sum += reward\n",
    "        if done:\n",
    "            # Calculate running average\n",
    "            running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "            print ('Episode reward total was %f. running mean: %f' % (reward_sum, running_reward))\n",
    "            break\n",
    "        # Note there's no env.render() here. But the environment still can open window and\n",
    "        # render if asked by env.monitor: it calls env.render('rgb_array') to record video.\n",
    "        # Video is not recorded every episode, see capped_cubic_video_schedule for details.\n",
    "\n",
    "# Close the env and write monitor result info to disk\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CEM Agent\n",
    "\n",
    "OpenAI's implementation of the cross-entropy method for maximizing a black-box function. \n",
    "\n",
    "In a nutshell the CE method consists of two phases:\n",
    "\n",
    "* Generate a random data sample (trajectories, vectors, etc.) according to a specified mechanism.\n",
    "* Update the parameters of the random mechanism based on the data to produce a \"better\" sample in the next iteration. This step involves minimizing the cross-entropy or Kullback–Leibler divergence.\n",
    "\n",
    "[Link to Wikipedia](https://en.wikipedia.org/wiki/Cross-entropy_method)\n",
    "\n",
    "One should always try a BB gun before reaching for the Bazooka. In the case of Reinforcement Learning for example, one strong baseline that should always be tried first is the cross-entropy method (CEM), a simple stochastic hill-climbing “guess and check” approach inspired loosely by evolution.\n",
    "\n",
    "And for Cartpole, CEM solves the problem (Achieving Episode mean reward: 200.000) in just 4 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import gym\n",
    "from gym import wrappers\n",
    "import logging\n",
    "import numpy as np\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import pickle\n",
    "import json, sys, os\n",
    "from os import path\n",
    "from examples.agents._policies import BinaryActionLinearPolicy # Support code for cem.py\n",
    "import argparse\n",
    "\n",
    "def cem(f, th_mean, batch_size, n_iter, elite_frac, initial_std=1.0):\n",
    "    \"\"\"\n",
    "    Generic implementation of the cross-entropy method for maximizing a black-box function\n",
    "\n",
    "    f: a function mapping from vector -> scalar\n",
    "    th_mean: initial mean over input distribution\n",
    "    batch_size: number of samples of theta to evaluate per batch\n",
    "    n_iter: number of batches\n",
    "    elite_frac: for each batch, select this fraction of the top-performing samples\n",
    "    initial_std: initial standard deviation over parameter vectors\n",
    "    \"\"\"\n",
    "    n_elite = int(np.round(batch_size*elite_frac))\n",
    "    th_std = np.ones_like(th_mean) * initial_std\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        ths = np.array([th_mean + dth for dth in  th_std[None,:]*np.random.randn(batch_size, th_mean.size)])\n",
    "        ys = np.array([f(th) for th in ths])\n",
    "        elite_inds = ys.argsort()[::-1][:n_elite]\n",
    "        elite_ths = ths[elite_inds]\n",
    "        th_mean = elite_ths.mean(axis=0)\n",
    "        th_std = elite_ths.std(axis=0)\n",
    "        yield {'ys' : ys, 'theta_mean' : th_mean, 'y_mean' : ys.mean()}\n",
    "\n",
    "def do_rollout(agent, env, num_steps, render=False):\n",
    "    total_rew = 0\n",
    "    ob = env.reset()\n",
    "    for t in range(num_steps):\n",
    "        a = agent.act(ob)\n",
    "        (ob, reward, done, _info) = env.step(a)\n",
    "        total_rew += reward\n",
    "        if render and t%3==0: env.render()\n",
    "        if done: break\n",
    "    return total_rew, t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-31 16:06:38,241] Making new env: CartPole-v0\n",
      "[2017-08-31 16:06:38,244] Finished writing results. You can upload them to the scoreboard via gym.upload('/tmp/cem-agent-results')\n",
      "[2017-08-31 16:06:38,250] Clearing 8 monitor files from previous run (because force=True was provided)\n",
      "[2017-08-31 16:06:38,252] Starting new video recorder writing to /tmp/cem-agent-results/openaigym.video.1.3995.video000000.mp4\n",
      "[2017-08-31 16:06:38,521] Starting new video recorder writing to /tmp/cem-agent-results/openaigym.video.1.3995.video000001.mp4\n",
      "[2017-08-31 16:06:38,871] Starting new video recorder writing to /tmp/cem-agent-results/openaigym.video.1.3995.video000008.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0. Episode mean reward:  25.640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-31 16:06:39,790] Starting new video recorder writing to /tmp/cem-agent-results/openaigym.video.1.3995.video000027.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1. Episode mean reward:  88.160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-31 16:06:41,724] Starting new video recorder writing to /tmp/cem-agent-results/openaigym.video.1.3995.video000064.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  2. Episode mean reward: 174.560\n",
      "Iteration  3. Episode mean reward: 193.400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-31 16:06:45,885] Starting new video recorder writing to /tmp/cem-agent-results/openaigym.video.1.3995.video000125.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  4. Episode mean reward: 200.000\n",
      "Iteration  5. Episode mean reward: 200.000\n",
      "Iteration  6. Episode mean reward: 200.000\n",
      "Iteration  7. Episode mean reward: 200.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-31 16:06:53,781] Starting new video recorder writing to /tmp/cem-agent-results/openaigym.video.1.3995.video000216.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  8. Episode mean reward: 200.000\n",
      "Iteration  9. Episode mean reward: 200.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-31 16:06:59,358] Finished writing results. You can upload them to the scoreboard via gym.upload('/tmp/cem-agent-results')\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "env.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "params = dict(n_iter=10, batch_size=25, elite_frac = 0.2)\n",
    "num_steps = 200\n",
    "display = True\n",
    "\n",
    "outdir = '/tmp/cem-agent-results'\n",
    "env = wrappers.Monitor(env, directory=outdir, force=True)\n",
    "\n",
    "# Prepare snapshotting\n",
    "# ----------------------------------------\n",
    "def writefile(fname, s):\n",
    "    with open(path.join(outdir, fname), 'w') as fh: fh.write(s)\n",
    "\n",
    "info = {}\n",
    "info['params'] = params\n",
    "info['argv'] = sys.argv\n",
    "info['env_id'] = env.spec.id\n",
    "# ------------------------------------------\n",
    "\n",
    "def noisy_evaluation(theta):\n",
    "    agent = BinaryActionLinearPolicy(theta)\n",
    "    rew, T = do_rollout(agent, env, num_steps)\n",
    "    return rew\n",
    "\n",
    "# Train the agent, and snapshot each stage\n",
    "for (i, iterdata) in enumerate(\n",
    "    cem(noisy_evaluation, np.zeros(env.observation_space.shape[0]+1), **params)):\n",
    "    print('Iteration %2i. Episode mean reward: %7.3f'%(i, iterdata['y_mean']))\n",
    "    agent = BinaryActionLinearPolicy(iterdata['theta_mean'])\n",
    "    if display: do_rollout(agent, env, 200, render=True)\n",
    "    writefile('agent-%.4i.pkl'%i, str(pickle.dumps(agent, -1)))\n",
    "\n",
    "# Write out the env at the end so we store the parameters of this\n",
    "# environment.\n",
    "writefile('info.json', json.dumps(info))\n",
    "\n",
    "env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Gradient Agent\n",
    "\n",
    "We will now bring out the Bazooka. Policy gradients (PG) is currently the default choice for attacking RL problems:\n",
    "* It works better than Q Learning when tuned well. \n",
    "* It is end-to-end: there’s an explicit policy and a principled approach that directly optimizes the expected reward\n",
    "\n",
    "I will adapt the Bazooka to the Cartpole problem.\n",
    "\n",
    "Karpathy's Bazooka is complex because he applies policy gradient to a more complex problem (Pong). We need to rebuild a simpler and more basic solution for Classic Control problems such as Cartpole.\n",
    "\n",
    "The Pong environment is different from that of CartPole:\n",
    "* The PG agent accept the difference between 2 successive frames of the Atari Pong screen as input\n",
    "* This difference frame is feed into a 2-layer NN to generate a single value - logprob for action=2 \"RIGHT\" \n",
    "* The reward of +1 or -1 is given at the end of a game between the agent and the Atari AI\n",
    "* An episode consists of 21 games; so after 21 games --> done=1\n",
    "* A batch of 10 episodes is played before there is an update to the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-01 18:03:49,278] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the 2 layer NN:\n",
      "(10, 4)\n",
      "(10,)\n",
      "observation [ 0.04961266 -0.0103578  -0.02179311  0.04812695]\n",
      "aprob: 0.503316204225\n",
      "action 0\n",
      "observation [ 0.04940551 -0.20516059 -0.02083057  0.33385507]\n",
      "aprob: 0.560592399845\n",
      "action 0\n",
      "observation [ 0.04530229 -0.39997997 -0.01415347  0.61989699]\n",
      "aprob: 0.620750803654\n",
      "action 0\n",
      "observation [ 0.03730269 -0.59490141 -0.00175553  0.90808889]\n",
      "aprob: 0.678782029508\n",
      "action 1\n",
      "observation [ 0.02540467 -0.39975574  0.01640625  0.61485471]\n",
      "aprob: 0.626149139203\n",
      "action 0\n",
      "observation [ 0.01740955 -0.59510304  0.02870334  0.91265945]\n",
      "aprob: 0.685034990519\n",
      "action 1\n",
      "observation [ 0.00550749 -0.40038093  0.04695653  0.62913421]\n",
      "aprob: 0.634266831585\n",
      "action 1\n",
      "observation [-0.00250013 -0.20594463  0.05953921  0.35160139]\n",
      "aprob: 0.580026386327\n",
      "action 1\n",
      "observation [-0.00661902 -0.01171769  0.06657124  0.0782714 ]\n",
      "aprob: 0.523411871633\n",
      "action 1\n",
      "observation [-0.00685337  0.1823899   0.06813667 -0.19268755]\n",
      "aprob: 0.518323772018\n",
      "action 0\n",
      "observation [-0.00320558 -0.01363725  0.06428292  0.12068757]\n",
      "aprob: 0.52942383779\n",
      "action 1\n",
      "observation [-0.00347832  0.18050762  0.06669667 -0.15104208]\n",
      "aprob: 0.517565852043\n",
      "action 1\n",
      "observation [  1.31831261e-04   3.74614269e-01   6.36758290e-02  -4.21960406e-01]\n",
      "aprob: 0.538830911295\n",
      "action 1\n",
      "observation [ 0.00762412  0.56877901  0.05523662 -0.69390922]\n",
      "aprob: 0.559994086868\n",
      "action 1\n",
      "observation [ 0.0189997   0.76309299  0.04135844 -0.96870435]\n",
      "aprob: 0.581011430468\n",
      "action 0\n",
      "observation [ 0.03426156  0.56744091  0.02198435 -0.66332127]\n",
      "aprob: 0.559549195884\n",
      "action 0\n",
      "observation [ 0.04561037  0.37202011  0.00871792 -0.36379804]\n",
      "aprob: 0.537931283182\n",
      "action 1\n",
      "observation [ 0.05305078  0.56701709  0.00144196 -0.65371934]\n",
      "aprob: 0.559397354357\n",
      "action 0\n",
      "observation [ 0.06439112  0.37187509 -0.01163242 -0.36058271]\n",
      "aprob: 0.53788555863\n",
      "action 0\n",
      "observation [ 0.07182862  0.1769204  -0.01884408 -0.07159032]\n",
      "aprob: 0.516277907642\n",
      "action 0\n",
      "observation [ 0.07536703 -0.0179264  -0.02027588  0.21508815]\n",
      "aprob: 0.528111909732\n",
      "action 0\n",
      "observation [ 0.0750085  -0.2127527  -0.01597412  0.50130683]\n",
      "aprob: 0.583879309598\n",
      "action 1\n",
      "observation [ 0.07075345 -0.01740925 -0.00594798  0.20363286]\n",
      "aprob: 0.528559290947\n",
      "action 0\n",
      "observation [ 0.07040526 -0.21244564 -0.00187533  0.49443357]\n",
      "aprob: 0.585325228381\n",
      "action 1\n",
      "observation [ 0.06615635 -0.01729729  0.00801334  0.20116021]\n",
      "aprob: 0.5304192112\n",
      "action 1\n",
      "observation [ 0.0658104   0.17770914  0.01203655 -0.08898415]\n",
      "aprob: 0.516219105367\n",
      "action 0\n",
      "observation [ 0.06936459 -0.01758325  0.01025686  0.20747188]\n",
      "aprob: 0.531578435118\n",
      "action 1\n",
      "observation [ 0.06901292  0.17739054  0.0144063  -0.08195796]\n",
      "aprob: 0.516011866244\n",
      "action 1\n",
      "observation [ 0.07256073  0.37230305  0.01276714 -0.37006108]\n",
      "aprob: 0.537566202912\n",
      "action 0\n",
      "observation [ 0.08000679  0.17700205  0.00536592 -0.07338002]\n",
      "aprob: 0.515825568284\n",
      "action 0\n",
      "observation [ 0.08354683 -0.01819641  0.00389832  0.22099104]\n",
      "aprob: 0.532036534121\n",
      "action 1\n",
      "observation [ 0.08318291  0.1768696   0.00831814 -0.07045966]\n",
      "aprob: 0.51568188272\n",
      "action 1\n",
      "observation [ 0.0867203   0.37187131  0.00690895 -0.3605066 ]\n",
      "aprob: 0.537268430331\n",
      "action 1\n",
      "observation [  9.41577236e-02   5.66894380e-01  -3.01183116e-04  -6.51003004e-01]\n",
      "aprob: 0.558749044835\n",
      "action 1\n",
      "observation [ 0.10549561  0.76202052 -0.01332124 -0.94378076]\n",
      "aprob: 0.58007569957\n",
      "action 0\n",
      "observation [ 0.12073602  0.56708055 -0.03219686 -0.65531307]\n",
      "aprob: 0.558881893484\n",
      "action 0\n",
      "observation [ 0.13207763  0.37242131 -0.04530312 -0.37293977]\n",
      "aprob: 0.537552944466\n",
      "action 1\n",
      "observation [ 0.13952606  0.56815656 -0.05276192 -0.67955598]\n",
      "aprob: 0.559311002035\n",
      "action 0\n",
      "observation [ 0.15088919  0.37380568 -0.06635303 -0.40394015]\n",
      "aprob: 0.538110145598\n",
      "action 1\n",
      "observation [ 0.1583653   0.56980284 -0.07443184 -0.71678241]\n",
      "aprob: 0.559977572564\n",
      "action 1\n",
      "observation [ 0.16976136  0.7658717  -0.08876749 -1.03193417]\n",
      "aprob: 0.581682011501\n",
      "action 1\n",
      "observation [ 0.18507879  0.96205512 -0.10940617 -1.35111404]\n",
      "aprob: 0.603167323901\n",
      "action 0\n",
      "observation [ 0.2043199   0.76846414 -0.13642845 -1.09456503]\n",
      "aprob: 0.582891036842\n",
      "action 1\n",
      "observation [ 0.21968918  0.96509338 -0.15831975 -1.42675395]\n",
      "aprob: 0.604578476906\n",
      "action 1\n",
      "observation [ 0.23899105  1.16177729 -0.18685483 -1.7644419 ]\n",
      "aprob: 0.625970480845\n",
      "action 0\n",
      "resetting env. episode reward total was 45.000000. running mean: 45.000000\n",
      "observation [ 0.04045741 -0.01235764  0.04951176 -0.04163969]\n",
      "aprob: 0.501441368397\n",
      "action 1\n",
      "observation [ 0.04021026  0.18202064  0.04867896 -0.3182993 ]\n",
      "aprob: 0.519525033556\n",
      "action 1\n",
      "observation [ 0.04385067  0.3764167   0.04231298 -0.59524201]\n",
      "aprob: 0.540935140471\n",
      "action 0\n",
      "observation [ 0.051379    0.18072888  0.03040814 -0.28953671]\n",
      "aprob: 0.519120808481\n",
      "action 0\n",
      "observation [ 0.05499358 -0.01481318  0.0246174   0.01257941]\n",
      "aprob: 0.504236469998\n",
      "action 0\n",
      "observation [ 0.05469732 -0.21027937  0.02486899  0.31292664]\n",
      "aprob: 0.564075480172\n",
      "action 1\n",
      "observation [ 0.05049173 -0.01552037  0.03112752  0.0281892 ]\n",
      "aprob: 0.507541914777\n",
      "action 0\n",
      "observation [ 0.05018132 -0.21107456  0.03169131  0.33052841]\n",
      "aprob: 0.568165667146\n",
      "action 0\n",
      "observation [ 0.04595983 -0.40663296  0.03830188  0.6330344 ]\n",
      "aprob: 0.630333552455\n",
      "action 1\n",
      "observation [ 0.03782717 -0.21206569  0.05096256  0.35265553]\n",
      "aprob: 0.575496777854\n",
      "action 1\n",
      "observation [ 0.03358586 -0.01770407  0.05801567  0.07646813]\n",
      "aprob: 0.519860054496\n",
      "action 1\n",
      "observation [ 0.03323178  0.17654026  0.05954504 -0.19736112]\n",
      "aprob: 0.517360052989\n",
      "action 0\n",
      "observation [ 0.03676258 -0.0193806   0.05559782  0.11349524]\n",
      "aprob: 0.52509977856\n",
      "action 1\n",
      "observation [ 0.03637497  0.17490244  0.05786772 -0.16114169]\n",
      "aprob: 0.516703786609\n",
      "action 0\n",
      "observation [ 0.03987302 -0.02099816  0.05464489  0.14922096]\n",
      "aprob: 0.530375516533\n",
      "action 1\n",
      "observation [ 0.03945306  0.17330044  0.05762931 -0.12573431]\n",
      "aprob: 0.516041332891\n",
      "action 0\n",
      "observation [ 0.04291907 -0.02259773  0.05511462  0.18455877]\n",
      "aprob: 0.53602356008\n",
      "action 1\n",
      "observation [ 0.04246711  0.17169409  0.05880579 -0.09024093]\n",
      "aprob: 0.515357383614\n",
      "action 1\n",
      "observation [ 0.04590099  0.365926    0.05700098 -0.36380624]\n",
      "aprob: 0.536664011204\n",
      "action 1\n",
      "observation [ 0.05321951  0.56019346  0.04972485 -0.63798496]\n",
      "aprob: 0.557869358252\n",
      "action 0\n",
      "observation [ 0.06442338  0.36441468  0.03696515 -0.3300667 ]\n",
      "aprob: 0.536088084251\n",
      "action 0\n",
      "observation [ 0.07171168  0.16878656  0.03036382 -0.02595969]\n",
      "aprob: 0.514202444713\n",
      "action 1\n",
      "observation [ 0.07508741  0.36346021  0.02984462 -0.30890997]\n",
      "aprob: 0.535660897976\n",
      "action 1\n",
      "observation [ 0.08235661  0.55814449  0.02366642 -0.59203333]\n",
      "aprob: 0.557014446604\n",
      "action 0\n",
      "observation [ 0.0935195   0.36269936  0.01182576 -0.29199045]\n",
      "aprob: 0.535348215063\n",
      "action 1\n",
      "observation [ 0.10077349  0.55765071  0.00598595 -0.58092035]\n",
      "aprob: 0.556800150071\n",
      "action 0\n",
      "observation [ 0.1119265   0.3624454  -0.00563246 -0.28635776]\n",
      "aprob: 0.535223676152\n",
      "action 0\n",
      "observation [ 0.11917541  0.16740423 -0.01135961  0.00454342]\n",
      "aprob: 0.513551748499\n",
      "action 0\n",
      "observation [ 0.1225235  -0.02755298 -0.01126874  0.29362072]\n",
      "aprob: 0.539626939757\n",
      "action 1\n",
      "observation [ 0.12197244  0.1677278  -0.00539633 -0.0025948 ]\n",
      "aprob: 0.513545257394\n",
      "action 0\n",
      "observation [ 0.12532699 -0.02731634 -0.00544823  0.28838064]\n",
      "aprob: 0.539435950427\n",
      "action 0\n",
      "observation [  1.24780665e-01  -2.22360180e-01   3.19386443e-04   5.79340283e-01]\n",
      "aprob: 0.593672122414\n",
      "action 1\n",
      "observation [ 0.12033346 -0.02724271  0.01190619  0.28675799]\n",
      "aprob: 0.541934014868\n",
      "action 1\n",
      "observation [ 0.11978861  0.16770744  0.01764135 -0.00214617]\n",
      "aprob: 0.513231052572\n",
      "action 1\n",
      "observation [ 0.12314276  0.36257201  0.01759843 -0.28921125]\n",
      "aprob: 0.534758945079\n",
      "action 0\n",
      "observation [ 0.1303942   0.16720358  0.0118142   0.00896968]\n",
      "aprob: 0.512958861921\n",
      "action 0\n",
      "observation [ 0.13373827 -0.02808579  0.0119936   0.30535659]\n",
      "aprob: 0.544177681912\n",
      "action 0\n",
      "observation [ 0.13317655 -0.22337658  0.01810073  0.60179775]\n",
      "aprob: 0.599181536571\n",
      "action 1\n",
      "observation [ 0.12870902 -0.02851244  0.03013668  0.31487074]\n",
      "aprob: 0.548592739863\n",
      "action 1\n",
      "observation [ 0.12813877  0.16616755  0.0364341   0.0318422 ]\n",
      "aprob: 0.512500517694\n",
      "action 0\n",
      "observation [ 0.13146212 -0.02945743  0.03707094  0.33579418]\n",
      "aprob: 0.552803812559\n",
      "action 1\n",
      "observation [ 0.13087297  0.16511787  0.04378683  0.05502811]\n",
      "aprob: 0.516270656534\n",
      "action 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation [ 0.13417533  0.35958553  0.04488739 -0.22352456]\n",
      "aprob: 0.533043250472\n",
      "action 1\n",
      "observation [ 0.14136704  0.55403813  0.0404169  -0.50171721]\n",
      "aprob: 0.554307327551\n",
      "action 1\n",
      "observation [ 0.1524478   0.74856776  0.03038255 -0.78139402]\n",
      "aprob: 0.57542224666\n",
      "action 0\n",
      "observation [ 0.16741916  0.55304164  0.01475467 -0.47930911]\n",
      "aprob: 0.553898171768\n",
      "action 0\n",
      "observation [ 0.17847999  0.35771454  0.00516849 -0.18201263]\n",
      "aprob: 0.532223182498\n",
      "action 1\n",
      "observation [ 0.18563428  0.55276215  0.00152824 -0.47306061]\n",
      "aprob: 0.553705163627\n",
      "action 0\n",
      "observation [ 0.19668953  0.35761865 -0.00793297 -0.1798964 ]\n",
      "aprob: 0.532098615126\n",
      "action 0\n",
      "observation [ 0.2038419   0.16261111 -0.0115309   0.11027343]\n",
      "aprob: 0.514964708665\n",
      "action 0\n",
      "observation [ 0.20709412 -0.03234372 -0.00932543  0.39929624]\n",
      "aprob: 0.552268698712\n",
      "action 0\n",
      "observation [ 0.20644725 -0.22733215 -0.00133951  0.68902452]\n",
      "aprob: 0.60602249107\n",
      "action 0\n",
      "observation [ 0.2019006  -0.42243549  0.01244098  0.98128545]\n",
      "aprob: 0.661171191193\n",
      "action 0\n",
      "observation [ 0.19345189 -0.61772194  0.03206669  1.27785002]\n",
      "aprob: 0.717790349819\n",
      "action 1\n",
      "observation [ 0.18109745 -0.42302313  0.05762369  0.99537793]\n",
      "aprob: 0.670887518188\n",
      "action 0\n",
      "observation [ 0.17263699 -0.61886646  0.07753125  1.30558733]\n",
      "aprob: 0.728243746861\n",
      "action 0\n",
      "observation [ 0.16025966 -0.81488103  0.103643    1.62149728]\n",
      "aprob: 0.78039497539\n",
      "action 1\n",
      "observation [ 0.14396204 -0.62112121  0.13607294  1.36283369]\n",
      "aprob: 0.743997206462\n",
      "action 1\n",
      "observation [ 0.13153962 -0.42794105  0.16332962  1.11562409]\n",
      "aprob: 0.704361712106\n",
      "action 1\n",
      "observation [ 0.1229808  -0.23529531  0.1856421   0.87830695]\n",
      "aprob: 0.664055936431\n",
      "action 1\n",
      "observation [ 0.11827489 -0.04311515  0.20320824  0.64925562]\n",
      "aprob: 0.62609411487\n",
      "action 1\n",
      "resetting env. episode reward total was 61.000000. running mean: 45.160000\n",
      "observation [ 0.03580976  0.02061463  0.03781051  0.02142488]\n",
      "aprob: 0.507683611879\n",
      "action 1\n",
      "observation [ 0.03622206  0.21517452  0.03823901 -0.25909272]\n",
      "aprob: 0.521974561052\n",
      "action 1\n",
      "observation [ 0.04052555  0.4097303   0.03305716 -0.53947352]\n",
      "aprob: 0.543403951771\n",
      "action 0\n",
      "observation [ 0.04872015  0.21415962  0.02226769 -0.23656074]\n",
      "aprob: 0.521624344848\n",
      "action 0\n",
      "observation [ 0.05300335  0.01872673  0.01753647  0.06306208]\n",
      "aprob: 0.509857469508\n",
      "action 1\n",
      "observation [ 0.05337788  0.21359292  0.01879771 -0.2240368 ]\n",
      "aprob: 0.521385035612\n",
      "action 0\n",
      "observation [ 0.05764974  0.01820741  0.01431698  0.07451587]\n",
      "aprob: 0.510946021649\n",
      "action 1\n",
      "observation [ 0.05801389  0.21312122  0.01580729 -0.21361582]\n",
      "aprob: 0.521175670429\n",
      "action 0\n",
      "observation [ 0.06227631  0.01777688  0.01153498  0.08401123]\n",
      "aprob: 0.511799001969\n",
      "action 0\n",
      "observation [ 0.06263185 -0.1775085   0.0132152   0.38031102]\n",
      "aprob: 0.568457305364\n",
      "action 0\n",
      "observation [ 0.05908168 -0.3728156   0.02082142  0.67713124]\n",
      "aprob: 0.629870827184\n",
      "action 1\n",
      "observation [ 0.05162537 -0.17798903  0.03436405  0.3910758 ]\n",
      "aprob: 0.57421961103\n",
      "action 0\n",
      "observation [ 0.04806559 -0.37358141  0.04218556  0.69439219]\n",
      "aprob: 0.636291439649\n",
      "action 1\n",
      "observation [ 0.04059396 -0.17906922  0.05607341  0.41528236]\n",
      "aprob: 0.582051258003\n",
      "action 1\n",
      "observation [ 0.03701257  0.01521502  0.06437906  0.14079098]\n",
      "aprob: 0.529856229874\n",
      "action 1\n",
      "observation [ 0.03731687  0.20935868  0.06719487 -0.13090685]\n",
      "aprob: 0.519291680976\n",
      "action 0\n",
      "observation [ 0.04150405  0.01334174  0.06457674  0.18219546]\n",
      "aprob: 0.536112890251\n",
      "action 0\n",
      "observation [ 0.04177088 -0.18264196  0.06822065  0.49453062]\n",
      "aprob: 0.595434428113\n",
      "action 0\n",
      "observation [ 0.03811804 -0.37865635  0.07811126  0.80790959]\n",
      "aprob: 0.657935762779\n",
      "action 1\n",
      "observation [ 0.03054492 -0.1846868   0.09426945  0.5407838 ]\n",
      "aprob: 0.60700344265\n",
      "action 1\n",
      "observation [ 0.02685118  0.00899247  0.10508513  0.279229  ]\n",
      "aprob: 0.558098623679\n",
      "action 1\n",
      "observation [ 0.02703103  0.20247064  0.11066971  0.02145089]\n",
      "aprob: 0.533123422395\n",
      "action 1\n",
      "observation [ 0.03108044  0.39584581  0.11109872 -0.23436685]\n",
      "aprob: 0.537096327687\n",
      "action 1\n",
      "observation [ 0.03899736  0.58921953  0.10641139 -0.49004331]\n",
      "aprob: 0.557927079922\n",
      "action 1\n",
      "observation [ 0.05078175  0.78269207  0.09661052 -0.74738465]\n",
      "aprob: 0.578601811884\n",
      "action 0\n",
      "observation [ 0.06643559  0.58637941  0.08166283 -0.42592949]\n",
      "aprob: 0.556768340485\n",
      "action 1\n",
      "observation [ 0.07816318  0.78025544  0.07314424 -0.69179218]\n",
      "aprob: 0.577585600942\n",
      "action 1\n",
      "observation [ 0.09376829  0.97429043  0.0593084  -0.9605812 ]\n",
      "aprob: 0.598200243194\n",
      "action 1\n",
      "observation [ 0.1132541   1.16856722  0.04009677 -1.23405757]\n",
      "aprob: 0.618571616075\n",
      "action 1\n",
      "observation [ 0.13662544  1.36315142  0.01541562 -1.51391397]\n",
      "aprob: 0.638657932463\n",
      "action 1\n",
      "observation [ 0.16388847  1.55808341 -0.01486266 -1.80174519]\n",
      "aprob: 0.65841547247\n",
      "action 1\n",
      "observation [ 0.19505014  1.75336825 -0.05089756 -2.09900957]\n",
      "aprob: 0.677797810425\n",
      "action 1\n",
      "observation [ 0.2301175   1.94896316 -0.09287775 -2.40697942]\n",
      "aprob: 0.696755108059\n",
      "action 1\n",
      "observation [ 0.26909677  2.14476203 -0.14101734 -2.72667868]\n",
      "aprob: 0.715233550263\n",
      "action 1\n",
      "observation [ 0.31199201  2.34057715 -0.19555092 -3.05880756]\n",
      "aprob: 0.7331750383\n",
      "action 0\n",
      "resetting env. episode reward total was 35.000000. running mean: 45.058400\n",
      "observation [ 0.03324904 -0.00606109 -0.03491707 -0.006766  ]\n",
      "aprob: 0.501797999599\n",
      "action 1\n",
      "observation [ 0.03312781  0.18954377 -0.03505239 -0.31025798]\n",
      "aprob: 0.521448185359\n",
      "action 1\n",
      "observation [ 0.03691869  0.38514714 -0.04125755 -0.6137861 ]\n",
      "aprob: 0.543305123808\n",
      "action 0\n",
      "observation [ 0.04462163  0.19062527 -0.05353327 -0.33437786]\n",
      "aprob: 0.521963312131\n",
      "action 0\n",
      "observation [ 0.04843414 -0.00369553 -0.06022082 -0.05904549]\n",
      "aprob: 0.502018561215\n",
      "action 0\n",
      "observation [ 0.04836023 -0.19790465 -0.06140173  0.21404589]\n",
      "aprob: 0.536420852753\n",
      "action 0\n",
      "observation [ 0.04440213 -0.39209746 -0.05712082  0.4867454 ]\n",
      "aprob: 0.59518665915\n",
      "action 1\n",
      "observation [ 0.03656018 -0.196218   -0.04738591  0.17662103]\n",
      "aprob: 0.533957575091\n",
      "action 0\n",
      "observation [ 0.03263582 -0.39063091 -0.04385349  0.45398681]\n",
      "aprob: 0.593380715567\n",
      "action 1\n",
      "observation [ 0.02482321 -0.19491718 -0.03477375  0.14780966]\n",
      "aprob: 0.532595968245\n",
      "action 1\n",
      "observation [ 0.02092486  0.00068504 -0.03181756 -0.15563771]\n",
      "aprob: 0.504033466995\n",
      "action 0\n",
      "observation [ 0.02093856 -0.19396725 -0.03493031  0.12684015]\n",
      "aprob: 0.529763757967\n",
      "action 1\n",
      "observation [ 0.01705922  0.00163724 -0.03239351 -0.17665503]\n",
      "aprob: 0.504733958379\n",
      "action 0\n",
      "observation [ 0.01709196 -0.19300651 -0.03592661  0.1056354 ]\n",
      "aprob: 0.526766651533\n",
      "action 0\n",
      "observation [ 0.01323183 -0.38759568 -0.0338139   0.38677066]\n",
      "aprob: 0.586748930851\n",
      "action 1\n",
      "observation [ 0.00547992 -0.19201045 -0.02607849  0.08362113]\n",
      "aprob: 0.526024126885\n",
      "action 1\n",
      "observation [ 0.00163971  0.00347543 -0.02440607 -0.2171742 ]\n",
      "aprob: 0.506368443401\n",
      "action 1\n",
      "observation [ 0.00170922  0.19893762 -0.02874955 -0.51745484]\n",
      "aprob: 0.525456631538\n",
      "action 1\n",
      "observation [ 0.00568797  0.39445232 -0.03909865 -0.81905691]\n",
      "aprob: 0.547313718157\n",
      "action 0\n",
      "observation [ 0.01357702  0.1998867  -0.05547979 -0.53892359]\n",
      "aprob: 0.526039778881\n",
      "action 0\n",
      "observation [ 0.01757475  0.00558678 -0.06625826 -0.26422483]\n",
      "aprob: 0.506912160279\n",
      "action 1\n",
      "observation [ 0.01768649  0.20158882 -0.07154275 -0.57704844]\n",
      "aprob: 0.526875695576\n",
      "action 1\n",
      "observation [ 0.02171826  0.39763678 -0.08308372 -0.89138375]\n",
      "aprob: 0.548956816723\n",
      "action 1\n",
      "observation [ 0.029671    0.59378162 -0.1009114  -1.20898464]\n",
      "aprob: 0.570929782542\n",
      "action 0\n",
      "observation [ 0.04154663  0.40009725 -0.12509109 -0.94955369]\n",
      "aprob: 0.55025922916\n",
      "action 1\n",
      "observation [ 0.04954858  0.5966609  -0.14408216 -1.27877627]\n",
      "aprob: 0.572423650755\n",
      "action 0\n",
      "observation [ 0.0614818   0.40363893 -0.16965769 -1.03445716]\n",
      "aprob: 0.552047529869\n",
      "action 1\n",
      "observation [ 0.06955457  0.60056054 -0.19034683 -1.37523909]\n",
      "aprob: 0.574398386458\n",
      "action 1\n",
      "resetting env. episode reward total was 28.000000. running mean: 44.887816\n",
      "observation [-0.03400387 -0.02164849 -0.0027888   0.02520812]\n",
      "aprob: 0.508777284961\n",
      "action 0\n",
      "observation [-0.03443684 -0.21673034 -0.00228464  0.31700985]\n",
      "aprob: 0.570267718984\n",
      "action 1\n",
      "observation [-0.03877144 -0.02157592  0.00405555  0.0236073 ]\n",
      "aprob: 0.510035218479\n",
      "action 1\n",
      "observation [-0.03920296  0.17348764  0.0045277  -0.2677933 ]\n",
      "aprob: 0.519951097819\n",
      "action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation [-0.03573321 -0.02169864 -0.00082817  0.02631425]\n",
      "aprob: 0.509414735672\n",
      "action 1\n",
      "observation [-0.03616718  0.17343518 -0.00030188 -0.26662986]\n",
      "aprob: 0.519955165755\n",
      "action 0\n",
      "observation [-0.03269848 -0.02168246 -0.00563448  0.02595784]\n",
      "aprob: 0.508330536455\n",
      "action 0\n",
      "observation [-0.03313213 -0.21672316 -0.00511532  0.31685771]\n",
      "aprob: 0.569706353667\n",
      "action 1\n",
      "observation [-0.03746659 -0.02152872  0.00122183  0.02256599]\n",
      "aprob: 0.509312126967\n",
      "action 1\n",
      "observation [-0.03789716  0.17357569  0.00167315 -0.26973118]\n",
      "aprob: 0.520006902478\n",
      "action 0\n",
      "observation [-0.03442565 -0.0215701  -0.00372147  0.023479  ]\n",
      "aprob: 0.508403353983\n",
      "action 1\n",
      "observation [-0.03485705  0.17360502 -0.00325189 -0.27037577]\n",
      "aprob: 0.520043872248\n",
      "action 0\n",
      "observation [-0.03138495 -0.02147037 -0.00865941  0.02127972]\n",
      "aprob: 0.507011720714\n",
      "action 1\n",
      "observation [-0.03181436  0.17377469 -0.00823381 -0.27412272]\n",
      "aprob: 0.5201357931\n",
      "action 0\n",
      "observation [-0.02833887 -0.02122882 -0.01371627  0.01595192]\n",
      "aprob: 0.505114798875\n",
      "action 1\n",
      "observation [-0.02876344  0.17408712 -0.01339723 -0.2810269 ]\n",
      "aprob: 0.520285368052\n",
      "action 1\n",
      "observation [-0.0252817   0.36939759 -0.01901777 -0.57790498]\n",
      "aprob: 0.542030229341\n",
      "action 0\n",
      "observation [-0.01789375  0.17454728 -0.03057586 -0.29127324]\n",
      "aprob: 0.520549448474\n",
      "action 0\n",
      "observation [-0.0144028  -0.02012566 -0.03640133 -0.00838822]\n",
      "aprob: 0.502486373475\n",
      "action 0\n",
      "observation [-0.01480532 -0.21470717 -0.03656909  0.27259106]\n",
      "aprob: 0.556635528872\n",
      "action 1\n",
      "observation [-0.01909946 -0.01908302 -0.03111727 -0.03139791]\n",
      "aprob: 0.502922731302\n",
      "action 0\n",
      "observation [-0.01948112 -0.21374523 -0.03174523  0.25130706]\n",
      "aprob: 0.554582910785\n",
      "action 1\n",
      "observation [-0.02375602 -0.01818469 -0.02671909 -0.0512175 ]\n",
      "aprob: 0.503324325009\n",
      "action 0\n",
      "observation [-0.02411972 -0.21291353 -0.02774344  0.23291703]\n",
      "aprob: 0.552844003796\n",
      "action 1\n",
      "observation [-0.02837799 -0.01740638 -0.0230851  -0.06838637]\n",
      "aprob: 0.50377926272\n",
      "action 1\n",
      "observation [-0.02872612  0.17803881 -0.02445283 -0.36826244]\n",
      "aprob: 0.521970813164\n",
      "action 1\n",
      "observation [-0.02516534  0.37349952 -0.03181808 -0.66855428]\n",
      "aprob: 0.54378949351\n",
      "action 1\n",
      "observation [-0.01769535  0.56904913 -0.04518916 -0.97108316]\n",
      "aprob: 0.565506520988\n",
      "action 0\n",
      "observation [-0.00631437  0.37456186 -0.06461082 -0.69293116]\n",
      "aprob: 0.544400142442\n",
      "action 0\n",
      "observation [ 0.00117687  0.18039292 -0.07846945 -0.42126785]\n",
      "aprob: 0.523226540859\n",
      "action 1\n",
      "observation [ 0.00478473  0.37653387 -0.0868948  -0.73762028]\n",
      "aprob: 0.545326987509\n",
      "action 0\n",
      "observation [ 0.01231541  0.1827126  -0.10164721 -0.47350023]\n",
      "aprob: 0.524303536889\n",
      "action 1\n",
      "observation [ 0.01596966  0.37911213 -0.11111721 -0.79641177]\n",
      "aprob: 0.546522165356\n",
      "action 1\n",
      "observation [ 0.0235519   0.57556921 -0.12704545 -1.12188128]\n",
      "aprob: 0.568629668213\n",
      "action 1\n",
      "observation [ 0.03506329  0.77210718 -0.14948308 -1.45156323]\n",
      "aprob: 0.590562811364\n",
      "action 1\n",
      "observation [ 0.05050543  0.96871594 -0.17851434 -1.78697208]\n",
      "aprob: 0.612254955589\n",
      "action 0\n",
      "resetting env. episode reward total was 36.000000. running mean: 44.798938\n",
      "observation [-0.01079464  0.00235884  0.03401652  0.03619538]\n",
      "aprob: 0.511505459096\n",
      "action 0\n",
      "observation [-0.01074747 -0.19323399  0.03474043  0.33941381]\n",
      "aprob: 0.574352095297\n",
      "action 0\n",
      "observation [-0.01461215 -0.3888326   0.0415287   0.64284633]\n",
      "aprob: 0.636321551161\n",
      "action 1\n",
      "observation [-0.0223888  -0.19431334  0.05438563  0.36352494]\n",
      "aprob: 0.581934312609\n",
      "action 1\n",
      "observation [ -2.62750656e-02  -4.82088492e-06   6.16561278e-02   8.84745941e-02]\n",
      "aprob: 0.525128089158\n",
      "action 0\n",
      "observation [-0.02627516 -0.19595387  0.06342562  0.39995509]\n",
      "aprob: 0.58903249977\n",
      "action 1\n",
      "observation [-0.03019424 -0.00178628  0.07142472  0.12792396]\n",
      "aprob: 0.532800098028\n",
      "action 1\n",
      "observation [-0.03022996  0.19224365  0.0739832  -0.14139785]\n",
      "aprob: 0.518813520093\n",
      "action 1\n",
      "observation [-0.02638509  0.38623233  0.07115524 -0.40985366]\n",
      "aprob: 0.540022641815\n",
      "action 1\n",
      "observation [-0.01866045  0.58027714  0.06295817 -0.67928234]\n",
      "aprob: 0.561124667377\n",
      "action 1\n",
      "observation [-0.0070549   0.77447064  0.04937252 -0.95149801]\n",
      "aprob: 0.58207641853\n",
      "action 0\n",
      "observation [ 0.00843451  0.57872024  0.03034256 -0.64372059]\n",
      "aprob: 0.560578659032\n",
      "action 1\n",
      "observation [ 0.02000892  0.77340646  0.01746815 -0.92669615]\n",
      "aprob: 0.581710919824\n",
      "action 0\n",
      "observation [ 0.03547704  0.57805303 -0.00106577 -0.62857534]\n",
      "aprob: 0.560364458875\n",
      "action 1\n",
      "observation [ 0.04703811  0.77318984 -0.01363728 -0.92159372]\n",
      "aprob: 0.581665757633\n",
      "action 0\n",
      "observation [ 0.0625019   0.5782548  -0.03206915 -0.63322758]\n",
      "aprob: 0.560483313752\n",
      "action 0\n",
      "observation [ 0.074067    0.38359455 -0.0447337  -0.35081406]\n",
      "aprob: 0.53915740374\n",
      "action 0\n",
      "observation [ 0.08173889  0.18913638 -0.05174999 -0.07256592]\n",
      "aprob: 0.517737950964\n",
      "action 0\n",
      "observation [ 0.08552162 -0.00520695 -0.0532013   0.2033511 ]\n",
      "aprob: 0.520438903082\n",
      "action 0\n",
      "observation [ 0.08541748 -0.19952929 -0.04913428  0.4787884 ]\n",
      "aprob: 0.573608111036\n",
      "action 0\n",
      "observation [ 0.08142689 -0.39392439 -0.03955851  0.75558948]\n",
      "aprob: 0.632218179549\n",
      "action 1\n",
      "observation [ 0.0735484  -0.19828012 -0.02444672  0.45072549]\n",
      "aprob: 0.574134201814\n",
      "action 1\n",
      "observation [ 0.0695828  -0.0028211  -0.01543221  0.15043794]\n",
      "aprob: 0.518130289893\n",
      "action 1\n",
      "observation [ 0.06952638  0.19251839 -0.01242346 -0.14707329]\n",
      "aprob: 0.518648344884\n",
      "action 1\n",
      "observation [ 0.07337675  0.38781603 -0.01536492 -0.44364954]\n",
      "aprob: 0.540351707289\n",
      "action 0\n",
      "observation [ 0.08113307  0.19291481 -0.02423791 -0.15584934]\n",
      "aprob: 0.518796557729\n",
      "action 1\n",
      "observation [ 0.08499136  0.38837526 -0.0273549  -0.45607914]\n",
      "aprob: 0.540564847014\n",
      "action 0\n",
      "observation [ 0.09275887  0.19365053 -0.03647648 -0.17214266]\n",
      "aprob: 0.519081899979\n",
      "action 1\n",
      "observation [ 0.09663188  0.38927506 -0.03991934 -0.47610596]\n",
      "aprob: 0.540917663597\n",
      "action 1\n",
      "observation [ 0.10441738  0.58493727 -0.04944145 -0.78109864]\n",
      "aprob: 0.562643182253\n",
      "action 1\n",
      "observation [ 0.11611613  0.78070273 -0.06506343 -1.08891785]\n",
      "aprob: 0.584205608075\n",
      "action 0\n",
      "observation [ 0.13173018  0.58649611 -0.08684178 -0.81733945]\n",
      "aprob: 0.56338755979\n",
      "action 0\n",
      "observation [ 0.1434601   0.39266351 -0.10318857 -0.55318561]\n",
      "aprob: 0.542456034566\n",
      "action 0\n",
      "observation [ 0.15131337  0.19913044 -0.11425229 -0.29471381]\n",
      "aprob: 0.521458512953\n",
      "action 0\n",
      "observation [ 0.15529598  0.005807   -0.12014656 -0.04013641]\n",
      "aprob: 0.507334322215\n",
      "action 1\n",
      "observation [ 0.15541212  0.20242863 -0.12094929 -0.36818087]\n",
      "aprob: 0.522773662225\n",
      "action 0\n",
      "observation [ 0.1594607   0.00921425 -0.12831291 -0.11594904]\n",
      "aprob: 0.50664509674\n",
      "action 0\n",
      "observation [ 0.15964498 -0.18385799 -0.13063189  0.13365795]\n",
      "aprob: 0.515926640172\n",
      "action 0\n",
      "observation [ 0.15596782 -0.37689034 -0.12795873  0.38244282]\n",
      "aprob: 0.557341425344\n",
      "action 0\n",
      "observation [ 0.14843001 -0.56998528 -0.12030987  0.63219994]\n",
      "aprob: 0.612831397732\n",
      "action 0\n",
      "observation [ 0.13703031 -0.76324152 -0.10766587  0.88470303]\n",
      "aprob: 0.666920813262\n",
      "action 0\n",
      "observation [ 0.12176548 -0.95674984 -0.08997181  1.14169215]\n",
      "aprob: 0.718426380207\n",
      "action 0\n",
      "observation [ 0.10263048 -1.15058818 -0.06713797  1.40485757]\n",
      "aprob: 0.766285877987\n",
      "action 1\n",
      "observation [ 0.07961872 -0.95469994 -0.03904082  1.09196346]\n",
      "aprob: 0.721793865575\n",
      "action 1\n",
      "observation [ 0.06052472 -0.75908587 -0.01720155  0.78729085]\n",
      "aprob: 0.672392706092\n",
      "action 1\n",
      "observation [ 0.045343   -0.5637319  -0.00145573  0.48924625]\n",
      "aprob: 0.618585510649\n",
      "action 1\n",
      "observation [ 0.03406836 -0.36858944  0.00832919  0.19610488]\n",
      "aprob: 0.561185737197\n",
      "action 0\n",
      "observation [ 0.02669657 -0.56382954  0.01225129  0.49140362]\n",
      "aprob: 0.622585597641\n",
      "action 0\n",
      "observation [ 0.01541998 -0.75912214  0.02207936  0.78792233]\n",
      "aprob: 0.681551759956\n",
      "action 1\n",
      "observation [  2.37540490e-04  -5.64310315e-01   3.78378092e-02   5.02266621e-01]\n",
      "aprob: 0.630190779329\n",
      "action 1\n",
      "observation [-0.01104867 -0.36974156  0.04788314  0.22174405]\n",
      "aprob: 0.575264346291\n",
      "action 0\n",
      "observation [-0.0184435  -0.56551406  0.05231802  0.52913848]\n",
      "aprob: 0.637758902641\n",
      "action 0\n",
      "observation [-0.02975378 -0.76133149  0.06290079  0.83783721]\n",
      "aprob: 0.697188500557\n",
      "action 1\n",
      "observation [-0.04498041 -0.56712235  0.07965754  0.56558025]\n",
      "aprob: 0.649055980438\n",
      "action 1\n",
      "observation [-0.05632286 -0.37320299  0.09096914  0.29901813]\n",
      "aprob: 0.597379586812\n",
      "action 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation [-0.06378691 -0.17948754  0.0969495   0.03635448]\n",
      "aprob: 0.542871895257\n",
      "action 1\n",
      "observation [-0.06737667  0.0141201   0.09767659 -0.2242347 ]\n",
      "aprob: 0.509232054715\n",
      "action 0\n",
      "observation [-0.06709426 -0.18225235  0.0931919   0.09759121]\n",
      "aprob: 0.551965184629\n",
      "action 0\n",
      "observation [-0.07073931 -0.37857782  0.09514372  0.41816035]\n",
      "aprob: 0.616797837785\n",
      "action 1\n",
      "observation [-0.07831087 -0.18492382  0.10350693  0.1569232 ]\n",
      "aprob: 0.563566453569\n",
      "action 1\n",
      "observation [-0.08200934  0.0085756   0.10664539 -0.10139578]\n",
      "aprob: 0.517248274343\n",
      "action 1\n",
      "observation [-0.08183783  0.20202036  0.10461748 -0.35862007]\n",
      "aprob: 0.522945192666\n",
      "action 1\n",
      "observation [-0.07779742  0.39551158  0.09744508 -0.61656859]\n",
      "aprob: 0.544008617036\n",
      "action 1\n",
      "observation [-0.06988719  0.58914683  0.08511371 -0.87704001]\n",
      "aprob: 0.564977929682\n",
      "action 0\n",
      "observation [-0.05810426  0.39297764  0.06757291 -0.55885819]\n",
      "aprob: 0.543149949419\n",
      "action 0\n",
      "observation [-0.0502447   0.1969755   0.05639574 -0.24567463]\n",
      "aprob: 0.521203564484\n",
      "action 0\n",
      "observation [-0.04630519  0.00109532  0.05148225  0.06425007]\n",
      "aprob: 0.522958350896\n",
      "action 0\n",
      "observation [-0.04628329 -0.19472551  0.05276725  0.37272124]\n",
      "aprob: 0.585441095559\n",
      "action 0\n",
      "observation [-0.0501778  -0.3905558   0.06022168  0.68156421]\n",
      "aprob: 0.647637946572\n",
      "action 1\n",
      "observation [-0.05798891 -0.19631964  0.07385296  0.40843259]\n",
      "aprob: 0.594891881008\n",
      "action 1\n",
      "observation [-0.06191531 -0.00231827  0.08202161  0.13991683]\n",
      "aprob: 0.540406415573\n",
      "action 0\n",
      "observation [-0.06196167 -0.19851334  0.08481995  0.45730737]\n",
      "aprob: 0.604027137196\n",
      "action 1\n",
      "observation [-0.06593194 -0.00468651  0.0939661   0.19251953]\n",
      "aprob: 0.550381860127\n",
      "action 0\n",
      "observation [-0.06602567 -0.20101829  0.09781649  0.5133034 ]\n",
      "aprob: 0.614416867345\n",
      "action 1\n",
      "observation [-0.07004603 -0.00740026  0.10808255  0.25297686]\n",
      "aprob: 0.561931134431\n",
      "action 0\n",
      "observation [-0.07019404 -0.20388619  0.11314209  0.57770039]\n",
      "aprob: 0.626240067192\n",
      "action 0\n",
      "observation [-0.07427176 -0.40039691  0.1246961   0.90377466]\n",
      "aprob: 0.688402668875\n",
      "action 1\n",
      "observation [-0.0822797  -0.20716441  0.14277159  0.65274215]\n",
      "aprob: 0.642094934751\n",
      "action 1\n",
      "observation [-0.08642299 -0.01428887  0.15582644  0.40820488]\n",
      "aprob: 0.59359540559\n",
      "action 0\n",
      "observation [-0.08670877 -0.21123727  0.16399053  0.74567582]\n",
      "aprob: 0.658298034839\n",
      "action 1\n",
      "observation [-0.09093351 -0.01871215  0.17890405  0.50876001]\n",
      "aprob: 0.612601532327\n",
      "action 0\n",
      "observation [-0.09130775 -0.21584374  0.18907925  0.85205553]\n",
      "aprob: 0.676456738717\n",
      "action 1\n",
      "observation [-0.09562463 -0.02373276  0.20612036  0.6242835 ]\n",
      "aprob: 0.634055684617\n",
      "action 1\n",
      "resetting env. episode reward total was 83.000000. running mean: 45.180948\n",
      "observation [ 0.00231717  0.0174209   0.00203596 -0.01269987]\n",
      "aprob: 0.501694907432\n",
      "action 0\n",
      "observation [ 0.00266558 -0.17773019  0.00178196  0.28062472]\n",
      "aprob: 0.558210226535\n",
      "action 1\n",
      "observation [-0.00088902  0.01736629  0.00739445 -0.01149565]\n",
      "aprob: 0.50164426324\n",
      "action 0\n",
      "observation [-0.00054169 -0.17786092  0.00716454  0.28351112]\n",
      "aprob: 0.559749607001\n",
      "action 1\n",
      "observation [-0.00409891  0.01715812  0.01283476 -0.00690357]\n",
      "aprob: 0.502849526648\n",
      "action 0\n",
      "observation [-0.00375575 -0.17814553  0.01269669  0.28980109]\n",
      "aprob: 0.561824270799\n",
      "action 0\n",
      "observation [-0.00731866 -0.37344621  0.01849271  0.58646121]\n",
      "aprob: 0.623284924377\n",
      "action 1\n",
      "observation [-0.01478759 -0.17858808  0.03022194  0.29966055]\n",
      "aprob: 0.566951083255\n",
      "action 0\n",
      "observation [-0.01835935 -0.37412748  0.03621515  0.60171961]\n",
      "aprob: 0.628969284224\n",
      "action 0\n",
      "observation [-0.0258419  -0.5697368   0.04824954  0.90558613]\n",
      "aprob: 0.688351796916\n",
      "action 1\n",
      "observation [-0.03723663 -0.37530025  0.06636126  0.62845059]\n",
      "aprob: 0.638673412273\n",
      "action 1\n",
      "observation [-0.04474264 -0.18116414  0.07893027  0.35738328]\n",
      "aprob: 0.585570523944\n",
      "action 1\n",
      "observation [-0.04836592  0.01275214  0.08607794  0.09059587]\n",
      "aprob: 0.531748699586\n",
      "action 0\n",
      "observation [-0.04811088 -0.18349139  0.08788986  0.40914697]\n",
      "aprob: 0.594856234799\n",
      "action 1\n",
      "observation [-0.05178071  0.01028167  0.0960728   0.14541565]\n",
      "aprob: 0.541645153444\n",
      "action 1\n",
      "observation [-0.05157507  0.20390587  0.09898111 -0.11547935]\n",
      "aprob: 0.522313276117\n",
      "action 0\n",
      "observation [-0.04749695  0.00751526  0.09667152  0.20671763]\n",
      "aprob: 0.550870358052\n",
      "action 0\n",
      "observation [-0.04734665 -0.1888466   0.10080587  0.52826237]\n",
      "aprob: 0.614063616743\n",
      "action 0\n",
      "observation [-0.05112358 -0.38523156  0.11137112  0.8509311 ]\n",
      "aprob: 0.676598889078\n",
      "action 1\n",
      "observation [-0.05882821 -0.19178998  0.12838974  0.59524186]\n",
      "aprob: 0.628640723095\n",
      "action 1\n",
      "observation [-0.06266401  0.00132345  0.14029458  0.34559885]\n",
      "aprob: 0.580035516879\n",
      "action 0\n",
      "observation [-0.06263754 -0.19548635  0.14720656  0.67902446]\n",
      "aprob: 0.64345114014\n",
      "action 0\n",
      "observation [-0.06654727 -0.39231327  0.16078705  1.01419431]\n",
      "aprob: 0.705491042504\n",
      "action 1\n",
      "observation [-0.07439354 -0.19965835  0.18107093  0.77600732]\n",
      "aprob: 0.662510734895\n",
      "action 1\n",
      "observation [-0.0783867  -0.00742718  0.19659108  0.54531906]\n",
      "aprob: 0.619698066747\n",
      "action 0\n",
      "observation [-0.07853525 -0.2046891   0.20749746  0.89293869]\n",
      "aprob: 0.682085749179\n",
      "action 0\n",
      "resetting env. episode reward total was 26.000000. running mean: 44.989139\n",
      "observation [ 0.03571128  0.04392379 -0.03399184  0.04177954]\n",
      "aprob: 0.504990328583\n",
      "action 1\n",
      "observation [ 0.03658975  0.23951627 -0.03315625 -0.26143138]\n",
      "aprob: 0.525270929005\n",
      "action 1\n",
      "observation [ 0.04138008  0.43509545 -0.03838487 -0.56438505]\n",
      "aprob: 0.547065501522\n",
      "action 0\n",
      "observation [ 0.05008199  0.24053249 -0.04967257 -0.28403797]\n",
      "aprob: 0.525699811583\n",
      "action 1\n",
      "observation [ 0.05489264  0.43632642 -0.05535333 -0.59196435]\n",
      "aprob: 0.547583197657\n",
      "action 0\n",
      "observation [ 0.06361916  0.2420213  -0.06719262 -0.31721864]\n",
      "aprob: 0.52632659397\n",
      "action 1\n",
      "observation [ 0.06845959  0.43803275 -0.07353699 -0.63031211]\n",
      "aprob: 0.548303201677\n",
      "action 0\n",
      "observation [ 0.07722025  0.24400978 -0.08614324 -0.36166461]\n",
      "aprob: 0.527168859766\n",
      "action 1\n",
      "observation [ 0.08210044  0.44024378 -0.09337653 -0.68021895]\n",
      "aprob: 0.549244599484\n",
      "action 1\n",
      "observation [ 0.09090532  0.63653016 -0.10698091 -1.00077869]\n",
      "aprob: 0.571191826047\n",
      "action 1\n",
      "observation [ 0.10363592  0.83290654 -0.12699648 -1.32505165]\n",
      "aprob: 0.592951200702\n",
      "action 1\n",
      "observation [ 0.12029405  1.02938271 -0.15349751 -1.6546292 ]\n",
      "aprob: 0.614460898152\n",
      "action 1\n",
      "observation [ 0.14088171  1.22592705 -0.1865901  -1.99093062]\n",
      "aprob: 0.635655468624\n",
      "action 1\n",
      "resetting env. episode reward total was 13.000000. running mean: 44.669248\n",
      "observation [ 0.01000878 -0.0081016   0.03792067  0.02130358]\n",
      "aprob: 0.50921264243\n",
      "action 1\n",
      "observation [ 0.00984675  0.18645659  0.03834675 -0.2591779 ]\n",
      "aprob: 0.519762732415\n",
      "action 0\n",
      "observation [ 0.01357588 -0.00919121  0.03316319  0.04534925]\n",
      "aprob: 0.511818613044\n",
      "action 1\n",
      "observation [ 0.01339206  0.18543989  0.03407017 -0.23668868]\n",
      "aprob: 0.5193785323\n",
      "action 0\n",
      "observation [ 0.01710085 -0.01015183  0.0293364   0.06654333]\n",
      "aprob: 0.514371870331\n",
      "action 1\n",
      "observation [ 0.01689782  0.1845375   0.03066727 -0.21674135]\n",
      "aprob: 0.519026348071\n",
      "action 1\n",
      "observation [ 0.02058857  0.37920793  0.02633244 -0.49959493]\n",
      "aprob: 0.540511735775\n",
      "action 0\n",
      "observation [ 0.02817273  0.18372483  0.01634054 -0.1987311 ]\n",
      "aprob: 0.518749326586\n",
      "action 0\n",
      "observation [ 0.03184722 -0.01162698  0.01236592  0.0990614 ]\n",
      "aprob: 0.516356592536\n",
      "action 1\n",
      "observation [ 0.03161468  0.18331558  0.01434715 -0.18969459]\n",
      "aprob: 0.518567761174\n",
      "action 1\n",
      "observation [ 0.035281    0.37822937  0.01055325 -0.47781727]\n",
      "aprob: 0.540139901646\n",
      "action 1\n",
      "observation [ 0.04284558  0.57320075  0.00099691 -0.76715545]\n",
      "aprob: 0.561608307973\n",
      "action 0\n",
      "observation [ 0.0543096   0.37806508 -0.0143462  -0.47415901]\n",
      "aprob: 0.540149551718\n",
      "action 0\n",
      "observation [ 0.0618709   0.18314864 -0.02382938 -0.18603206]\n",
      "aprob: 0.518599636564\n",
      "action 1\n",
      "observation [ 0.06553387  0.37860329 -0.02755002 -0.48613597]\n",
      "aprob: 0.540378606712\n",
      "action 1\n",
      "observation [ 0.07310594  0.57410294 -0.03727274 -0.78737285]\n",
      "aprob: 0.562051158774\n",
      "action 0\n",
      "observation [ 0.084588    0.37951227 -0.0530202  -0.50664523]\n",
      "aprob: 0.540814180197\n",
      "action 0\n",
      "observation [ 0.09217824  0.18517595 -0.0631531  -0.23113101]\n",
      "aprob: 0.519497887946\n",
      "action 1\n",
      "observation [ 0.09588176  0.3811408  -0.06777572 -0.54304698]\n",
      "aprob: 0.541487694032\n",
      "action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation [ 0.10350458  0.18703353 -0.07863666 -0.27246537]\n",
      "aprob: 0.520271802907\n",
      "action 0\n",
      "observation [ 0.10724525 -0.00688342 -0.08408597 -0.00558417]\n",
      "aprob: 0.50546404268\n",
      "action 1\n",
      "observation [ 0.10710758  0.18933749 -0.08419765 -0.32356778]\n",
      "aprob: 0.521189411594\n",
      "action 0\n",
      "observation [ 0.11089433 -0.00449093 -0.09066901 -0.05857999]\n",
      "aprob: 0.505023930795\n",
      "action 0\n",
      "observation [ 0.11080451 -0.19820377 -0.09184061  0.20417554]\n",
      "aprob: 0.524181375474\n",
      "action 0\n",
      "observation [ 0.10684043 -0.3919005  -0.0877571   0.46653298]\n",
      "aprob: 0.581720244673\n",
      "action 1\n",
      "observation [ 0.09900242 -0.19565535 -0.07842644  0.14753055]\n",
      "aprob: 0.518680654601\n",
      "action 1\n",
      "observation [ 0.09508932  0.00049698 -0.07547583 -0.1688273 ]\n",
      "aprob: 0.504471071623\n",
      "action 0\n",
      "observation [ 0.09509926 -0.19346804 -0.07885237  0.09912309]\n",
      "aprob: 0.516614971075\n",
      "action 1\n",
      "observation [ 0.0912299   0.00269027 -0.07686991 -0.2173587 ]\n",
      "aprob: 0.505313172703\n",
      "action 0\n",
      "observation [ 0.0912837  -0.19125344 -0.08121708  0.05012028]\n",
      "aprob: 0.515687644785\n",
      "action 1\n",
      "observation [ 0.08745863  0.00493349 -0.08021468 -0.26704165]\n",
      "aprob: 0.506163665771\n",
      "action 0\n",
      "observation [ 0.0875573  -0.18895748 -0.08555551 -0.00069821]\n",
      "aprob: 0.515302500761\n",
      "action 1\n",
      "observation [ 0.08377815  0.00728063 -0.08556948 -0.31910138]\n",
      "aprob: 0.507045621059\n",
      "action 0\n",
      "observation [ 0.08392377 -0.18652502 -0.0919515  -0.05458329]\n",
      "aprob: 0.514949841035\n",
      "action 0\n",
      "observation [ 0.08019327 -0.38021644 -0.09304317  0.20773079]\n",
      "aprob: 0.544589455992\n",
      "action 0\n",
      "observation [ 0.07258894 -0.57389329 -0.08888855  0.46967423]\n",
      "aprob: 0.601841218901\n",
      "action 1\n",
      "observation [ 0.06111107 -0.37763552 -0.07949507  0.15035097]\n",
      "aprob: 0.539762363254\n",
      "action 0\n",
      "observation [ 0.05355836 -0.57153447 -0.07648805  0.41693394]\n",
      "aprob: 0.597690346485\n",
      "action 1\n",
      "observation [ 0.04212767 -0.3754166  -0.06814937  0.10115167]\n",
      "aprob: 0.535843180273\n",
      "action 0\n",
      "observation [ 0.03461934 -0.56949904 -0.06612634  0.37157914]\n",
      "aprob: 0.594319001176\n",
      "action 1\n",
      "observation [ 0.02322936 -0.37350302 -0.05869475  0.05880068]\n",
      "aprob: 0.532679559217\n",
      "action 0\n",
      "observation [ 0.0157593  -0.56773642 -0.05751874  0.33240272]\n",
      "aprob: 0.59159703459\n",
      "action 1\n",
      "observation [ 0.00440457 -0.37184495 -0.05087069  0.02215026]\n",
      "aprob: 0.532107245493\n",
      "action 1\n",
      "observation [-0.00303233 -0.17603177 -0.05042768 -0.28613908]\n",
      "aprob: 0.516250657667\n",
      "action 1\n",
      "observation [-0.00655297  0.01977173 -0.05615046 -0.59429044]\n",
      "aprob: 0.517357835928\n",
      "action 1\n",
      "observation [-0.00615753  0.2156328  -0.06803627 -0.90411857]\n",
      "aprob: 0.532821104923\n",
      "action 1\n",
      "observation [-0.00184487  0.41160699 -0.08611864 -1.21738699]\n",
      "aprob: 0.554929635574\n",
      "action 1\n",
      "observation [ 0.00638727  0.60772738 -0.11046638 -1.53576497]\n",
      "aprob: 0.576933705143\n",
      "action 1\n",
      "observation [ 0.01854181  0.80399252 -0.14118168 -1.86077937]\n",
      "aprob: 0.598766695714\n",
      "action 0\n",
      "observation [ 0.03462166  0.61067327 -0.17839727 -1.61505533]\n",
      "aprob: 0.578782438851\n",
      "action 0\n",
      "resetting env. episode reward total was 50.000000. running mean: 44.722555\n",
      "observation [ 0.04780385  0.01113725  0.02047119  0.04567218]\n",
      "aprob: 0.508046961544\n",
      "action 0\n",
      "observation [ 0.0480266  -0.18427217  0.02138464  0.34474301]\n",
      "aprob: 0.566511929689\n",
      "action 1\n",
      "observation [ 0.04434115  0.01053915  0.0282795   0.05887944]\n",
      "aprob: 0.511428191556\n",
      "action 0\n",
      "observation [ 0.04455194 -0.18497662  0.02945709  0.3603489 ]\n",
      "aprob: 0.570372716601\n",
      "action 1\n",
      "observation [ 0.0408524   0.00971449  0.03666406  0.07709806]\n",
      "aprob: 0.515706018158\n",
      "action 0\n",
      "observation [ 0.04104669 -0.18591336  0.03820602  0.38111945]\n",
      "aprob: 0.5750995861\n",
      "action 1\n",
      "observation [ 0.03732843  0.00864583  0.04582841  0.10072346]\n",
      "aprob: 0.520943404119\n",
      "action 1\n",
      "observation [ 0.03750134  0.20308205  0.04784288 -0.17715581]\n",
      "aprob: 0.5196184204\n",
      "action 0\n",
      "observation [ 0.04156298  0.00730924  0.04429977  0.13022783]\n",
      "aprob: 0.525110225335\n",
      "action 1\n",
      "observation [ 0.04170917  0.20176952  0.04690432 -0.14815655]\n",
      "aprob: 0.51906096257\n",
      "action 1\n",
      "observation [ 0.04574456  0.39618952  0.04394119 -0.42568099]\n",
      "aprob: 0.540427332789\n",
      "action 1\n",
      "observation [ 0.05366835  0.5906624   0.03542757 -0.70419419]\n",
      "aprob: 0.561685401085\n",
      "action 1\n",
      "observation [ 0.0654816   0.78527597  0.02134369 -0.98551783]\n",
      "aprob: 0.58278992891\n",
      "action 0\n",
      "observation [ 0.08118712  0.58987475  0.00163333 -0.68620819]\n",
      "aprob: 0.561450588696\n",
      "action 0\n",
      "observation [ 0.09298461  0.39473016 -0.01209083 -0.3930115 ]\n",
      "aprob: 0.539958079261\n",
      "action 1\n",
      "observation [ 0.10087922  0.59002158 -0.01995106 -0.68948184]\n",
      "aprob: 0.561520955002\n",
      "action 0\n",
      "observation [ 0.11267965  0.3951821  -0.0337407  -0.40314601]\n",
      "aprob: 0.540148690747\n",
      "action 1\n",
      "observation [ 0.12058329  0.59076594 -0.04180362 -0.70627268]\n",
      "aprob: 0.561826515148\n",
      "action 1\n",
      "observation [ 0.13239861  0.78644138 -0.05592907 -1.01181609]\n",
      "aprob: 0.583338608902\n",
      "action 1\n",
      "observation [ 0.14812744  0.98226316 -0.07616539 -1.32152404]\n",
      "aprob: 0.604632373318\n",
      "action 1\n",
      "observation [ 0.1677727   1.17826053 -0.10259588 -1.63703874]\n",
      "aprob: 0.625653129274\n",
      "action 1\n",
      "observation [ 0.19133791  1.37442523 -0.13533665 -1.95984883]\n",
      "aprob: 0.646343075632\n",
      "action 0\n",
      "observation [ 0.21882641  1.18097267 -0.17453363 -1.71199102]\n",
      "aprob: 0.627077610869\n",
      "action 1\n",
      "observation [ 0.24244587  1.37761676 -0.20877345 -2.05352869]\n",
      "aprob: 0.648020731854\n",
      "action 0\n",
      "resetting env. episode reward total was 24.000000. running mean: 44.515330\n",
      "observation [-0.01828807  0.03846426  0.0125289   0.03651015]\n",
      "aprob: 0.511410348664\n",
      "action 1\n",
      "observation [-0.01751878  0.23340433  0.0132591  -0.25219359]\n",
      "aprob: 0.52474174964\n",
      "action 1\n",
      "observation [-0.0128507   0.42833446  0.00821523 -0.54066503]\n",
      "aprob: 0.546288340408\n",
      "action 0\n",
      "observation [-0.00428401  0.233098   -0.00259807 -0.24540498]\n",
      "aprob: 0.5246529281\n",
      "action 0\n",
      "observation [ 0.00037795  0.03801326 -0.00750617  0.04645733]\n",
      "aprob: 0.508090569673\n",
      "action 1\n",
      "observation [ 0.00113822  0.23324203 -0.00657702 -0.24858438]\n",
      "aprob: 0.524683384243\n",
      "action 1\n",
      "observation [ 0.00580306  0.42845729 -0.01154871 -0.54333457]\n",
      "aprob: 0.54633826015\n",
      "action 1\n",
      "observation [ 0.0143722   0.62373962 -0.0224154  -0.83963377]\n",
      "aprob: 0.567871732901\n",
      "action 1\n",
      "observation [ 0.026847    0.81916034 -0.03920808 -1.13928078]\n",
      "aprob: 0.589233522526\n",
      "action 1\n",
      "observation [ 0.0432302   1.01477238 -0.06199369 -1.44399757]\n",
      "aprob: 0.610371801365\n",
      "action 0\n",
      "observation [ 0.06352565  0.82046578 -0.09087364 -1.17131202]\n",
      "aprob: 0.589952609128\n",
      "action 1\n",
      "observation [ 0.07993497  1.01664414 -0.11429988 -1.49104547]\n",
      "aprob: 0.61132667236\n",
      "action 1\n",
      "observation [ 0.10026785  1.21295686 -0.14412079 -1.81712414]\n",
      "aprob: 0.632402662643\n",
      "action 0\n",
      "observation [ 0.12452699  1.01970233 -0.18046328 -1.57247266]\n",
      "aprob: 0.612897858706\n",
      "action 1\n",
      "resetting env. episode reward total was 14.000000. running mean: 44.210176\n",
      "observation [ 0.04697551 -0.00206209 -0.04105502  0.02122304]\n",
      "aprob: 0.502737167334\n",
      "action 0\n",
      "observation [ 0.04693427 -0.19657195 -0.04063056  0.3006752 ]\n",
      "aprob: 0.552288137572\n",
      "action 0\n",
      "observation [ 0.04300283 -0.39109194 -0.03461706  0.58027228]\n",
      "aprob: 0.611749595037\n",
      "action 1\n",
      "observation [ 0.03518099 -0.19550244 -0.02301161  0.27688841]\n",
      "aprob: 0.552427788946\n",
      "action 0\n",
      "observation [ 0.03127094 -0.39028866 -0.01747385  0.56222557]\n",
      "aprob: 0.612651800168\n",
      "action 1\n",
      "observation [ 0.02346517 -0.19492592 -0.00622933  0.26408914]\n",
      "aprob: 0.554107649859\n",
      "action 1\n",
      "observation [ 0.01956665  0.00028439 -0.00094755 -0.03055206]\n",
      "aprob: 0.500853867217\n",
      "action 1\n",
      "observation [ 0.01957234  0.19541992 -0.00155859 -0.32353379]\n",
      "aprob: 0.521876193945\n",
      "action 1\n",
      "observation [ 0.02348074  0.39056403 -0.00802927 -0.61670783]\n",
      "aprob: 0.543553955307\n",
      "action 0\n",
      "observation [ 0.03129202  0.19555516 -0.02036342 -0.32656454]\n",
      "aprob: 0.522025288118\n",
      "action 0\n",
      "observation [ 0.03520312  0.00072897 -0.02689472 -0.04037227]\n",
      "aprob: 0.50136917141\n",
      "action 1\n",
      "observation [ 0.0352177   0.19622605 -0.02770216 -0.34141794]\n",
      "aprob: 0.52233198977\n",
      "action 1\n",
      "observation [ 0.03914222  0.39173097 -0.03453052 -0.64270619]\n",
      "aprob: 0.544152335575\n",
      "action 0\n",
      "observation [ 0.04697684  0.1971069  -0.04738464 -0.36109407]\n",
      "aprob: 0.522783157814\n",
      "action 0\n",
      "observation [ 0.05091898  0.00268939 -0.05460652 -0.08372101]\n",
      "aprob: 0.502367973689\n",
      "action 0\n",
      "observation [ 0.05097277 -0.191609   -0.05628095  0.19124581]\n",
      "aprob: 0.532934819053\n",
      "action 1\n",
      "observation [ 0.04714058  0.00427104 -0.05245603 -0.11864689]\n",
      "aprob: 0.502802931934\n",
      "action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation [ 0.04722601 -0.19006163 -0.05482897  0.15703615]\n",
      "aprob: 0.528300963359\n",
      "action 0\n",
      "observation [ 0.04342477 -0.38435745 -0.05168824  0.43193028]\n",
      "aprob: 0.587452795753\n",
      "action 1\n",
      "observation [ 0.03573762 -0.18854318 -0.04304964  0.12341158]\n",
      "aprob: 0.526053962471\n",
      "action 1\n",
      "observation [ 0.03196676  0.00716824 -0.04058141 -0.18253625]\n",
      "aprob: 0.504258580578\n",
      "action 1\n",
      "observation [ 0.03211013  0.20284666 -0.04423213 -0.48773989]\n",
      "aprob: 0.525176220594\n",
      "action 0\n",
      "observation [ 0.03616706  0.0083758  -0.05398693 -0.20931891]\n",
      "aprob: 0.504799226212\n",
      "action 0\n",
      "observation [ 0.03633457 -0.18593431 -0.05817331  0.06585716]\n",
      "aprob: 0.516620118368\n",
      "action 0\n",
      "observation [ 0.03261589 -0.38017606 -0.05685616  0.3396336 ]\n",
      "aprob: 0.573999511352\n",
      "action 1\n",
      "observation [ 0.02501237 -0.18429314 -0.05006349  0.0295773 ]\n",
      "aprob: 0.515789467461\n",
      "action 1\n",
      "observation [ 0.0213265   0.01150968 -0.04947195 -0.27847145]\n",
      "aprob: 0.507226815061\n",
      "action 0\n",
      "observation [ 0.0215567  -0.18287289 -0.05504138 -0.00179316]\n",
      "aprob: 0.515501975325\n",
      "action 0\n",
      "observation [ 0.01789924 -0.37716404 -0.05507724  0.27302821]\n",
      "aprob: 0.565711217104\n",
      "action 1\n",
      "observation [ 0.01035596 -0.18130123 -0.04961667 -0.03650502]\n",
      "aprob: 0.515243000689\n",
      "action 1\n",
      "observation [ 0.00672994  0.01449583 -0.05034677 -0.34442049]\n",
      "aprob: 0.50971874875\n",
      "action 0\n",
      "observation [ 0.00701985 -0.1798751  -0.05723518 -0.06802923]\n",
      "aprob: 0.515150903136\n",
      "action 1\n",
      "observation [ 0.00342235  0.01601873 -0.05859577 -0.37820678]\n",
      "aprob: 0.510940692656\n",
      "action 0\n",
      "observation [ 0.00374272 -0.17822422 -0.0661599  -0.1045597 ]\n",
      "aprob: 0.515034073926\n",
      "action 0\n",
      "observation [  1.78239804e-04  -3.72338733e-01  -6.82510989e-02   1.66538225e-01]\n",
      "aprob: 0.549467240724\n",
      "action 1\n",
      "observation [-0.00726853 -0.17630956 -0.06492033 -0.1468712 ]\n",
      "aprob: 0.514785767115\n",
      "action 0\n",
      "observation [-0.01079473 -0.37044465 -0.06785776  0.12464483]\n",
      "aprob: 0.544264650628\n",
      "action 1\n",
      "observation [-0.01820362 -0.17441947 -0.06536486 -0.18865109]\n",
      "aprob: 0.515382477192\n",
      "action 1\n",
      "observation [-0.02169201  0.02157378 -0.06913788 -0.50121675]\n",
      "aprob: 0.515933801959\n",
      "action 1\n",
      "observation [-0.02126053  0.21759873 -0.07916222 -0.81486204]\n",
      "aprob: 0.53220950039\n",
      "action 0\n",
      "observation [-0.01690856  0.02364487 -0.09545946 -0.54809174]\n",
      "aprob: 0.517245511667\n",
      "action 0\n",
      "observation [-0.01643566 -0.17001556 -0.10642129 -0.28694613]\n",
      "aprob: 0.517761406093\n",
      "action 0\n",
      "observation [-0.01983597 -0.36347159 -0.11216022 -0.0296326 ]\n",
      "aprob: 0.53204712616\n",
      "action 1\n",
      "observation [-0.0271054  -0.1669348  -0.11275287 -0.35549143]\n",
      "aprob: 0.519386517185\n",
      "action 1\n",
      "observation [-0.0304441   0.0295946  -0.1198627  -0.68149278]\n",
      "aprob: 0.522001854943\n",
      "action 1\n",
      "observation [-0.02985221  0.22615931 -0.13349255 -1.00937964]\n",
      "aprob: 0.537552467004\n",
      "action 1\n",
      "observation [-0.02532902  0.42278592 -0.15368015 -1.34082584]\n",
      "aprob: 0.558907969987\n",
      "action 0\n",
      "observation [-0.0168733   0.22989566 -0.18049666 -1.09990476]\n",
      "aprob: 0.539807716067\n",
      "action 1\n",
      "observation [-0.01227539  0.42687397 -0.20249476 -1.4433506 ]\n",
      "aprob: 0.561136966067\n",
      "action 1\n",
      "resetting env. episode reward total was 49.000000. running mean: 44.258075\n",
      "observation [-0.03230861  0.01268875 -0.01663813  0.03185068]\n",
      "aprob: 0.506929042485\n",
      "action 1\n",
      "observation [-0.03205483  0.2080453  -0.01600111 -0.26603497]\n",
      "aprob: 0.523270707848\n",
      "action 0\n",
      "observation [-0.02789392  0.01315534 -0.02132181  0.02155843]\n",
      "aprob: 0.504274846667\n",
      "action 1\n",
      "observation [-0.02763082  0.20857647 -0.02089065 -0.27777478]\n",
      "aprob: 0.523479331622\n",
      "action 1\n",
      "observation [-0.02345929  0.40399013 -0.02644614 -0.57697271]\n",
      "aprob: 0.545234503765\n",
      "action 0\n",
      "observation [-0.01537949  0.20924865 -0.0379856  -0.2927369 ]\n",
      "aprob: 0.523802854194\n",
      "action 0\n",
      "observation [-0.01119451  0.0146883  -0.04384033 -0.01227198]\n",
      "aprob: 0.503106967503\n",
      "action 0\n",
      "observation [-0.01090075 -0.1797784  -0.04408577  0.26626286]\n",
      "aprob: 0.550985843799\n",
      "action 0\n",
      "observation [-0.01449632 -0.37424432 -0.03876052  0.54472131]\n",
      "aprob: 0.610203086173\n",
      "action 0\n",
      "observation [-0.0219812  -0.56880079 -0.02786609  0.82494408]\n",
      "aprob: 0.667661007459\n",
      "action 0\n",
      "observation [-0.03335722 -0.76353074 -0.01136721  1.10873404]\n",
      "aprob: 0.721951029316\n",
      "action 1\n",
      "observation [-0.04862783 -0.56826126  0.01080747  0.81250685]\n",
      "aprob: 0.673402599632\n",
      "action 0\n",
      "observation [-0.05999306 -0.76352957  0.02705761  1.10856954]\n",
      "aprob: 0.728598248245\n",
      "action 1\n",
      "observation [-0.07526365 -0.56877347  0.049229    0.82449628]\n",
      "aprob: 0.682312169417\n",
      "action 0\n",
      "observation [-0.08663912 -0.76453297  0.06571893  1.13224728]\n",
      "aprob: 0.738005339909\n",
      "action 0\n",
      "observation [-0.10192978 -0.96045076  0.08836387  1.44479702]\n",
      "aprob: 0.788344353923\n",
      "action 1\n",
      "observation [-0.12113879 -0.76652027  0.11725981  1.18098142]\n",
      "aprob: 0.752096470999\n",
      "action 1\n",
      "observation [-0.1364692  -0.57309915  0.14087944  0.92723752]\n",
      "aprob: 0.712219810041\n",
      "action 0\n",
      "observation [-0.14793118 -0.76981332  0.15942419  1.26066716]\n",
      "aprob: 0.767512511251\n",
      "action 1\n",
      "observation [-0.16332745 -0.57704852  0.18463753  1.02185909]\n",
      "aprob: 0.731216422285\n",
      "action 1\n",
      "observation [-0.17486842 -0.38480187  0.20507472  0.79236611]\n",
      "aprob: 0.691823309924\n",
      "action 1\n",
      "resetting env. episode reward total was 21.000000. running mean: 44.025494\n",
      "observation [ 0.02816104  0.00064877 -0.02988009 -0.02600662]\n",
      "aprob: 0.501167950875\n",
      "action 0\n",
      "observation [ 0.02817401 -0.19403222 -0.03040022  0.25710107]\n",
      "aprob: 0.549002625583\n",
      "action 0\n",
      "observation [ 0.02429337 -0.38870726 -0.0252582   0.54004241]\n",
      "aprob: 0.60895315551\n",
      "action 1\n",
      "observation [ 0.01651922 -0.19323953 -0.01445735  0.23950922]\n",
      "aprob: 0.54982898826\n",
      "action 0\n",
      "observation [ 0.01265443 -0.388152   -0.00966717  0.52759706]\n",
      "aprob: 0.610448455649\n",
      "action 1\n",
      "observation [ 0.00489139 -0.19289537  0.00088477  0.2318837 ]\n",
      "aprob: 0.552077158262\n",
      "action 1\n",
      "observation [ 0.00103349  0.00221392  0.00552244 -0.06052001]\n",
      "aprob: 0.501855643922\n",
      "action 1\n",
      "observation [ 0.00107776  0.19725626  0.00431204 -0.35145546]\n",
      "aprob: 0.522614575476\n",
      "action 1\n",
      "observation [ 0.00502289  0.39231663 -0.00271706 -0.64277555]\n",
      "aprob: 0.544263565671\n",
      "action 0\n",
      "observation [ 0.01286922  0.19723265 -0.01557258 -0.35094949]\n",
      "aprob: 0.522716857761\n",
      "action 0\n",
      "observation [ 0.01681387  0.00233558 -0.02259157 -0.06321749]\n",
      "aprob: 0.501368286284\n",
      "action 1\n",
      "observation [ 0.01686059  0.19777404 -0.02385592 -0.36294171]\n",
      "aprob: 0.522986508274\n",
      "action 0\n",
      "observation [ 0.02081607  0.00299913 -0.03111475 -0.07787545]\n",
      "aprob: 0.501663371587\n",
      "action 0\n",
      "observation [ 0.02087605 -0.19166328 -0.03267226  0.20483056]\n",
      "aprob: 0.541457675295\n",
      "action 0\n",
      "observation [ 0.01704278 -0.38630314 -0.02857565  0.4870306 ]\n",
      "aprob: 0.601422325403\n",
      "action 1\n",
      "observation [ 0.00931672 -0.19078988 -0.01883504  0.18548035]\n",
      "aprob: 0.54170135471\n",
      "action 0\n",
      "observation [ 0.00550092 -0.38563735 -0.01512543  0.47216254]\n",
      "aprob: 0.60226062035\n",
      "action 0\n",
      "observation [-0.00221182 -0.58054244 -0.00568218  0.76004002]\n",
      "aprob: 0.661119872373\n",
      "action 1\n",
      "observation [-0.01382267 -0.38534266  0.00951862  0.46557453]\n",
      "aprob: 0.606643938315\n",
      "action 0\n",
      "observation [-0.02152953 -0.58059781  0.01883011  0.76124242]\n",
      "aprob: 0.666260670166\n",
      "action 0\n",
      "observation [-0.03314148 -0.77597404  0.03405496  1.05979053]\n",
      "aprob: 0.72237007088\n",
      "action 0\n",
      "observation [-0.04866096 -0.97153011  0.05525077  1.36296479]\n",
      "aprob: 0.773662513866\n",
      "action 1\n",
      "observation [-0.06809156 -0.77714222  0.08251007  1.08806334]\n",
      "aprob: 0.734251721978\n",
      "action 1\n",
      "observation [-0.08363441 -0.58319942  0.10427134  0.82236929]\n",
      "aprob: 0.69090134007\n",
      "action 1\n",
      "observation [-0.0952984  -0.3896468   0.12071872  0.56421749]\n",
      "aprob: 0.643894772466\n",
      "action 0\n",
      "observation [-0.10309133 -0.58623725  0.13200307  0.89236225]\n",
      "aprob: 0.705051986313\n",
      "action 0\n",
      "observation [-0.11481608 -0.78287889  0.14985032  1.2234549 ]\n",
      "aprob: 0.76094669854\n",
      "action 1\n",
      "observation [-0.13047366 -0.58997057  0.17431941  0.98122647]\n",
      "aprob: 0.723509263519\n",
      "action 1\n",
      "observation [-0.14227307 -0.39755886  0.19394394  0.74797371]\n",
      "aprob: 0.682896066804\n",
      "action 1\n",
      "observation [-0.15022424 -0.20556575  0.20890342  0.52204608]\n",
      "aprob: 0.639340698435\n",
      "action 1\n",
      "resetting env. episode reward total was 30.000000. running mean: 43.885239\n",
      "observation [ 0.03245199  0.04312357  0.02966035  0.04135587]\n",
      "aprob: 0.510776870253\n",
      "action 0\n",
      "observation [ 0.03331446 -0.15241087  0.03048746  0.34324739]\n",
      "aprob: 0.566151711744\n",
      "action 1\n",
      "observation [ 0.03026624  0.04226438  0.03735241  0.06033213]\n",
      "aprob: 0.514911146079\n",
      "action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation [ 0.03111153 -0.15337267  0.03855905  0.36456207]\n",
      "aprob: 0.5707442118\n",
      "action 0\n",
      "observation [ 0.02804408 -0.34902079  0.0458503   0.66914966]\n",
      "aprob: 0.633060803931\n",
      "action 1\n",
      "observation [ 0.02106366 -0.15456535  0.05923329  0.3912483 ]\n",
      "aprob: 0.57871758316\n",
      "action 1\n",
      "observation [ 0.01797235  0.03966813  0.06705825  0.11781345]\n",
      "aprob: 0.52879355397\n",
      "action 1\n",
      "observation [ 0.01876572  0.23376839  0.06941452 -0.1529822 ]\n",
      "aprob: 0.52206542599\n",
      "action 0\n",
      "observation [ 0.02344109  0.03772472  0.06635488  0.16076662]\n",
      "aprob: 0.534670456742\n",
      "action 1\n",
      "observation [ 0.02419558  0.23183706  0.06957021 -0.1102671 ]\n",
      "aprob: 0.521233974923\n",
      "action 0\n",
      "observation [ 0.02883232  0.03579073  0.06736487  0.20352818]\n",
      "aprob: 0.541075501927\n",
      "action 0\n",
      "observation [ 0.02954814 -0.1602267   0.07143543  0.51667773]\n",
      "aprob: 0.598248577783\n",
      "action 1\n",
      "observation [ 0.0263436   0.0338205   0.08176899  0.24733344]\n",
      "aprob: 0.549993576589\n",
      "action 1\n",
      "observation [ 0.02702001  0.22768522  0.08671566 -0.01847873]\n",
      "aprob: 0.526769401478\n",
      "action 1\n",
      "observation [ 0.03157372  0.42146345  0.08634608 -0.28259143]\n",
      "aprob: 0.540418155714\n",
      "action 0\n",
      "observation [ 0.04000298  0.22522282  0.08069425  0.03602708]\n",
      "aprob: 0.531027530587\n",
      "action 1\n",
      "observation [ 0.04450744  0.41910044  0.0814148  -0.23014466]\n",
      "aprob: 0.539381520419\n",
      "action 0\n",
      "observation [ 0.05288945  0.22291518  0.0768119   0.08706799]\n",
      "aprob: 0.535413949551\n",
      "action 1\n",
      "observation [ 0.05734775  0.41685687  0.07855326 -0.18042626]\n",
      "aprob: 0.538362641028\n",
      "action 0\n",
      "observation [ 0.06568489  0.22070385  0.07494474  0.13596686]\n",
      "aprob: 0.539987712199\n",
      "action 1\n",
      "observation [ 0.07009897  0.41467679  0.07766407 -0.13216268]\n",
      "aprob: 0.537340918007\n",
      "action 0\n",
      "observation [ 0.0783925   0.21853321  0.07502082  0.18397612]\n",
      "aprob: 0.545867063864\n",
      "action 1\n",
      "observation [ 0.08276317  0.41250603  0.07870034 -0.08412928]\n",
      "aprob: 0.536295827642\n",
      "action 1\n",
      "observation [ 0.09101329  0.6064168   0.07701776 -0.3509811 ]\n",
      "aprob: 0.557279673626\n",
      "action 0\n",
      "observation [ 0.10314162  0.41028887  0.06999814 -0.03504047]\n",
      "aprob: 0.535256623003\n",
      "action 1\n",
      "observation [ 0.1113474   0.60434085  0.06929733 -0.30484297]\n",
      "aprob: 0.556286572858\n",
      "action 1\n",
      "observation [ 0.12343422  0.79841035  0.06320047 -0.57489143]\n",
      "aprob: 0.577140732564\n",
      "action 1\n",
      "observation [ 0.13940243  0.99259201  0.05170264 -0.84701384]\n",
      "aprob: 0.597779033987\n",
      "action 1\n",
      "observation [ 0.15925427  1.18697198  0.03476236 -1.12300036]\n",
      "aprob: 0.618161644677\n",
      "action 1\n",
      "observation [ 0.18299371  1.38162134  0.01230235 -1.40457994]\n",
      "aprob: 0.638248106903\n",
      "action 1\n",
      "observation [ 0.21062613  1.5765884  -0.01578925 -1.69339159]\n",
      "aprob: 0.657996500908\n",
      "action 1\n",
      "observation [ 0.2421579   1.77188902 -0.04965708 -1.99094785]\n",
      "aprob: 0.677362639737\n",
      "action 0\n",
      "observation [ 0.27759568  1.57732117 -0.08947603 -1.71404902]\n",
      "aprob: 0.658352536453\n",
      "action 0\n",
      "observation [ 0.3091421   1.38333282 -0.12375701 -1.45050137]\n",
      "aprob: 0.639012975038\n",
      "action 0\n",
      "observation [ 0.33680876  1.18992991 -0.15276704 -1.19890753]\n",
      "aprob: 0.619395961408\n",
      "action 0\n",
      "observation [ 0.36060736  0.9970783  -0.17674519 -0.95773812]\n",
      "aprob: 0.59954934236\n",
      "action 0\n",
      "observation [ 0.38054892  0.80471647 -0.19589995 -0.72538348]\n",
      "aprob: 0.579517633747\n",
      "action 0\n",
      "resetting env. episode reward total was 37.000000. running mean: 43.816386\n",
      "observation [-0.00922493  0.0278795  -0.01762154 -0.008536  ]\n",
      "aprob: 0.503063522043\n",
      "action 0\n",
      "observation [-0.00866734 -0.16698535 -0.01779226  0.27853544]\n",
      "aprob: 0.555209220869\n",
      "action 1\n",
      "observation [-0.01200705  0.02838584 -0.01222155 -0.01970561]\n",
      "aprob: 0.503222149221\n",
      "action 0\n",
      "observation [-0.01143933 -0.16655873 -0.01261566  0.26909636]\n",
      "aprob: 0.554810198939\n",
      "action 1\n",
      "observation [-0.01477051  0.02874096 -0.00723373 -0.02753877]\n",
      "aprob: 0.503328219846\n",
      "action 0\n",
      "observation [-0.01419569 -0.16627651 -0.00778451  0.26285308]\n",
      "aprob: 0.55484362226\n",
      "action 0\n",
      "observation [-0.01752122 -0.36128648 -0.00252745  0.55307056]\n",
      "aprob: 0.615582611526\n",
      "action 0\n",
      "observation [-0.02474695 -0.55637285  0.00853396  0.8449561 ]\n",
      "aprob: 0.674244937937\n",
      "action 0\n",
      "observation [-0.0358744  -0.7516102   0.02543309  1.14031042]\n",
      "aprob: 0.729325949982\n",
      "action 1\n",
      "observation [-0.05090661 -0.55682979  0.04823929  0.85571082]\n",
      "aprob: 0.683099843446\n",
      "action 0\n",
      "observation [-0.0620432  -0.75257474  0.06535351  1.16316354]\n",
      "aprob: 0.738724483971\n",
      "action 1\n",
      "observation [-0.0770947  -0.5583618   0.08861678  0.89166628]\n",
      "aprob: 0.695191522596\n",
      "action 1\n",
      "observation [-0.08826193 -0.36454653  0.10645011  0.62810339]\n",
      "aprob: 0.647886635004\n",
      "action 1\n",
      "observation [-0.09555286 -0.17105865  0.11901217  0.37075167]\n",
      "aprob: 0.597285725538\n",
      "action 1\n",
      "observation [-0.09897404  0.02218915  0.12642721  0.11783745]\n",
      "aprob: 0.548488379576\n",
      "action 1\n",
      "observation [-0.09853025  0.21529428  0.12878396 -0.13243774]\n",
      "aprob: 0.529911866992\n",
      "action 0\n",
      "observation [-0.09422437  0.01858533  0.1261352   0.19794012]\n",
      "aprob: 0.559179519822\n",
      "action 1\n",
      "observation [-0.09385266  0.21169863  0.130094   -0.05244306]\n",
      "aprob: 0.538951540721\n",
      "action 1\n",
      "observation [-0.08961869  0.40473846  0.12904514 -0.30141609]\n",
      "aprob: 0.540385556691\n",
      "action 0\n",
      "observation [-0.08152392  0.20803605  0.12301682  0.02901828]\n",
      "aprob: 0.546807201734\n",
      "action 0\n",
      "observation [-0.0773632   0.01138436  0.12359719  0.35784246]\n",
      "aprob: 0.581828257287\n",
      "action 1\n",
      "observation [-0.07713551  0.20455232  0.13075404  0.10654598]\n",
      "aprob: 0.557178633486\n",
      "action 0\n",
      "observation [-0.07304447  0.00782261  0.13288496  0.43745382]\n",
      "aprob: 0.595274194058\n",
      "action 0\n",
      "observation [-0.07288801 -0.18890532  0.14163403  0.76889742]\n",
      "aprob: 0.655301899176\n",
      "action 0\n",
      "observation [-0.07666612 -0.38566315  0.15701198  1.10258019]\n",
      "aprob: 0.716207679085\n",
      "action 1\n",
      "observation [-0.08437938 -0.19291554  0.17906358  0.86298737]\n",
      "aprob: 0.674093434365\n",
      "action 1\n",
      "observation [ -8.82376936e-02  -6.24009892e-04   1.96323332e-01   6.31525734e-01]\n",
      "aprob: 0.634290278145\n",
      "action 1\n",
      "observation [-0.08825017  0.19129573  0.20895385  0.40652517]\n",
      "aprob: 0.609377043299\n",
      "action 0\n",
      "resetting env. episode reward total was 28.000000. running mean: 43.658223\n",
      "observation [-0.00978521  0.00476055 -0.03526127 -0.01757253]\n",
      "aprob: 0.50226406549\n",
      "action 0\n",
      "observation [-0.00969    -0.18983843 -0.03561272  0.26377984]\n",
      "aprob: 0.552661290956\n",
      "action 0\n",
      "observation [-0.01348677 -0.38443444 -0.03033713  0.54502085]\n",
      "aprob: 0.612231507586\n",
      "action 1\n",
      "observation [-0.02117546 -0.18889964 -0.01943671  0.24293585]\n",
      "aprob: 0.553010194638\n",
      "action 0\n",
      "observation [-0.02495345 -0.38373864 -0.01457799  0.52942512]\n",
      "aprob: 0.613270907045\n",
      "action 0\n",
      "observation [-0.03262822 -0.57865251 -0.00398949  0.81747907]\n",
      "aprob: 0.671558951139\n",
      "action 0\n",
      "observation [-0.04420127 -0.77371962  0.01236009  1.1089045 ]\n",
      "aprob: 0.726403871596\n",
      "action 1\n",
      "observation [-0.05967567 -0.57876226  0.03453818  0.82012458]\n",
      "aprob: 0.679299144223\n",
      "action 1\n",
      "observation [-0.07125091 -0.38412957  0.05094067  0.53850186]\n",
      "aprob: 0.628095897355\n",
      "action 1\n",
      "observation [-0.0789335  -0.18975938  0.06171071  0.26229487]\n",
      "aprob: 0.573461907231\n",
      "action 1\n",
      "observation [-0.08272869  0.00442989  0.06695661 -0.01030314]\n",
      "aprob: 0.5215634384\n",
      "action 0\n",
      "observation [-0.08264009 -0.19158524  0.06675055  0.30273126]\n",
      "aprob: 0.580608370332\n",
      "action 1\n",
      "observation [-0.0864718   0.00252502  0.07280517  0.03182437]\n",
      "aprob: 0.528176916313\n",
      "action 1\n",
      "observation [-0.0864213   0.19653149  0.07344166 -0.23702859]\n",
      "aprob: 0.521354968968\n",
      "action 1\n",
      "observation [-0.08249067  0.39053156  0.06870109 -0.50567182]\n",
      "aprob: 0.542581093386\n",
      "action 0\n",
      "observation [-0.07468004  0.19451214  0.05858765 -0.19215408]\n",
      "aprob: 0.520610536594\n",
      "action 0\n",
      "observation [-0.07078979 -0.00139686  0.05474457  0.11842014]\n",
      "aprob: 0.534798194535\n",
      "action 1\n",
      "observation [-0.07081773  0.19289972  0.05711297 -0.15650125]\n",
      "aprob: 0.519950366063\n",
      "action 1\n",
      "observation [-0.06695974  0.38715942  0.05398295 -0.4306336 ]\n",
      "aprob: 0.541257790881\n",
      "action 1\n",
      "observation [-0.05921655  0.58147705  0.04537027 -0.70582216]\n",
      "aprob: 0.56245507539\n",
      "action 1\n",
      "observation [-0.04758701  0.77594199  0.03125383 -0.98388512]\n",
      "aprob: 0.583497732598\n",
      "action 0\n",
      "observation [-0.03206817  0.58041559  0.01157613 -0.68155161]\n",
      "aprob: 0.562118756838\n",
      "action 1\n",
      "observation [-0.02045986  0.77537487 -0.0020549  -0.97056764]\n",
      "aprob: 0.583345038682\n",
      "action 0\n",
      "observation [-0.00495236  0.58028056 -0.02146626 -0.67853093]\n",
      "aprob: 0.562134631138\n",
      "action 0\n",
      "observation [ 0.00665325  0.3854633  -0.03503687 -0.39268296]\n",
      "aprob: 0.540776080798\n",
      "action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation [ 0.01436252  0.19085562 -0.04289053 -0.11124933]\n",
      "aprob: 0.519320466011\n",
      "action 0\n",
      "observation [ 0.01817963 -0.00362633 -0.04511552  0.16759936]\n",
      "aprob: 0.520716419082\n",
      "action 0\n",
      "observation [ 0.0181071  -0.19807443 -0.04176353  0.44571526]\n",
      "aprob: 0.576420006703\n",
      "action 1\n",
      "observation [ 0.01414562 -0.00238728 -0.03284923  0.14016557]\n",
      "aprob: 0.518041891447\n",
      "action 1\n",
      "observation [ 0.01409787  0.19318938 -0.03004592 -0.16269708]\n",
      "aprob: 0.520033776837\n",
      "action 0\n",
      "observation [ 0.01796166 -0.00148985 -0.03329986  0.12035779]\n",
      "aprob: 0.514350227524\n",
      "action 0\n",
      "observation [ 0.01793186 -0.19611927 -0.0308927   0.40235172]\n",
      "aprob: 0.571496385063\n",
      "action 0\n",
      "observation [ 0.01400948 -0.39078975 -0.02284567  0.6851371 ]\n",
      "aprob: 0.6308493247\n",
      "action 0\n",
      "observation [ 0.00619368 -0.5855872  -0.00914293  0.97054098]\n",
      "aprob: 0.687893367221\n",
      "action 1\n",
      "observation [-0.00551806 -0.39034373  0.01026789  0.67500003]\n",
      "aprob: 0.63577812312\n",
      "action 1\n",
      "observation [-0.01332494 -0.19536596  0.02376789  0.38556751]\n",
      "aprob: 0.579947675328\n",
      "action 1\n",
      "observation [-0.01723226 -0.00058935  0.03147924  0.10047221]\n",
      "aprob: 0.522201658875\n",
      "action 0\n",
      "observation [-0.01724404 -0.19614798  0.03348869  0.4029182 ]\n",
      "aprob: 0.584316183618\n",
      "action 1\n",
      "observation [-0.021167   -0.00151661  0.04154705  0.12097867]\n",
      "aprob: 0.52716993706\n",
      "action 0\n",
      "observation [-0.02119734 -0.19720842  0.04396663  0.4264744 ]\n",
      "aprob: 0.589703902657\n",
      "action 1\n",
      "observation [-0.0251415  -0.00273589  0.05249611  0.14796953]\n",
      "aprob: 0.533310746501\n",
      "action 0\n",
      "observation [-0.02519622 -0.19856876  0.0554555   0.45674093]\n",
      "aprob: 0.596209057831\n",
      "action 1\n",
      "observation [-0.0291676  -0.00427289  0.06459032  0.18204071]\n",
      "aprob: 0.540747559078\n",
      "action 1\n",
      "observation [-0.02925306  0.18986822  0.06823114 -0.08958736]\n",
      "aprob: 0.517975787998\n",
      "action 0\n",
      "observation [-0.02545569 -0.00616202  0.06643939  0.2238182 ]\n",
      "aprob: 0.547476922235\n",
      "action 1\n",
      "observation [-0.02557893  0.18795053  0.07091575 -0.04718941]\n",
      "aprob: 0.52229304192\n",
      "action 1\n",
      "observation [-0.02181992  0.38198773  0.06997197 -0.31668189]\n",
      "aprob: 0.538348147644\n",
      "action 1\n",
      "observation [-0.01418017  0.57604688  0.06363833 -0.58650334]\n",
      "aprob: 0.559444941075\n",
      "action 1\n",
      "observation [-0.00265923  0.77022251  0.05190826 -0.85848015]\n",
      "aprob: 0.580386792266\n",
      "action 1\n",
      "observation [ 0.01274522  0.96460037  0.03473866 -1.13440005]\n",
      "aprob: 0.601130755377\n",
      "action 1\n",
      "observation [ 0.03203723  1.15925095  0.01205066 -1.41598864]\n",
      "aprob: 0.62163275571\n",
      "action 1\n",
      "observation [ 0.05522225  1.35422159 -0.01626912 -1.70488057]\n",
      "aprob: 0.641846749107\n",
      "action 1\n",
      "observation [ 0.08230668  1.54952691 -0.05036673 -2.00258268]\n",
      "aprob: 0.661723902646\n",
      "action 1\n",
      "observation [ 0.11329722  1.74513672 -0.09041838 -2.31042686]\n",
      "aprob: 0.681211833072\n",
      "action 1\n",
      "observation [ 0.14819995  1.94096127 -0.13662692 -2.62951059]\n",
      "aprob: 0.700253973222\n",
      "action 0\n",
      "observation [ 0.18701918  1.7471188  -0.18921713 -2.38149995]\n",
      "aprob: 0.682469570993\n",
      "action 1\n",
      "resetting env. episode reward total was 56.000000. running mean: 43.781640\n",
      "observation [ 0.03910764 -0.04333682 -0.00600036  0.00996405]\n",
      "aprob: 0.502880512123\n",
      "action 1\n",
      "observation [ 0.0382409   0.15187066 -0.00580108 -0.284606  ]\n",
      "aprob: 0.517159732168\n",
      "action 0\n",
      "observation [ 0.04127831 -0.04316807 -0.0114932   0.00624167]\n",
      "aprob: 0.502907126456\n",
      "action 1\n",
      "observation [ 0.04041495  0.15211681 -0.01136836 -0.29004523]\n",
      "aprob: 0.517303294273\n",
      "action 0\n",
      "observation [ 0.04345729 -0.04284121 -0.01716927 -0.00096933]\n",
      "aprob: 0.502913959925\n",
      "action 0\n",
      "observation [ 0.04260046 -0.23771277 -0.01718866  0.28624742]\n",
      "aprob: 0.557807586457\n",
      "action 1\n",
      "observation [ 0.03784621 -0.04234996 -0.01146371 -0.01180673]\n",
      "aprob: 0.502836303203\n",
      "action 1\n",
      "observation [ 0.03699921  0.15293451 -0.01169984 -0.30808444]\n",
      "aprob: 0.517676108919\n",
      "action 0\n",
      "observation [ 0.0400579  -0.0420188  -0.01786153 -0.01911417]\n",
      "aprob: 0.502879007021\n",
      "action 0\n",
      "observation [ 0.03921752 -0.2368801  -0.01824381  0.26788015]\n",
      "aprob: 0.555213673494\n",
      "action 0\n",
      "observation [ 0.03447992 -0.431737   -0.01288621  0.55475347]\n",
      "aprob: 0.615601779411\n",
      "action 0\n",
      "observation [ 0.02584518 -0.62667566 -0.00179114  0.84334875]\n",
      "aprob: 0.673949941965\n",
      "action 0\n",
      "observation [ 0.01331167 -0.82177312  0.01507583  1.13546788]\n",
      "aprob: 0.728778641249\n",
      "action 0\n",
      "observation [-0.00312379 -1.01708904  0.03778519  1.43284059]\n",
      "aprob: 0.778855231397\n",
      "action 0\n",
      "observation [-0.02346557 -1.21265629  0.066442    1.73708827]\n",
      "aprob: 0.823299927751\n",
      "action 1\n",
      "observation [-0.0477187  -1.01835163  0.10118377  1.46579395]\n",
      "aprob: 0.791602304404\n",
      "action 1\n",
      "observation [-0.06808573 -0.82460383  0.13049965  1.20635599]\n",
      "aprob: 0.756366407086\n",
      "action 1\n",
      "observation [-0.08457781 -0.63138691  0.15462677  0.95725308]\n",
      "aprob: 0.71765158851\n",
      "action 0\n",
      "observation [-0.09720555 -0.82821197  0.17377183  1.29424755]\n",
      "aprob: 0.77276102894\n",
      "action 0\n",
      "observation [-0.11376979 -1.02506305  0.19965678  1.63590939]\n",
      "aprob: 0.821046866876\n",
      "action 1\n",
      "resetting env. episode reward total was 20.000000. running mean: 43.543824\n",
      "observation [ 0.03878099 -0.04957686 -0.01884702  0.00380795]\n",
      "aprob: 0.503627099474\n",
      "action 0\n",
      "observation [ 0.03778945 -0.24442352 -0.01877086  0.29048533]\n",
      "aprob: 0.559304619118\n",
      "action 1\n",
      "observation [ 0.03290098 -0.04903901 -0.01296115 -0.00805811]\n",
      "aprob: 0.503489364243\n",
      "action 1\n",
      "observation [ 0.0319202   0.1462664  -0.01312232 -0.30480209]\n",
      "aprob: 0.517123441633\n",
      "action 1\n",
      "observation [ 0.03484553  0.34157287 -0.01921836 -0.60159442]\n",
      "aprob: 0.538898638376\n",
      "action 1\n",
      "observation [ 0.04167699  0.53695831 -0.03125025 -0.90026831]\n",
      "aprob: 0.5605851319\n",
      "action 1\n",
      "observation [ 0.05241615  0.73248947 -0.04925561 -1.20260792]\n",
      "aprob: 0.582130364629\n",
      "action 1\n",
      "observation [ 0.06706594  0.92821249 -0.07330777 -1.51031168]\n",
      "aprob: 0.60347958696\n",
      "action 0\n",
      "observation [ 0.08563019  0.73405133 -0.103514   -1.24138536]\n",
      "aprob: 0.583052815644\n",
      "action 1\n",
      "observation [ 0.10031122  0.93033855 -0.12834171 -1.56461895]\n",
      "aprob: 0.604645006696\n",
      "action 1\n",
      "observation [ 0.11891799  1.12673987 -0.15963409 -1.89442694]\n",
      "aprob: 0.625961151244\n",
      "action 1\n",
      "observation [ 0.14145279  1.32319274 -0.19752263 -2.2320929 ]\n",
      "aprob: 0.646933059646\n",
      "action 1\n",
      "resetting env. episode reward total was 12.000000. running mean: 43.228386\n",
      "observation [-0.0038199  -0.01794     0.03254581 -0.00701488]\n",
      "aprob: 0.506260072869\n",
      "action 0\n",
      "observation [-0.0041787  -0.21351322  0.03240552  0.29575638]\n",
      "aprob: 0.568841499441\n",
      "action 1\n",
      "observation [-0.00844896 -0.01886787  0.03832064  0.0134672 ]\n",
      "aprob: 0.510514248135\n",
      "action 0\n",
      "observation [-0.00882632 -0.21451784  0.03858999  0.31799021]\n",
      "aprob: 0.573537355664\n",
      "action 1\n",
      "observation [-0.01311668 -0.01996616  0.04494979  0.0377226 ]\n",
      "aprob: 0.515584379029\n",
      "action 0\n",
      "observation [-0.013516   -0.21570291  0.04570424  0.34424195]\n",
      "aprob: 0.578958397019\n",
      "action 1\n",
      "observation [-0.01783006 -0.02125993  0.05258908  0.06631442]\n",
      "aprob: 0.521441158096\n",
      "action 0\n",
      "observation [-0.01825526 -0.21709487  0.05391537  0.37511479]\n",
      "aprob: 0.585210193724\n",
      "action 0\n",
      "observation [-0.02259716 -0.41293954  0.06141767  0.68429837]\n",
      "aprob: 0.647516495337\n",
      "action 0\n",
      "observation [-0.03085595 -0.60885805  0.07510363  0.99566748]\n",
      "aprob: 0.706541817818\n",
      "action 1\n",
      "observation [-0.04303311 -0.41481651  0.09501698  0.72748538]\n",
      "aprob: 0.659866857268\n",
      "action 0\n",
      "observation [-0.05132944 -0.61111469  0.10956669  1.04849745]\n",
      "aprob: 0.719024047744\n",
      "action 1\n",
      "observation [-0.06355173 -0.41760356  0.13053664  0.79211952]\n",
      "aprob: 0.675147426751\n",
      "action 1\n",
      "observation [-0.0719038  -0.22449223  0.14637903  0.54318583]\n",
      "aprob: 0.627963513635\n",
      "action 0\n",
      "observation [-0.07639365 -0.42133521  0.15724275  0.87817457]\n",
      "aprob: 0.691093522493\n",
      "action 1\n",
      "observation [-0.08482035 -0.22865926  0.17480624  0.63876536]\n",
      "aprob: 0.646583396591\n",
      "action 0\n",
      "observation [-0.08939354 -0.42573204  0.18758155  0.98100121]\n",
      "aprob: 0.709172543388\n",
      "action 1\n",
      "observation [-0.09790818 -0.23355155  0.20720157  0.75261342]\n",
      "aprob: 0.667786903343\n",
      "action 0\n",
      "resetting env. episode reward total was 18.000000. running mean: 42.976102\n",
      "observation [-0.02431722  0.02136204  0.03625956 -0.00319603]\n",
      "aprob: 0.509237747902\n",
      "action 1\n",
      "observation [-0.02388998  0.21594572  0.03619564 -0.28422172]\n",
      "aprob: 0.523337603176\n",
      "action 1\n",
      "observation [-0.01957107  0.41053323  0.03051121 -0.56527262]\n",
      "aprob: 0.544778061166\n",
      "action 1\n",
      "observation [-0.0113604   0.60521413  0.01920576 -0.84818915]\n",
      "aprob: 0.566109100396\n",
      "action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation [ 0.00074388  0.40983556  0.00224197 -0.5495292 ]\n",
      "aprob: 0.544608947231\n",
      "action 0\n",
      "observation [ 0.00894059  0.21468219 -0.00874861 -0.25614073]\n",
      "aprob: 0.523004216151\n",
      "action 1\n",
      "observation [ 0.01323424  0.40992795 -0.01387143 -0.55157022]\n",
      "aprob: 0.54468887528\n",
      "action 0\n",
      "observation [ 0.02143279  0.21500354 -0.02490283 -0.2632898 ]\n",
      "aprob: 0.523174113123\n",
      "action 1\n",
      "observation [ 0.02573287  0.41047193 -0.03016863 -0.56372216]\n",
      "aprob: 0.544946197278\n",
      "action 1\n",
      "observation [ 0.0339423   0.60600391 -0.04144307 -0.8657549 ]\n",
      "aprob: 0.566602294764\n",
      "action 1\n",
      "observation [ 0.04606238  0.80166467 -0.05875817 -1.1711748 ]\n",
      "aprob: 0.588090036863\n",
      "action 1\n",
      "observation [ 0.06209568  0.99749936 -0.08218166 -1.48168485]\n",
      "aprob: 0.60935528289\n",
      "action 1\n",
      "observation [ 0.08204566  1.19352214 -0.11181536 -1.79886088]\n",
      "aprob: 0.630341034775\n",
      "action 1\n",
      "observation [ 0.10591611  1.38970337 -0.14779258 -2.1241003 ]\n",
      "aprob: 0.650986464671\n",
      "action 0\n",
      "observation [ 0.13371017  1.19632888 -0.19027458 -1.88049367]\n",
      "aprob: 0.631930070212\n",
      "action 1\n",
      "resetting env. episode reward total was 15.000000. running mean: 42.696341\n",
      "observation [-0.02451409  0.04603039  0.01004923  0.04798198]\n",
      "aprob: 0.51373864505\n",
      "action 1\n",
      "observation [-0.02359349  0.24100681  0.01100887 -0.24151346]\n",
      "aprob: 0.525419066627\n",
      "action 1\n",
      "observation [-0.01877335  0.43596979  0.00617861 -0.53070366]\n",
      "aprob: 0.546968488379\n",
      "action 1\n",
      "observation [-0.01005395  0.63100428 -0.00443547 -0.82143332]\n",
      "aprob: 0.568394547728\n",
      "action 1\n",
      "observation [ 0.00256613  0.82618664 -0.02086413 -1.11550801]\n",
      "aprob: 0.589648707261\n",
      "action 1\n",
      "observation [ 0.01908986  1.02157618 -0.04317429 -1.41466213]\n",
      "aprob: 0.610681030344\n",
      "action 0\n",
      "observation [ 0.03952139  0.82701489 -0.07146754 -1.13578146]\n",
      "aprob: 0.590154214119\n",
      "action 0\n",
      "observation [ 0.05606169  0.63289696 -0.09418317 -0.86634142]\n",
      "aprob: 0.569449959516\n",
      "action 1\n",
      "observation [ 0.06871962  0.82916578 -0.11150999 -1.18708881]\n",
      "aprob: 0.591142149387\n",
      "action 0\n",
      "observation [ 0.08530294  0.63565218 -0.13525177 -0.93133725]\n",
      "aprob: 0.570698907416\n",
      "action 1\n",
      "observation [ 0.09801598  0.83231453 -0.15387852 -1.26327962]\n",
      "aprob: 0.592570016623\n",
      "action 1\n",
      "observation [ 0.11466227  1.02903186 -0.17914411 -1.59993098]\n",
      "aprob: 0.614180026894\n",
      "action 1\n",
      "resetting env. episode reward total was 12.000000. running mean: 42.389377\n",
      "observation [-0.0387821  -0.00608882  0.03530108 -0.0222163 ]\n",
      "aprob: 0.508486016821\n",
      "action 0\n",
      "observation [-0.03890388 -0.20169878  0.03485675  0.28139219]\n",
      "aprob: 0.569481325181\n",
      "action 1\n",
      "observation [ -4.29378512e-02  -7.09091825e-03   4.04845951e-02  -9.64712697e-05]\n",
      "aprob: 0.512581591191\n",
      "action 0\n",
      "observation [-0.04307967 -0.20276939  0.04048267  0.30507995]\n",
      "aprob: 0.57426616954\n",
      "action 1\n",
      "observation [-0.04713506 -0.00824702  0.04658426  0.02543412]\n",
      "aprob: 0.517206949555\n",
      "action 0\n",
      "observation [-0.0473     -0.204005    0.04709295  0.33244336]\n",
      "aprob: 0.579732074733\n",
      "action 0\n",
      "observation [-0.0513801  -0.39976452  0.05374181  0.63959729]\n",
      "aprob: 0.641932933347\n",
      "action 0\n",
      "observation [-0.05937539 -0.59559294  0.06653376  0.94870832]\n",
      "aprob: 0.701040232546\n",
      "action 1\n",
      "observation [-0.07128725 -0.40142679  0.08550793  0.67764999]\n",
      "aprob: 0.653370290218\n",
      "action 1\n",
      "observation [-0.07931578 -0.20759036  0.09906093  0.41306636]\n",
      "aprob: 0.602221876492\n",
      "action 0\n",
      "observation [-0.08346759 -0.40396671  0.10732225  0.73526307]\n",
      "aprob: 0.665300073464\n",
      "action 0\n",
      "observation [-0.09154692 -0.60039462  0.12202751  1.05970192]\n",
      "aprob: 0.724326363734\n",
      "action 1\n",
      "observation [-0.10355482 -0.40708163  0.14322155  0.80767579]\n",
      "aprob: 0.681499811266\n",
      "action 1\n",
      "observation [-0.11169645 -0.21418242  0.15937507  0.56325287]\n",
      "aprob: 0.635403951148\n",
      "action 1\n",
      "observation [-0.1159801  -0.02161339  0.17064013  0.32471823]\n",
      "aprob: 0.586772730856\n",
      "action 0\n",
      "observation [-0.11641237 -0.21870202  0.17713449  0.66598256]\n",
      "aprob: 0.652674158021\n",
      "action 1\n",
      "observation [-0.12078641 -0.02642822  0.19045414  0.43389034]\n",
      "aprob: 0.606078296027\n",
      "action 0\n",
      "observation [-0.12131497 -0.22366403  0.19913195  0.78005017]\n",
      "aprob: 0.671649813628\n",
      "action 0\n",
      "resetting env. episode reward total was 18.000000. running mean: 42.145484\n",
      "observation [-0.01130026  0.04095926  0.02533851 -0.03249314]\n",
      "aprob: 0.504332750732\n",
      "action 1\n",
      "observation [-0.01048108  0.23570885  0.02468865 -0.31707503]\n",
      "aprob: 0.525538807125\n",
      "action 1\n",
      "observation [-0.0057669   0.43047061  0.01834715 -0.60187092]\n",
      "aprob: 0.547034862765\n",
      "action 1\n",
      "observation [ 0.00284251  0.62533118  0.00630973 -0.88871882]\n",
      "aprob: 0.568416116617\n",
      "action 1\n",
      "observation [ 0.01534914  0.82036694 -0.01146464 -1.17941158]\n",
      "aprob: 0.589634257791\n",
      "action 1\n",
      "observation [ 0.03175648  1.01563586 -0.03505288 -1.47566624]\n",
      "aprob: 0.610639207064\n",
      "action 1\n",
      "observation [ 0.05206919  1.21116808 -0.0645662  -1.77908784]\n",
      "aprob: 0.63137815226\n",
      "action 1\n",
      "observation [ 0.07629255  1.40695456 -0.10014796 -2.0911249 ]\n",
      "aprob: 0.651794643741\n",
      "action 0\n",
      "observation [ 0.10443165  1.21297464 -0.14197045 -1.83100727]\n",
      "aprob: 0.63248711184\n",
      "action 1\n",
      "observation [ 0.12869114  1.40935492 -0.1785906  -2.1642133 ]\n",
      "aprob: 0.653194672409\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 41.824029\n",
      "observation [ 0.02485165 -0.02320635  0.00387562 -0.01278904]\n",
      "aprob: 0.501441321673\n",
      "action 1\n",
      "observation [ 0.02438752  0.17185981  0.00361984 -0.30424665]\n",
      "aprob: 0.519320015669\n",
      "action 0\n",
      "observation [ 0.02782472 -0.02331354 -0.00246509 -0.01042431]\n",
      "aprob: 0.501504890964\n",
      "action 0\n",
      "observation [ 0.02735845 -0.21840005 -0.00267358  0.28147983]\n",
      "aprob: 0.558961219798\n",
      "action 1\n",
      "observation [ 0.02299045 -0.02324007  0.00295602 -0.01204513]\n",
      "aprob: 0.501457695172\n",
      "action 1\n",
      "observation [ 0.02252565  0.17183936  0.00271512 -0.30379393]\n",
      "aprob: 0.519354214804\n",
      "action 1\n",
      "observation [ 0.02596243  0.36692252 -0.00336076 -0.59561934]\n",
      "aprob: 0.541023798167\n",
      "action 1\n",
      "observation [ 0.03330088  0.56209134 -0.01527315 -0.88935898]\n",
      "aprob: 0.562597671709\n",
      "action 0\n",
      "observation [ 0.04454271  0.36717994 -0.03306033 -0.60151611]\n",
      "aprob: 0.541275739073\n",
      "action 0\n",
      "observation [ 0.05188631  0.17253567 -0.04509065 -0.31942721]\n",
      "aprob: 0.51987792282\n",
      "action 0\n",
      "observation [ 0.05533702 -0.02191607 -0.0514792  -0.04129823]\n",
      "aprob: 0.50264437946\n",
      "action 0\n",
      "observation [ 0.0548987  -0.21626347 -0.05230516  0.23470848]\n",
      "aprob: 0.541858053401\n",
      "action 1\n",
      "observation [ 0.05057343 -0.02043473 -0.04761099 -0.07400361]\n",
      "aprob: 0.501980414302\n",
      "action 0\n",
      "observation [ 0.05016474 -0.21484294 -0.04909106  0.2032859 ]\n",
      "aprob: 0.538018661794\n",
      "action 0\n",
      "observation [ 0.04586788 -0.40922971 -0.04502534  0.48008781]\n",
      "aprob: 0.597343216695\n",
      "action 1\n",
      "observation [ 0.03768328 -0.21350204 -0.03542359  0.17356087]\n",
      "aprob: 0.536749185726\n",
      "action 1\n",
      "observation [ 0.03341324 -0.01789148 -0.03195237 -0.13008326]\n",
      "aprob: 0.503735588239\n",
      "action 0\n",
      "observation [ 0.03305541 -0.21254149 -0.03455404  0.15235033]\n",
      "aprob: 0.534108942513\n",
      "action 0\n",
      "observation [ 0.02880458 -0.40715207 -0.03150703  0.43393507]\n",
      "aprob: 0.594115621724\n",
      "action 1\n",
      "observation [ 0.02066154 -0.21159854 -0.02282833  0.13148884]\n",
      "aprob: 0.533897995606\n",
      "action 1\n",
      "observation [ 0.01642957 -0.01615715 -0.02019855 -0.16830781]\n",
      "aprob: 0.505381539323\n",
      "action 1\n",
      "observation [ 0.01610643  0.17924801 -0.02356471 -0.46729373]\n",
      "aprob: 0.522695552923\n",
      "action 0\n",
      "observation [ 0.01969139 -0.01553322 -0.03291058 -0.18213039]\n",
      "aprob: 0.505567585107\n",
      "action 1\n",
      "observation [ 0.01938072  0.18004381 -0.03655319 -0.48501105]\n",
      "aprob: 0.523145104206\n",
      "action 1\n",
      "observation [ 0.0229816   0.37566202 -0.04625341 -0.7889866 ]\n",
      "aprob: 0.545053568742\n",
      "action 0\n",
      "observation [ 0.03049484  0.1812048  -0.06203314 -0.51120638]\n",
      "aprob: 0.523803995823\n",
      "action 0\n",
      "observation [ 0.03411894 -0.01299098 -0.07225727 -0.23869904]\n",
      "aprob: 0.506455985478\n",
      "action 1\n",
      "observation [ 0.03385912  0.18308485 -0.07703125 -0.55327048]\n",
      "aprob: 0.524704777285\n",
      "action 1\n",
      "observation [ 0.03752081  0.37919922 -0.08809666 -0.86919448]\n",
      "aprob: 0.546825813532\n",
      "action 1\n",
      "observation [ 0.0451048   0.5754021  -0.10548055 -1.18822441]\n",
      "aprob: 0.568844134495\n",
      "action 1\n",
      "observation [ 0.05661284  0.77172134 -0.12924504 -1.5120204 ]\n",
      "aprob: 0.590697906506\n",
      "action 1\n",
      "observation [ 0.07204727  0.96815006 -0.15948545 -1.84209833]\n",
      "aprob: 0.61232146843\n",
      "action 0\n",
      "observation [ 0.09141027  0.77510726 -0.19632741 -1.60289917]\n",
      "aprob: 0.592607080507\n",
      "action 0\n",
      "resetting env. episode reward total was 33.000000. running mean: 41.735789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation [ 0.02907203  0.03496261 -0.01225431 -0.02022591]\n",
      "aprob: 0.503194985317\n",
      "action 1\n",
      "observation [ 0.02977128  0.23025813 -0.01265883 -0.31674988]\n",
      "aprob: 0.524967266846\n",
      "action 0\n",
      "observation [ 0.03437644  0.03531876 -0.01899383 -0.02808584]\n",
      "aprob: 0.50334998443\n",
      "action 1\n",
      "observation [ 0.03508282  0.23070787 -0.01955555 -0.32670049]\n",
      "aprob: 0.525160460778\n",
      "action 0\n",
      "observation [ 0.03969698  0.03586972 -0.02608956 -0.04024811]\n",
      "aprob: 0.503585230492\n",
      "action 1\n",
      "observation [ 0.04041437  0.23135589 -0.02689452 -0.34104703]\n",
      "aprob: 0.525436462134\n",
      "action 1\n",
      "observation [ 0.04504149  0.42684996 -0.03371546 -0.64208814]\n",
      "aprob: 0.547222790036\n",
      "action 0\n",
      "observation [ 0.05357849  0.2322138  -0.04655722 -0.36021028]\n",
      "aprob: 0.525856477905\n",
      "action 1\n",
      "observation [ 0.05822276  0.42796557 -0.05376143 -0.66720264]\n",
      "aprob: 0.547747532882\n",
      "action 1\n",
      "observation [ 0.06678207  0.62379234 -0.06710548 -0.97631665]\n",
      "aprob: 0.569519472944\n",
      "action 1\n",
      "observation [ 0.07925792  0.81974697 -0.08663181 -1.28930124]\n",
      "aprob: 0.591116865317\n",
      "action 1\n",
      "observation [ 0.09565286  1.01585739 -0.11241784 -1.60780161]\n",
      "aprob: 0.612481893055\n",
      "action 0\n",
      "observation [ 0.11597001  0.82222951 -0.14457387 -1.35217439]\n",
      "aprob: 0.592425700398\n",
      "action 0\n",
      "observation [ 0.1324146   0.62918838 -0.17161736 -1.10799038]\n",
      "aprob: 0.572243528694\n",
      "action 1\n",
      "observation [ 0.14499837  0.82609879 -0.19377717 -1.44922523]\n",
      "aprob: 0.594285710998\n",
      "action 1\n",
      "resetting env. episode reward total was 15.000000. running mean: 41.468431\n",
      "observation [ 0.04456226  0.00817871  0.02836041 -0.01395631]\n",
      "aprob: 0.501549712847\n",
      "action 0\n",
      "observation [ 0.04472584 -0.18733824  0.02808128  0.28753802]\n",
      "aprob: 0.55969900257\n",
      "action 1\n",
      "observation [ 0.04097907  0.00737222  0.03383204  0.00384228]\n",
      "aprob: 0.504637002892\n",
      "action 1\n",
      "observation [ 0.04112652  0.20199305  0.03390889 -0.27797718]\n",
      "aprob: 0.521012578066\n",
      "action 1\n",
      "observation [ 0.04516638  0.39661526  0.02834934 -0.55977537]\n",
      "aprob: 0.542481690929\n",
      "action 1\n",
      "observation [ 0.05309868  0.59132808  0.01715384 -0.84339365]\n",
      "aprob: 0.563848904865\n",
      "action 0\n",
      "observation [  6.49252432e-02   3.95976272e-01   2.85963062e-04  -5.45366073e-01]\n",
      "aprob: 0.542340966755\n",
      "action 1\n",
      "observation [ 0.07284477  0.5910942  -0.01062136 -0.83795889]\n",
      "aprob: 0.563859751223\n",
      "action 0\n",
      "observation [ 0.08466665  0.3961189  -0.02738054 -0.54863505]\n",
      "aprob: 0.542499907904\n",
      "action 1\n",
      "observation [ 0.09258903  0.59161457 -0.03835324 -0.84981751]\n",
      "aprob: 0.564164872742\n",
      "action 1\n",
      "observation [ 0.10442132  0.78723796 -0.05534959 -1.1543099 ]\n",
      "aprob: 0.585669511759\n",
      "action 0\n",
      "observation [ 0.12016608  0.5928798  -0.07843579 -0.87948358]\n",
      "aprob: 0.564830930223\n",
      "action 0\n",
      "observation [ 0.13202368  0.39890613 -0.09602546 -0.61245412]\n",
      "aprob: 0.543877960868\n",
      "action 0\n",
      "observation [ 0.1400018   0.20524805 -0.10827454 -0.35149336]\n",
      "aprob: 0.522859290403\n",
      "action 1\n",
      "observation [ 0.14410676  0.4017298  -0.11530441 -0.67626065]\n",
      "aprob: 0.545076200002\n",
      "action 0\n",
      "observation [ 0.15214136  0.20838279 -0.12882962 -0.42199036]\n",
      "aprob: 0.524199834874\n",
      "action 0\n",
      "observation [ 0.15630901  0.01529894 -0.13726943 -0.17253595]\n",
      "aprob: 0.506194010609\n",
      "action 1\n",
      "observation [ 0.15661499  0.21209129 -0.14072015 -0.50517834]\n",
      "aprob: 0.525751881088\n",
      "action 0\n",
      "observation [ 0.16085682  0.01920366 -0.15082371 -0.25994218]\n",
      "aprob: 0.507345415877\n",
      "action 1\n",
      "observation [ 0.16124089  0.2161208  -0.15602256 -0.59613893]\n",
      "aprob: 0.527484036767\n",
      "action 0\n",
      "observation [ 0.16556331  0.02348677 -0.16794533 -0.35638248]\n",
      "aprob: 0.50897292382\n",
      "action 1\n",
      "observation [ 0.16603304  0.22054867 -0.17507298 -0.69696056]\n",
      "aprob: 0.529435622251\n",
      "action 0\n",
      "observation [ 0.17044402  0.02823091 -0.1890122  -0.46410255]\n",
      "aprob: 0.510970210171\n",
      "action 1\n",
      "observation [ 0.17100863  0.22545055 -0.19829425 -0.80990268]\n",
      "aprob: 0.53164916987\n",
      "action 1\n",
      "resetting env. episode reward total was 24.000000. running mean: 41.293746\n",
      "observation [-0.04033655  0.02762818 -0.01840636 -0.01756095]\n",
      "aprob: 0.504532525047\n",
      "action 1\n",
      "observation [-0.03978399  0.2230092  -0.01875758 -0.315994  ]\n",
      "aprob: 0.525459635921\n",
      "action 0\n",
      "observation [-0.03532381  0.02815939 -0.02507746 -0.0292851 ]\n",
      "aprob: 0.504418067004\n",
      "action 0\n",
      "observation [-0.03476062 -0.16659413 -0.02566316  0.25538132]\n",
      "aprob: 0.553245379086\n",
      "action 1\n",
      "observation [-0.0380925   0.02888466 -0.02055553 -0.04528445]\n",
      "aprob: 0.504837235427\n",
      "action 1\n",
      "observation [-0.03751481  0.22429524 -0.02146122 -0.3443813 ]\n",
      "aprob: 0.525959648732\n",
      "action 0\n",
      "observation [-0.0330289   0.02948506 -0.02834885 -0.05854244]\n",
      "aprob: 0.504892696797\n",
      "action 0\n",
      "observation [-0.0324392  -0.16521919 -0.0295197   0.22506315]\n",
      "aprob: 0.547847204986\n",
      "action 0\n",
      "observation [-0.03574359 -0.35990708 -0.02501844  0.50829022]\n",
      "aprob: 0.60773754248\n",
      "action 0\n",
      "observation [-0.04294173 -0.55466777 -0.01485263  0.79298517]\n",
      "aprob: 0.665849001109\n",
      "action 1\n",
      "observation [-0.05403508 -0.3593451   0.00100707  0.49566698]\n",
      "aprob: 0.611313488044\n",
      "action 1\n",
      "observation [-0.06122198 -0.16423737  0.01092041  0.20330161]\n",
      "aprob: 0.553333429189\n",
      "action 1\n",
      "observation [-0.06450673  0.03072672  0.01498644 -0.08591655]\n",
      "aprob: 0.506960826075\n",
      "action 1\n",
      "observation [-0.0638922   0.22563068  0.01326811 -0.37383381]\n",
      "aprob: 0.526368619346\n",
      "action 0\n",
      "observation [-0.05937958  0.03032279  0.00579144 -0.07699706]\n",
      "aprob: 0.506467666283\n",
      "action 0\n",
      "observation [-0.05877313 -0.1648817   0.0042515   0.21750745]\n",
      "aprob: 0.554271141563\n",
      "action 0\n",
      "observation [-0.06207076 -0.36006417  0.00860164  0.51152844]\n",
      "aprob: 0.615457483247\n",
      "action 0\n",
      "observation [-0.06927205 -0.55530622  0.01883221  0.80690954]\n",
      "aprob: 0.674490046492\n",
      "action 0\n",
      "observation [-0.08037817 -0.75068116  0.0349704   1.10545632]\n",
      "aprob: 0.729842045015\n",
      "action 1\n",
      "observation [-0.09539179 -0.55603605  0.05707953  0.82394637]\n",
      "aprob: 0.683985017112\n",
      "action 1\n",
      "observation [-0.10651251 -0.36173941  0.07355846  0.54974833]\n",
      "aprob: 0.634150674741\n",
      "action 0\n",
      "observation [-0.1137473  -0.55781334  0.08455342  0.86467058]\n",
      "aprob: 0.694395380771\n",
      "action 1\n",
      "observation [-0.12490357 -0.36393782  0.10184684  0.59972532]\n",
      "aprob: 0.646762590892\n",
      "action 1\n",
      "observation [-0.13218233 -0.17037714  0.11384134  0.34078006]\n",
      "aprob: 0.595783804126\n",
      "action 1\n",
      "observation [-0.13558987  0.02295655  0.12065694  0.08605378]\n",
      "aprob: 0.549627040117\n",
      "action 0\n",
      "observation [-0.13513074 -0.17366975  0.12237802  0.41423608]\n",
      "aprob: 0.608069340491\n",
      "action 1\n",
      "observation [-0.13860413  0.01952438  0.13066274  0.1625016 ]\n",
      "aprob: 0.560836841778\n",
      "action 0\n",
      "observation [-0.13821365 -0.17720249  0.13391277  0.49338212]\n",
      "aprob: 0.621467685047\n",
      "action 1\n",
      "observation [-0.1417577   0.0158018   0.14378042  0.24572041]\n",
      "aprob: 0.575002715686\n",
      "action 0\n",
      "observation [-0.14144166 -0.18104971  0.14869482  0.58007677]\n",
      "aprob: 0.636209765085\n",
      "action 1\n",
      "observation [-0.14506265  0.01171011  0.16029636  0.33768298]\n",
      "aprob: 0.590814481258\n",
      "action 0\n",
      "observation [-0.14482845 -0.18528658  0.16705002  0.67631533]\n",
      "aprob: 0.652517797201\n",
      "action 0\n",
      "observation [-0.14853418 -0.38228723  0.18057633  1.01658741]\n",
      "aprob: 0.714293428225\n",
      "action 0\n",
      "observation [-0.15617993 -0.57929693  0.20090807  1.36009839]\n",
      "aprob: 0.770312556329\n",
      "action 1\n",
      "resetting env. episode reward total was 34.000000. running mean: 41.220809\n",
      "observation [ 0.00464966 -0.00810544  0.00781228  0.02208207]\n",
      "aprob: 0.504726443105\n",
      "action 1\n",
      "observation [ 0.00448755  0.1869036   0.00825392 -0.26812579]\n",
      "aprob: 0.520449395065\n",
      "action 0\n",
      "observation [ 0.00822562 -0.00833516  0.0028914   0.02714901]\n",
      "aprob: 0.504634434352\n",
      "action 0\n",
      "observation [ 0.00805892 -0.20349846  0.00343438  0.3207428 ]\n",
      "aprob: 0.566172814225\n",
      "action 1\n",
      "observation [ 0.00398895 -0.00842558  0.00984924  0.02914492]\n",
      "aprob: 0.506208909814\n",
      "action 0\n",
      "observation [ 0.00382044 -0.20368739  0.01043214  0.32491905]\n",
      "aprob: 0.568236375906\n",
      "action 1\n",
      "observation [-0.00025331 -0.00871551  0.01693052  0.03554414]\n",
      "aprob: 0.508631072047\n",
      "action 1\n",
      "observation [-0.00042762  0.18615961  0.0176414  -0.25174931]\n",
      "aprob: 0.520100685172\n",
      "action 0\n",
      "observation [ 0.00329557 -0.00920975  0.01260642  0.04644543]\n",
      "aprob: 0.509477214459\n",
      "action 0\n",
      "observation [ 0.00311138 -0.20451018  0.01353532  0.34307899]\n",
      "aprob: 0.571485578402\n",
      "action 0\n",
      "observation [-0.00097883 -0.39982205  0.0203969   0.63999922]\n",
      "aprob: 0.632710238653\n",
      "action 1\n",
      "observation [-0.00897527 -0.20499032  0.03319689  0.35380869]\n",
      "aprob: 0.577126384771\n",
      "action 0\n",
      "observation [-0.01307508 -0.4005682   0.04027306  0.65677196]\n",
      "aprob: 0.638940654861\n",
      "action 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation [-0.02108644 -0.20602933  0.0534085   0.37703735]\n",
      "aprob: 0.5846908329\n",
      "action 0\n",
      "observation [-0.02520703 -0.40186754  0.06094925  0.68607044]\n",
      "aprob: 0.646991594827\n",
      "action 1\n",
      "observation [-0.03324438 -0.20764228  0.07467066  0.4131815 ]\n",
      "aprob: 0.594280314045\n",
      "action 1\n",
      "observation [-0.03739722 -0.01365381  0.08293429  0.14494242]\n",
      "aprob: 0.5388227872\n",
      "action 0\n",
      "observation [-0.0376703  -0.2098595   0.08583314  0.46259413]\n",
      "aprob: 0.603570778961\n",
      "action 0\n",
      "observation [-0.04186749 -0.40608297  0.09508502  0.78104973]\n",
      "aprob: 0.666178255731\n",
      "action 1\n",
      "observation [-0.04998915 -0.21238772  0.11070601  0.51973218]\n",
      "aprob: 0.616578393587\n",
      "action 0\n",
      "observation [-0.0542369  -0.40887981  0.12110066  0.84514716]\n",
      "aprob: 0.679304967486\n",
      "action 0\n",
      "observation [-0.0624145  -0.60542753  0.1380036   1.17332618]\n",
      "aprob: 0.737537525875\n",
      "action 0\n",
      "observation [-0.07452305 -0.80204659  0.16147012  1.50589517]\n",
      "aprob: 0.789837635311\n",
      "action 1\n",
      "observation [-0.09056398 -0.60920933  0.19158803  1.26766811]\n",
      "aprob: 0.75655765694\n",
      "action 1\n",
      "resetting env. episode reward total was 24.000000. running mean: 41.048601\n",
      "observation [-0.02742324  0.01189912 -0.02834904  0.02228992]\n",
      "aprob: 0.503433288742\n",
      "action 1\n",
      "observation [-0.02718526  0.20741591 -0.02790324 -0.27920093]\n",
      "aprob: 0.523489055852\n",
      "action 1\n",
      "observation [-0.02303694  0.40292457 -0.03348726 -0.58055225]\n",
      "aprob: 0.545282066567\n",
      "action 1\n",
      "observation [-0.01497845  0.59849937 -0.04509831 -0.88359339]\n",
      "aprob: 0.566959122244\n",
      "action 1\n",
      "observation [-0.00300846  0.79420378 -0.06277018 -1.19010593]\n",
      "aprob: 0.588467372513\n",
      "action 1\n",
      "observation [ 0.01287561  0.99008051 -0.08657229 -1.5017847 ]\n",
      "aprob: 0.609752094434\n",
      "action 0\n",
      "observation [ 0.03267722  0.79610979 -0.11660799 -1.23733874]\n",
      "aprob: 0.589482395257\n",
      "action 1\n",
      "observation [ 0.04859942  0.99252064 -0.14135476 -1.56415938]\n",
      "aprob: 0.611000672753\n",
      "action 0\n",
      "observation [ 0.06844983  0.7993433  -0.17263795 -1.31870353]\n",
      "aprob: 0.591084630638\n",
      "action 0\n",
      "observation [ 0.0844367   0.60677269 -0.19901202 -1.08464526]\n",
      "aprob: 0.571055983656\n",
      "action 1\n",
      "resetting env. episode reward total was 10.000000. running mean: 40.738115\n",
      "observation [ 0.012845   -0.00271624  0.01481565  0.01440695]\n",
      "aprob: 0.504101412083\n",
      "action 1\n",
      "observation [ 0.01279067  0.19219014  0.01510379 -0.27356489]\n",
      "aprob: 0.520774730712\n",
      "action 1\n",
      "observation [ 0.01663448  0.38709336  0.00963249 -0.56144603]\n",
      "aprob: 0.542352975779\n",
      "action 1\n",
      "observation [ 0.02437634  0.58207882 -0.00159643 -0.85107874]\n",
      "aprob: 0.563828244645\n",
      "action 0\n",
      "observation [ 0.03601792  0.38697867 -0.018618   -0.55889824]\n",
      "aprob: 0.542425539596\n",
      "action 0\n",
      "observation [ 0.04375749  0.19212293 -0.02979597 -0.27213867]\n",
      "aprob: 0.520933680015\n",
      "action 0\n",
      "observation [ 0.04759995 -0.00256146 -0.03523874  0.01099959]\n",
      "aprob: 0.502557148774\n",
      "action 1\n",
      "observation [ 0.04754872  0.19304767 -0.03501875 -0.29259001]\n",
      "aprob: 0.521309063834\n",
      "action 1\n",
      "observation [ 0.05140968  0.38865097 -0.04087055 -0.59610847]\n",
      "aprob: 0.543160397012\n",
      "action 0\n",
      "observation [ 0.0591827   0.1941241  -0.05279272 -0.31657444]\n",
      "aprob: 0.521809348417\n",
      "action 0\n",
      "observation [ 0.06306518 -0.00020769 -0.05912421 -0.04099671]\n",
      "aprob: 0.502840639111\n",
      "action 1\n",
      "observation [ 0.06306102  0.19571006 -0.05994414 -0.35173223]\n",
      "aprob: 0.522468009735\n",
      "action 1\n",
      "observation [ 0.06697523  0.39163096 -0.06697879 -0.66269876]\n",
      "aprob: 0.544456647439\n",
      "action 1\n",
      "observation [ 0.07480784  0.5876177  -0.08023276 -0.97569674]\n",
      "aprob: 0.566336597951\n",
      "action 0\n",
      "observation [ 0.0865602   0.3936582  -0.0997467  -0.70925655]\n",
      "aprob: 0.545436670736\n",
      "action 1\n",
      "observation [ 0.09443336  0.59000985 -0.11393183 -1.03159698]\n",
      "aprob: 0.567475048393\n",
      "action 1\n",
      "observation [ 0.10623356  0.78644784 -0.13456377 -1.35776719]\n",
      "aprob: 0.589340130792\n",
      "action 0\n",
      "observation [ 0.12196252  0.59324567 -0.16171911 -1.11002622]\n",
      "aprob: 0.569067759677\n",
      "action 0\n",
      "observation [ 0.13382743  0.40057472 -0.18391963 -0.87212922]\n",
      "aprob: 0.54872616135\n",
      "action 0\n",
      "observation [ 0.14183892  0.20836605 -0.20136222 -0.64244683]\n",
      "aprob: 0.528361163899\n",
      "action 0\n",
      "resetting env. episode reward total was 20.000000. running mean: 40.530734\n",
      "observation [-0.03839176  0.02560668  0.04562947  0.01947967]\n",
      "aprob: 0.515394397227\n",
      "action 0\n",
      "observation [-0.03787962 -0.17013894  0.04601906  0.3262029 ]\n",
      "aprob: 0.574638149743\n",
      "action 1\n",
      "observation [-0.0412824   0.02429863  0.05254312  0.04838015]\n",
      "aprob: 0.52037587503\n",
      "action 0\n",
      "observation [-0.04079643 -0.17153584  0.05351072  0.35716702]\n",
      "aprob: 0.580637407965\n",
      "action 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-b4708d90b07a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Slow the interaction down\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import pickle\n",
    "import gym\n",
    "\n",
    "# hyperparameters\n",
    "H = 10 # number of hidden layer neurons - Is 100 an overkill?\n",
    "batch_size = 10 # How many episodes before we do a param update?\n",
    "learning_rate = 1e-5\n",
    "gamma = 0.99 # discount factor for reward\n",
    "decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n",
    "render = True\n",
    "\n",
    "# Neural Network initialization\n",
    "D = 4 # input dimensionality: 4 (cartpole-v0 observation)\n",
    "model = {}\n",
    "model['W1'] = np.random.randn(H,D) / np.sqrt(D) # \"Xavier\" initialization\n",
    "model['W2'] = np.random.randn(H) / np.sqrt(H)\n",
    "\n",
    "print(\"The dimensions of the 2 layer NN:\")\n",
    "print(model['W1'].shape)\n",
    "print(model['W2'].shape)\n",
    "\n",
    "def sigmoid(x): \n",
    "  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n",
    "\n",
    "def policy_forward(x):\n",
    "  h = np.dot(model['W1'], x)\n",
    "  h[h<0] = 0 # ReLU nonlinearity\n",
    "  logp = np.dot(model['W2'], h)\n",
    "  p = sigmoid(logp)\n",
    "  return p, h # return probability of taking action 1, and hidden state\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "observation = env.reset()\n",
    "\n",
    "xs,hs,dlogps,drs = [],[],[],[]\n",
    "running_reward = None\n",
    "reward_sum = 0\n",
    "episode_number = 0\n",
    "\n",
    "while True:\n",
    "  if render: env.render()\n",
    "  time.sleep(0.5)  # Slow the interaction down\n",
    "\n",
    "  x = observation\n",
    "    \n",
    "  # forward the policy network and sample an action from the returned probability\n",
    "  aprob, h = policy_forward(x)\n",
    "  action = 1 if np.random.uniform() < aprob else 0 # roll the dice!\n",
    "    \n",
    "  # step the environment and get new measurements\n",
    "  observation, reward, done, info = env.step(action)\n",
    "    \n",
    "  print(\"observation\",x)\n",
    "  print(\"aprob:\",aprob)\n",
    "  print(\"action\",action)\n",
    "\n",
    "  reward_sum += reward\n",
    "\n",
    "  if done: # an episode finished\n",
    "    episode_number += 1\n",
    "    \n",
    "    running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "    print ('resetting env. episode reward total was %f. running mean: %f' % (reward_sum, running_reward))  \n",
    "\n",
    "    reward_sum = 0  # Reset reward sum\n",
    "    observation = env.reset() # reset env\n",
    "    \n",
    "\"\"\"\n",
    "# Update to python3.5 format iteritems --> items\n",
    "grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } # update buffers that add up gradients over a batch\n",
    "rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } # rmsprop memory\n",
    "\n",
    "\n",
    "def discount_rewards(r):\n",
    "  #take 1D float array of rewards and compute discounted reward\n",
    "  discounted_r = np.zeros_like(r)\n",
    "  running_add = 0\n",
    "  for t in reversed(range(0, r.size)):  # Update to python3.5  xrange--> range\n",
    "    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n",
    "    running_add = running_add * gamma + r[t]\n",
    "    discounted_r[t] = running_add\n",
    "  return discounted_r\n",
    "\n",
    "\n",
    "def policy_backward(eph, epdlogp):\n",
    "  # backward pass. (eph is array of intermediate hidden states)\n",
    "  dW2 = np.dot(eph.T, epdlogp).ravel()\n",
    "  dh = np.outer(epdlogp, model['W2'])\n",
    "  dh[eph <= 0] = 0 # backpro prelu\n",
    "  dW1 = np.dot(dh.T, epx)\n",
    "  return {'W1':dW1, 'W2':dW2}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-01 10:15:43,450] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01715323 -0.0465265  -0.01929824 -0.04573151]\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: 0.5\n",
      "action 0\n",
      "[-0.00093053 -0.19483999 -0.00091463  0.28653223]\n",
      "aprob: 0.49153577418\n",
      "action 1\n",
      "[-0.00482733  0.19540477  0.00481601 -0.29898946]\n",
      "aprob: 0.494732336482\n",
      "action 1\n",
      "[-0.00091923  0.19533929 -0.00116377 -0.2975007 ]\n",
      "aprob: 0.494086187979\n",
      "action 1\n",
      "[ 0.00298755  0.19535345 -0.00711379 -0.29785859]\n",
      "aprob: 0.493408971476\n",
      "action 1\n",
      "[ 0.00689462  0.19544347 -0.01307096 -0.30004268]\n",
      "aprob: 0.492709209596\n",
      "action 1\n",
      "[ 0.01080349  0.19559655 -0.01907181 -0.30399749]\n",
      "aprob: 0.491986080904\n",
      "action 0\n",
      "[ 0.01471542 -0.19436493 -0.02515176  0.27469161]\n",
      "aprob: 0.495648520194\n",
      "action 0\n",
      "[ 0.01082812 -0.1939492  -0.01965793  0.26619181]\n",
      "aprob: 0.495531117033\n",
      "action 0\n",
      "[ 0.00694914 -0.19359593 -0.0143341   0.25939049]\n",
      "aprob: 0.495276787168\n",
      "action 1\n",
      "[ 0.00307722  0.19654354 -0.00914629 -0.32659344]\n",
      "aprob: 0.492967200482\n",
      "action 1\n",
      "[ 0.00700809  0.19658897 -0.01567815 -0.32900933]\n",
      "aprob: 0.492239569864\n",
      "action 0\n",
      "[ 0.01093987 -0.1930374  -0.02225834  0.24576853]\n",
      "aprob: 0.497468812778\n",
      "action 0\n",
      "[ 0.00707912 -0.19259003 -0.01734297  0.23766789]\n",
      "aprob: 0.497337817376\n",
      "action 1\n",
      "[ 0.00322732  0.19711164 -0.01258961 -0.34338028]\n",
      "aprob: 0.492609167186\n",
      "action 1\n",
      "resetting env. episode reward total was 15.000000. running mean: 15.000000\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: 0.5\n",
      "action 1\n",
      "[ 0.00047841  0.19447022  0.0006441  -0.27860882]\n",
      "aprob: 0.494235091897\n",
      "action 0\n",
      "[ 0.00436781 -0.19572522 -0.00492808  0.30630858]\n",
      "aprob: 0.490632175071\n",
      "action 1\n",
      "[ 0.00045331  0.19453658  0.0011981  -0.2800185 ]\n",
      "aprob: 0.494242886051\n",
      "action 1\n",
      "[ 0.00434404  0.19451987 -0.00440227 -0.27962754]\n",
      "aprob: 0.493590631597\n",
      "action 1\n",
      "[ 0.00823444  0.1945945  -0.00999482 -0.28108195]\n",
      "aprob: 0.492916078718\n",
      "action 1\n",
      "[ 0.01212633  0.19475315 -0.01561646 -0.28434769]\n",
      "aprob: 0.492218035234\n",
      "action 1\n",
      "[ 0.01602139  0.1949812  -0.02130342 -0.28936377]\n",
      "aprob: 0.491495761161\n",
      "action 1\n",
      "[ 0.01992102  0.19525567 -0.02709069 -0.29603769]\n",
      "aprob: 0.490749073042\n",
      "action 0\n",
      "[ 0.02382613 -0.19465948 -0.03301145  0.2806465 ]\n",
      "aprob: 0.496158636684\n",
      "action 0\n",
      "[ 0.01993294 -0.19416711 -0.02739852  0.26969531]\n",
      "aprob: 0.496203038391\n",
      "action 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukeliem/.local/lib/python3.5/site-packages/ipykernel_launcher.py:52: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0160496  -0.19370084 -0.02200461  0.26029898]\n",
      "aprob: 0.496163522362\n",
      "action 0\n",
      "[ 0.01217558 -0.19329231 -0.01679863  0.25256265]\n",
      "aprob: 0.496011655795\n",
      "action 0\n",
      "[ 0.00830973 -0.19296271 -0.01174738  0.24654994]\n",
      "aprob: 0.495709682736\n",
      "action 1\n",
      "[ 0.00445048  0.19689152 -0.00681638 -0.33566903]\n",
      "aprob: 0.492794687549\n",
      "action 0\n",
      "[ 0.00838831 -0.19265595 -0.01352976  0.23991238]\n",
      "aprob: 0.496484592034\n",
      "action 0\n",
      "[ 0.00453519 -0.19237387 -0.00873151  0.23493769]\n",
      "aprob: 0.49615077361\n",
      "action 1\n",
      "[ 0.00068771  0.19716114 -0.00403276 -0.34310502]\n",
      "aprob: 0.493183337228\n",
      "action 1\n",
      "[ 0.00463094  0.19714945 -0.01089486 -0.34404082]\n",
      "aprob: 0.492513262732\n",
      "action 0\n",
      "resetting env. episode reward total was 19.000000. running mean: 15.040000\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: 0.5\n",
      "action 1\n",
      "[ 0.00056074  0.19571025 -0.00097565 -0.30590929]\n",
      "aprob: 0.493826794203\n",
      "action 0\n",
      "[ 0.00447494 -0.19447124 -0.00709384  0.27852506]\n",
      "aprob: 0.492834178879\n",
      "action 0\n",
      "[ 0.00058552 -0.19435532 -0.00152334  0.27617004]\n",
      "aprob: 0.49228261872\n",
      "action 1\n",
      "[-0.00330159  0.19583214  0.00400006 -0.30877462]\n",
      "aprob: 0.494395034304\n",
      "action 0\n",
      "[ 0.00061506 -0.19439443 -0.00217543  0.2769918 ]\n",
      "aprob: 0.492320462141\n",
      "action 1\n",
      "[-0.00327283  0.19580946  0.00336441 -0.30823255]\n",
      "aprob: 0.494378388647\n",
      "action 0\n",
      "[ 0.00064336 -0.19441336 -0.00280024  0.27738593]\n",
      "aprob: 0.492383079149\n",
      "action 0\n",
      "[-0.00324491 -0.19436954  0.00274747  0.27645822]\n",
      "aprob: 0.491739399933\n",
      "action 1\n",
      "[-0.0071323   0.19576033  0.00827664 -0.30723417]\n",
      "aprob: 0.494975564207\n",
      "action 0\n",
      "[-0.00321709 -0.19454047  0.00213196  0.2800956 ]\n",
      "aprob: 0.491583278901\n",
      "action 0\n",
      "[-0.0071079  -0.19457822  0.00773387  0.28080218]\n",
      "aprob: 0.49082265748\n",
      "action 1\n",
      "[-0.01099947  0.19551603  0.01334991 -0.30174198]\n",
      "aprob: 0.495641896982\n",
      "action 1\n",
      "[-0.00708915  0.19534402  0.00731507 -0.29764846]\n",
      "aprob: 0.495080630812\n",
      "action 0\n",
      "[-0.00318227 -0.19499807  0.0013621   0.28996745]\n",
      "aprob: 0.491030905825\n",
      "action 1\n",
      "[-0.00708223  0.19522365  0.00716145 -0.29494635]\n",
      "aprob: 0.495114827445\n",
      "action 1\n",
      "[-0.00317776  0.19512259  0.00126252 -0.29269691]\n",
      "aprob: 0.49449316911\n",
      "action 0\n",
      "[ 0.0007247  -0.19513934 -0.00459141  0.29306694]\n",
      "aprob: 0.49158651637\n",
      "action 1\n",
      "[-0.00317809  0.19517015  0.00126993 -0.29374529]\n",
      "aprob: 0.494480678192\n",
      "action 1\n",
      "[ 0.00072531  0.19515194 -0.00460498 -0.29334564]\n",
      "aprob: 0.493816087221\n",
      "action 1\n",
      "[ 0.00462835  0.19521572 -0.01047189 -0.29478921]\n",
      "aprob: 0.493129352642\n",
      "action 1\n",
      "[ 0.00853267  0.19535285 -0.01636768 -0.29803675]\n",
      "aprob: 0.492419382503\n",
      "action 0\n",
      "[ 0.01243972 -0.19466595 -0.02232841  0.28197341]\n",
      "aprob: 0.494726425635\n",
      "action 1\n",
      "[ 0.0085464   0.195839   -0.01668894 -0.30971911]\n",
      "aprob: 0.492262592051\n",
      "action 1\n",
      "[ 0.01246318  0.19599101 -0.02288333 -0.31452829]\n",
      "aprob: 0.491520881576\n",
      "action 1\n",
      "[ 0.016383    0.19615432 -0.02917389 -0.32091149]\n",
      "aprob: 0.490756520124\n",
      "action 0\n",
      "[ 0.02030609 -0.19351841 -0.03559212  0.25148219]\n",
      "aprob: 0.498969785912\n",
      "action 0\n",
      "[ 0.01643572 -0.19286765 -0.03056248  0.23869459]\n",
      "aprob: 0.499207954642\n",
      "action 1\n",
      "resetting env. episode reward total was 28.000000. running mean: 15.169600\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: 0.5\n",
      "action 1\n",
      "[  6.29596927e-05   1.95053148e-01  -1.91471268e-04  -2.91172566e-01]\n",
      "aprob: 0.494093713338\n",
      "action 0\n",
      "[ 0.00396402 -0.19518698 -0.00601492  0.29412492]\n",
      "aprob: 0.491642849011\n",
      "action 1\n",
      "[  6.02830693e-05   1.95142451e-01  -1.32424150e-04  -2.93134231e-01]\n",
      "aprob: 0.494072383211\n",
      "action 0\n",
      "[ 0.00396313 -0.19509962 -0.00599511  0.29218929]\n",
      "aprob: 0.491771660333\n",
      "action 0\n",
      "[  6.11395995e-05  -1.95012733e-01  -1.51322910e-04   2.90288415e-01]\n",
      "aprob: 0.491151221795\n",
      "action 1\n",
      "[-0.00383912  0.19523107  0.00565445 -0.29510472]\n",
      "aprob: 0.494712194822\n",
      "action 1\n",
      "[  6.55064110e-05   1.95151375e-01  -2.47649024e-04  -2.93330874e-01]\n",
      "aprob: 0.494064762774\n",
      "action 0\n",
      "[ 0.00396853 -0.19508905 -0.00611427  0.29195556]\n",
      "aprob: 0.491804325668\n",
      "action 0\n",
      "[  6.67529177e-05  -1.95000224e-01  -2.75155319e-04   2.90015168e-01]\n",
      "aprob: 0.491187195569\n",
      "action 0\n",
      "[-0.00383325 -0.19499686  0.00552515  0.28992854]\n",
      "aprob: 0.490451279803\n",
      "action 0\n",
      "[-0.00773319 -0.19507737  0.01132372  0.29168325]\n",
      "aprob: 0.489592094723\n",
      "action 1\n",
      "[-0.01163474  0.1950099   0.01715738 -0.2901073 ]\n",
      "aprob: 0.496077934525\n",
      "action 0\n",
      "[-0.00773454 -0.1954677   0.01135524  0.30054894]\n",
      "aprob: 0.488991927979\n",
      "action 0\n",
      "[-0.01164389 -0.19560116  0.01736622  0.30398264]\n",
      "aprob: 0.487988574376\n",
      "action 0\n",
      "[-0.01555592 -0.19578118  0.02344587  0.30912164]\n",
      "aprob: 0.486859313227\n",
      "action 1\n",
      "[-0.01947154  0.19409584  0.0296283  -0.26751378]\n",
      "aprob: 0.498040401795\n",
      "action 1\n",
      "[-0.01558962  0.19358938  0.02427803 -0.25729012]\n",
      "aprob: 0.497532846628\n",
      "action 1\n",
      "[-0.01171783  0.19313369  0.01913222 -0.24868693]\n",
      "aprob: 0.497001645797\n",
      "action 1\n",
      "[-0.00785516  0.19275193  0.01415849 -0.2417731 ]\n",
      "aprob: 0.496397231923\n",
      "action 1\n",
      "[-0.00400012  0.192459    0.00932302 -0.2365862 ]\n",
      "aprob: 0.495773792165\n",
      "action 0\n",
      "[ -1.50942233e-04  -1.97126100e-01   4.59129930e-03   3.42122708e-01]\n",
      "aprob: 0.486934085916\n",
      "action 0\n",
      "[-0.00409346 -0.1971173   0.01143375  0.34320054]\n",
      "aprob: 0.486017577636\n",
      "action 0\n",
      "[-0.00803581 -0.19711325  0.01829776  0.34587958]\n",
      "aprob: 0.484937558306\n",
      "action 1\n",
      "resetting env. episode reward total was 24.000000. running mean: 15.257904\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: 0.5\n",
      "action 0\n",
      "[-0.00058695 -0.19492522  0.0004244   0.28838112]\n",
      "aprob: 0.491211617107\n",
      "action 0\n",
      "[-0.00448546 -0.19493268  0.00619202  0.28851873]\n",
      "aprob: 0.490465342565\n",
      "action 1\n",
      "[-0.00838411  0.19521811  0.0119624  -0.29485494]\n",
      "aprob: 0.495419435831\n",
      "action 0\n",
      "[-0.00447975 -0.19519343  0.0060653   0.29426856]\n",
      "aprob: 0.490097482011\n",
      "action 0\n",
      "[-0.00838362 -0.19527559  0.01195067  0.29616058]\n",
      "aprob: 0.489216476022\n",
      "action 1\n",
      "[-0.01228913  0.19480178  0.01787388 -0.28534678]\n",
      "aprob: 0.496280692003\n",
      "action 0\n",
      "[-0.00839309 -0.19566956  0.01216694  0.3052889 ]\n",
      "aprob: 0.488571902613\n",
      "action 0\n",
      "[-0.01230648 -0.19579845  0.01827272  0.30888724]\n",
      "aprob: 0.487543333095\n",
      "action 0\n",
      "[-0.01622245 -0.19596515  0.02445047  0.31416458]\n",
      "aprob: 0.486389718714\n",
      "action 1\n",
      "[-0.02014176  0.19384671  0.03073376 -0.26130785]\n",
      "aprob: 0.498318437112\n",
      "action 0\n",
      "[-0.01626482 -0.19648828  0.0255076   0.32948326]\n",
      "aprob: 0.485201360598\n",
      "action 0\n",
      "[-0.02019459 -0.19655865  0.03209727  0.33597008]\n",
      "aprob: 0.483899360206\n",
      "action 0\n",
      "resetting env. episode reward total was 13.000000. running mean: 15.235325\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: 0.5\n",
      "action 1\n",
      "[ 0.0007002   0.19556752 -0.00095247 -0.30264298]\n",
      "aprob: 0.493852140707\n",
      "action 0\n",
      "[ 0.00461155 -0.1946363  -0.00700533  0.28207181]\n",
      "aprob: 0.492580462668\n",
      "action 0\n",
      "[ 0.00071882 -0.19452505 -0.00136389  0.27977209]\n",
      "aprob: 0.492015222062\n",
      "action 0\n",
      "[-0.00317168 -0.1945056   0.00423155  0.27932607]\n",
      "aprob: 0.491332576482\n",
      "action 0\n",
      "[-0.00706179 -0.19457777  0.00981807  0.2807259 ]\n",
      "aprob: 0.490527805087\n",
      "action 0\n",
      "[-0.01095335 -0.19473446  0.01543259  0.2839384 ]\n",
      "aprob: 0.489597579301\n",
      "action 1\n",
      "[-0.01484804  0.19527847  0.02111136 -0.29641415]\n",
      "aprob: 0.496489567077\n",
      "action 0\n",
      "[-0.01094247 -0.19524679  0.01518308  0.29554714]\n",
      "aprob: 0.488853225038\n",
      "action 0\n",
      "[-0.0148474  -0.19543588  0.02109402  0.30021942]\n",
      "aprob: 0.487780990183\n",
      "action 1\n",
      "[-0.01875612  0.19452338  0.02709841 -0.27813397]\n",
      "aprob: 0.497590933409\n",
      "action 0\n",
      "[-0.01486565 -0.19600113  0.02153573  0.31453183]\n",
      "aprob: 0.486752809294\n",
      "action 0\n",
      "[-0.01878568 -0.19615896  0.02782636  0.32055024]\n",
      "aprob: 0.485531001904\n",
      "action 0\n",
      "[-0.02270886 -0.19629277  0.03423737  0.32800022]\n",
      "aprob: 0.484190964676\n",
      "action 0\n",
      "[-0.02663471 -0.1963462   0.04079737  0.33665092]\n",
      "aprob: 0.482741465511\n",
      "action 0\n",
      "resetting env. episode reward total was 15.000000. running mean: 15.232972\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: 0.5\n",
      "action 0\n",
      "[ 0.00067105 -0.1955301   0.00042964  0.30179223]\n",
      "aprob: 0.490281309804\n",
      "action 1\n",
      "[-0.00323955  0.19468575  0.00646548 -0.28314975]\n",
      "aprob: 0.494826177192\n",
      "action 0\n",
      "[ 0.00065417 -0.19562225  0.00080249  0.30389016]\n",
      "aprob: 0.490087220788\n",
      "action 0\n",
      "[-0.00325828 -0.19562867  0.00688029  0.30412693]\n",
      "aprob: 0.489289851806\n",
      "action 1\n",
      "[-0.00717085  0.19448355  0.01296283 -0.27853784]\n",
      "aprob: 0.495617016699\n",
      "action 0\n",
      "[-0.00328118 -0.19588198  0.00739207  0.31006034]\n",
      "aprob: 0.488817840966\n",
      "action 0\n",
      "[-0.00719882 -0.19595303  0.01359328  0.31220448]\n",
      "aprob: 0.487873709111\n",
      "action 1\n",
      "[-0.01111788  0.19399859  0.01983737 -0.26724821]\n",
      "aprob: 0.496635834905\n",
      "action 1\n",
      "[-0.00723791  0.19364486  0.0144924  -0.26040445]\n",
      "aprob: 0.496044745922\n",
      "action 1\n",
      "[-0.00336501  0.19337263  0.00928432 -0.25532042]\n",
      "aprob: 0.495392958309\n",
      "action 0\n",
      "[ 0.00050244 -0.19663057  0.00417791  0.32839834]\n",
      "aprob: 0.487938490893\n",
      "action 1\n",
      "[-0.00343017  0.19315213  0.01074587 -0.2505991 ]\n",
      "aprob: 0.495575551054\n",
      "action 1\n",
      "[ 0.00043287  0.19293984  0.00573389 -0.24674466]\n",
      "aprob: 0.494917167517\n",
      "action 1\n",
      "[ 0.00429167  0.192828    0.000799   -0.2446788 ]\n",
      "aprob: 0.494234271173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action 1\n",
      "[ 0.00814823  0.19281945 -0.00409458 -0.24440075]\n",
      "aprob: 0.49361251975\n",
      "action 1\n",
      "[ 0.01200462  0.1929132  -0.00898259 -0.24589819]\n",
      "aprob: 0.49296994497\n",
      "action 1\n",
      "[ 0.01586288  0.19310461 -0.01390056 -0.24914813]\n",
      "aprob: 0.49230369855\n",
      "action 0\n",
      "[ 0.01972497 -0.19647698 -0.01888352  0.3267506 ]\n",
      "aprob: 0.490657951335\n",
      "action 0\n",
      "[ 0.01579543 -0.19633437 -0.01234851  0.32160912]\n",
      "aprob: 0.490254252521\n",
      "action 0\n",
      "[ 0.01186875 -0.19622115 -0.00591632  0.31815455]\n",
      "aprob: 0.489739736395\n",
      "action 0\n",
      "[ 0.00794432 -0.19615848  0.00044677  0.31646947]\n",
      "aprob: 0.489089136296\n",
      "action 1\n",
      "[ 0.00402115  0.19391004  0.00677616 -0.2666762 ]\n",
      "aprob: 0.494288183585\n",
      "action 0\n",
      "[ 0.00789936 -0.1962432   0.00144263  0.31853746]\n",
      "aprob: 0.488808874303\n",
      "action 1\n",
      "[ 0.00397449  0.19377867  0.00781338 -0.26387292]\n",
      "aprob: 0.494409057335\n",
      "action 1\n",
      "[ 0.00785006  0.19363693  0.00253592 -0.26116649]\n",
      "aprob: 0.493712130783\n",
      "action 0\n",
      "[ 0.0117228  -0.19637713 -0.00268741  0.32187093]\n",
      "aprob: 0.489040514767\n",
      "action 1\n",
      "[ 0.00779526  0.19364123  0.00375001 -0.26122143]\n",
      "aprob: 0.493797331283\n",
      "action 1\n",
      "[ 0.01166808  0.19357553 -0.00147442 -0.25992054]\n",
      "aprob: 0.493137428454\n",
      "action 0\n",
      "[ 0.0155396  -0.19636365 -0.00667283  0.32174213]\n",
      "aprob: 0.489492076366\n",
      "action 0\n",
      "[  1.16123223e-02  -1.96298167e-01  -2.37985531e-04   3.19875792e-01]\n",
      "aprob: 0.488847200817\n",
      "action 1\n",
      "[ 0.00768636  0.19372374  0.00615953 -0.26282636]\n",
      "aprob: 0.493941172849\n",
      "action 0\n",
      "[ 0.01156083 -0.19636553  0.000903    0.32154654]\n",
      "aprob: 0.48857494978\n",
      "action 0\n",
      "[ 0.00763352 -0.19636315  0.00733393  0.32178142]\n",
      "aprob: 0.487779608944\n",
      "action 1\n",
      "[ 0.00370626  0.19352181  0.01376956 -0.25790474]\n",
      "aprob: 0.494931652623\n",
      "action 0\n",
      "[ 0.0075767  -0.19658483  0.00861147  0.32760899]\n",
      "aprob: 0.487196772569\n",
      "action 0\n",
      "[ 0.003645   -0.19662463  0.01516365  0.32986939]\n",
      "aprob: 0.486203865283\n",
      "action 1\n",
      "[-0.00028749  0.19298608  0.02176104 -0.2448118 ]\n",
      "aprob: 0.496084382054\n",
      "action 1\n",
      "[ 0.00357223  0.19254612  0.0168648  -0.23687616]\n",
      "aprob: 0.495502610428\n",
      "action 0\n",
      "[ 0.00742315 -0.19712997  0.01212728  0.34380379]\n",
      "aprob: 0.48556008725\n",
      "action 1\n",
      "resetting env. episode reward total was 40.000000. running mean: 15.480642\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: 0.5\n",
      "action 1\n",
      "[-0.000871    0.19517601 -0.00048359 -0.29387435]\n",
      "aprob: 0.494152545222\n",
      "action 0\n",
      "[ 0.00303252 -0.19506091 -0.00636107  0.2913341 ]\n",
      "aprob: 0.491903201704\n",
      "action 0\n",
      "[-0.0008687  -0.19496793 -0.00053439  0.28931067]\n",
      "aprob: 0.491293388789\n",
      "action 1\n",
      "[-0.00476806  0.1952795   0.00525182 -0.29618281]\n",
      "aprob: 0.494782477705\n",
      "action 1\n",
      "[-0.00086247  0.19520622 -0.00067183 -0.29454204]\n",
      "aprob: 0.494135858445\n",
      "action 0\n",
      "[ 0.00304166 -0.19502762 -0.00656267  0.29059974]\n",
      "aprob: 0.491981215316\n",
      "action 1\n",
      "[-0.00085889  0.19530797 -0.00075068 -0.29680131]\n",
      "aprob: 0.494104660512\n",
      "action 0\n",
      "[ 0.00304727 -0.19492145 -0.00668671  0.28826859]\n",
      "aprob: 0.492155338818\n",
      "action 0\n",
      "[-0.00085116 -0.19482085 -0.00092133  0.28611842]\n",
      "aprob: 0.491562647143\n",
      "action 1\n",
      "[-0.00474758  0.19542244  0.00480104 -0.29938764]\n",
      "aprob: 0.494717326317\n",
      "action 0\n",
      "[-0.00083913 -0.19487853 -0.00118672  0.2873665 ]\n",
      "aprob: 0.491516740104\n",
      "action 0\n",
      "[-0.0047367  -0.19486178  0.00456061  0.28698654]\n",
      "aprob: 0.490808035307\n",
      "action 0\n",
      "[-0.00863394 -0.19493173  0.01030034  0.28845291]\n",
      "aprob: 0.489976705117\n",
      "action 1\n",
      "[-0.01253257  0.19516335  0.0160694  -0.2936342 ]\n",
      "aprob: 0.496031696124\n",
      "action 0\n",
      "[-0.00862931 -0.19530321  0.01019672  0.29676369]\n",
      "aprob: 0.489433381181\n",
      "action 1\n",
      "[-0.01253537  0.19479587  0.01613199 -0.28528382]\n",
      "aprob: 0.496201295779\n",
      "action 1\n",
      "[-0.00863945  0.19454631  0.01042631 -0.2800218 ]\n",
      "aprob: 0.495615287075\n",
      "action 0\n",
      "[-0.00474853 -0.19579659  0.00482588  0.30796465]\n",
      "aprob: 0.489361312808\n",
      "action 0\n",
      "[-0.00866446 -0.19584496  0.01098517  0.30938002]\n",
      "aprob: 0.488472619857\n",
      "action 0\n",
      "[-0.01258136 -0.19595137  0.01717277  0.31256919]\n",
      "aprob: 0.487459629115\n",
      "action 1\n",
      "[-0.01650038  0.19395382  0.02342416 -0.26562519]\n",
      "aprob: 0.497409202478\n",
      "action 1\n",
      "[-0.01262131  0.19353595  0.01811165 -0.25750313]\n",
      "aprob: 0.496868094932\n",
      "action 0\n",
      "[-0.00875059 -0.1966145   0.01296159  0.32910036]\n",
      "aprob: 0.486860534135\n",
      "action 0\n",
      "[-0.01268288 -0.19666909  0.0195436   0.33246104]\n",
      "aprob: 0.485776514473\n",
      "action 1\n",
      "[-0.01661626  0.1928268   0.02619282 -0.23977448]\n",
      "aprob: 0.498115579079\n",
      "action 0\n",
      "[-0.01275972 -0.19700773  0.02139733  0.34408247]\n",
      "aprob: 0.484721826088\n",
      "action 0\n",
      "resetting env. episode reward total was 27.000000. running mean: 15.595836\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: 0.5\n",
      "action 0\n",
      "[-0.0009716  -0.19487923 -0.00090681  0.28738228]\n",
      "aprob: 0.491478587764\n",
      "action 0\n",
      "[-0.00486918 -0.19486676  0.00484084  0.28709248]\n",
      "aprob: 0.490763799467\n",
      "action 1\n",
      "[-0.00876652  0.19529857  0.01058269 -0.29666371]\n",
      "aprob: 0.495386841484\n",
      "action 0\n",
      "[-0.00486055 -0.19509135  0.00464942  0.29200801]\n",
      "aprob: 0.490461240258\n",
      "action 0\n",
      "[-0.00876237 -0.19515722  0.01048958  0.29347348]\n",
      "aprob: 0.489615453715\n",
      "action 0\n",
      "[-0.01266552 -0.19529749  0.01635905  0.29674389]\n",
      "aprob: 0.488643991512\n",
      "action 0\n",
      "[-0.01657147 -0.19549487  0.02229392  0.30174676]\n",
      "aprob: 0.48754579363\n",
      "action 1\n",
      "[-0.02048136  0.1944456   0.02832886 -0.27609963]\n",
      "aprob: 0.497872265058\n",
      "action 1\n",
      "[-0.01659245  0.19399051  0.02280687 -0.26656537]\n",
      "aprob: 0.497362928988\n",
      "action 1\n",
      "[-0.01271264  0.19358544  0.01747556 -0.25867825]\n",
      "aprob: 0.496816063416\n",
      "action 1\n",
      "[-0.00884093  0.19325449  0.01230199 -0.25251481]\n",
      "aprob: 0.496193917363\n",
      "action 0\n",
      "[-0.00497584 -0.19673252  0.0072517   0.33137043]\n",
      "aprob: 0.487440557478\n",
      "action 0\n",
      "[-0.00891049 -0.19675604  0.01387911  0.33322708]\n",
      "aprob: 0.486453090718\n",
      "action 0\n",
      "[-0.01284561 -0.19679658  0.02054365  0.33672473]\n",
      "aprob: 0.485346977245\n",
      "action 0\n",
      "[-0.01678155 -0.19682311  0.02727814  0.34173273]\n",
      "aprob: 0.484124874469\n",
      "action 1\n",
      "resetting env. episode reward total was 16.000000. running mean: 15.599877\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: 0.5\n",
      "action 1\n",
      "[ -7.55087148e-06   1.94554618e-01  -6.96794227e-04  -2.80404750e-01]\n",
      "aprob: 0.494213069551\n",
      "action 1\n",
      "[ 0.00388354  0.19456892 -0.00630489 -0.28063858]\n",
      "aprob: 0.493552787904\n",
      "action 0\n",
      "[ 0.00777492 -0.19554377 -0.01191766  0.30233086]\n",
      "aprob: 0.49177670936\n",
      "action 1\n",
      "[ 0.00386404  0.1948425  -0.00587104 -0.28655481]\n",
      "aprob: 0.493499961163\n",
      "action 0\n",
      "[ 0.00776089 -0.19530665 -0.01160214  0.29686283]\n",
      "aprob: 0.492117602036\n",
      "action 1\n",
      "[ 0.00385476  0.19509677 -0.00566488 -0.2921266 ]\n",
      "aprob: 0.493441103284\n",
      "action 1\n",
      "[ 0.0077567   0.19517644 -0.01150742 -0.29390981]\n",
      "aprob: 0.492751324725\n",
      "action 0\n",
      "[ 0.01166023 -0.19490896 -0.01738561  0.28779834]\n",
      "aprob: 0.493520924941\n",
      "action 0\n",
      "[ 0.00776205 -0.19464745 -0.01162964  0.28217398]\n",
      "aprob: 0.493146517779\n",
      "action 1\n",
      "[ 0.0038691   0.19572611 -0.00598617 -0.30635624]\n",
      "aprob: 0.493252721592\n",
      "action 1\n",
      "[ 0.00778362  0.19578929 -0.01211329 -0.30812554]\n",
      "aprob: 0.492550479581\n",
      "action 0\n",
      "[ 0.01169941 -0.19422301 -0.0182758   0.27239493]\n",
      "aprob: 0.494812367209\n",
      "action 0\n",
      "[ 0.00781495 -0.19390815 -0.0128279   0.26618374]\n",
      "aprob: 0.4945062947\n",
      "action 0\n",
      "[ 0.00393678 -0.19367599 -0.00750423  0.26175498]\n",
      "aprob: 0.494046711171\n",
      "action 1\n",
      "[  6.32623765e-05   1.96414713e-01  -2.26912790e-03  -3.22799038e-01]\n",
      "aprob: 0.493611812064\n",
      "action 0\n",
      "[ 0.00399156 -0.19351787 -0.00872511  0.25838039]\n",
      "aprob: 0.494493405533\n",
      "action 0\n",
      "[  1.21199173e-04  -1.93353656e-01  -3.55750089e-03   2.55312911e-01]\n",
      "aprob: 0.49398171461\n",
      "action 0\n",
      "[-0.00374587 -0.19328987  0.00154876  0.25406147]\n",
      "aprob: 0.493422774797\n",
      "action 0\n",
      "[-0.00761167 -0.19332799  0.00662999  0.25462209]\n",
      "aprob: 0.492746416854\n",
      "action 0\n",
      "[-0.01147823 -0.193465    0.01172243  0.25697631]\n",
      "aprob: 0.491949123187\n",
      "action 1\n",
      "[-0.01534753  0.19628955  0.01686195 -0.32120196]\n",
      "aprob: 0.495910293672\n",
      "action 0\n",
      "[-0.01142174 -0.19392755  0.01043792  0.26680709]\n",
      "aprob: 0.491473243444\n",
      "action 1\n",
      "[-0.01530029  0.19599235  0.01577406 -0.31341778]\n",
      "aprob: 0.495995632805\n",
      "action 1\n",
      "[-0.01138044  0.1958251   0.0095057  -0.30881907]\n",
      "aprob: 0.49545107357\n",
      "action 0\n",
      "[-0.00746394 -0.19447774  0.00332932  0.27874649]\n",
      "aprob: 0.49160054897\n",
      "action 0\n",
      "[-0.0113535  -0.19453579  0.00890425  0.2798518 ]\n",
      "aprob: 0.49081713618\n",
      "action 0\n",
      "[-0.01524421 -0.1946803   0.01450129  0.28277668]\n",
      "aprob: 0.489908732488\n",
      "action 0\n",
      "[-0.01913782 -0.19489826  0.02015682  0.28746614]\n",
      "aprob: 0.488873264781\n",
      "action 0\n",
      "[-0.02303578 -0.19516861  0.02590614  0.29383521]\n",
      "aprob: 0.48771044588\n",
      "action 1\n",
      "[-0.02693916  0.1947582   0.03178285 -0.28330996]\n",
      "aprob: 0.498581652576\n",
      "action 1\n",
      "[-0.02304399  0.19429248  0.02611665 -0.27285643]\n",
      "aprob: 0.498067044679\n",
      "action 0\n",
      "[-0.01915814 -0.19616978  0.02065952  0.31881944]\n",
      "aprob: 0.48668896487\n",
      "action 1\n",
      "[-0.02308154  0.19361032  0.02703591 -0.25698353]\n",
      "aprob: 0.498479313592\n",
      "action 0\n",
      "[-0.01920933 -0.19661828  0.02189624  0.33186111]\n",
      "aprob: 0.485629441622\n",
      "action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0231417  -0.19667506  0.02853346  0.33737362]\n",
      "aprob: 0.484387751929\n",
      "action 0\n",
      "resetting env. episode reward total was 36.000000. running mean: 15.803878\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00065949 -0.19457056  0.00071615  0.28074469]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0045509  -0.19458506  0.00633105  0.28098451]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0084426  -0.19468855  0.01195074  0.28306138]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01233637 -0.19487117  0.01761197  0.28693183]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01623379 -0.19511534  0.0233506   0.29252365]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0201361  -0.19539447  0.02920108  0.29973042]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02404399 -0.19567107  0.03519568  0.30840318]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02795741 -0.19589435  0.04136375  0.31833994]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0318753  -0.19599753  0.04773055  0.32927369]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 15.745840\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -4.57913877e-05  -1.95670289e-01   2.13233219e-04   3.04988739e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukeliem/.local/lib/python3.5/site-packages/ipykernel_launcher.py:62: RuntimeWarning: invalid value encountered in less\n",
      "/home/lukeliem/.local/lib/python3.5/site-packages/ipykernel_launcher.py:71: RuntimeWarning: invalid value encountered in less_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aprob: nan\n",
      "action 0\n",
      "[-0.0039592  -0.1956692   0.00631301  0.30504725]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00787258 -0.19573805  0.01241395  0.30692462]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01178734 -0.19586449  0.01855245  0.31056697]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01570463 -0.19602567  0.02476378  0.31587895]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01962515 -0.19618695  0.03108136  0.32271814]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02354888 -0.19630001  0.03753573  0.33088694]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 15.668381\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -4.90906753e-04  -1.94598968e-01   1.89427504e-04   2.81352138e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00438289 -0.19460476  0.00581647  0.28141842]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00827498 -0.19469977  0.01144484  0.28332463]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01216898 -0.19487476  0.01711133  0.28702956]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01606647 -0.1951128   0.02285192  0.29246337]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01996873 -0.19538802  0.02870119  0.2995223 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02387649 -0.1956638   0.03469164  0.3080607 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02778976 -0.19589038  0.04085285  0.31788063]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03170757 -0.19600223  0.04721046  0.32871998]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 15.611697\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  1.26912283e-04  -1.94708873e-01  -1.04645059e-04   2.83706682e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00376727 -0.19470942  0.00556949  0.28367589]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00766145 -0.19479804  0.01124301  0.28548693]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01155741 -0.1949656   0.01695274  0.28909888]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01545673 -0.19519506  0.02273472  0.29444124]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01936063 -0.19546027  0.02862355  0.30140871]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02326983 -0.19572415  0.03465172  0.30985328]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02718432 -0.19593631  0.04084879  0.31957396]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03110304 -0.1960305   0.04724027  0.33030499]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 15.555580\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  1.12773181e-04  -1.95787048e-01   2.02715273e-05   3.07681854e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00380297 -0.19578277  0.00617391  0.30768111]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00771862 -0.1958458   0.01232753  0.30949406]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01163554 -0.19596376  0.01851741  0.31306663]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01555481 -0.19611345  0.02477874  0.31830179]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01947708 -0.19625957  0.03114478  0.32505418]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02340228 -0.19635293  0.03764586  0.33312198]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 15.480025\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  1.29476543e-04  -1.95185885e-01   5.19845244e-04   2.94092485e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00377424 -0.19519277  0.00640169  0.29425493]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0076781  -0.19527937  0.01228679  0.29625148]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01158368 -0.19543434  0.01821182  0.30003248]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01549237 -0.19563713  0.02421247  0.30551267]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01940511 -0.19585662  0.03032273  0.31256559]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02332225 -0.19604927  0.03657404  0.32101515]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02724323 -0.19615673  0.04299434  0.3306253 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 15.415224\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00090325 -0.19564054  0.00086271  0.30430841]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00481607 -0.19564747  0.00694888  0.30456263]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00872901 -0.19572413  0.01304013  0.30663314]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0126435  -0.19585718  0.01917279  0.31046221]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01656064 -0.19602275  0.02538204  0.31595049]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0204811  -0.19618508  0.03170105  0.3229512 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0244048  -0.19629459  0.03816007  0.33126167]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 15.341072\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -9.83588290e-04  -1.95172230e-01   1.53499616e-04   2.93790873e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00488703 -0.19517409  0.00602932  0.29383863]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00879051 -0.19525637  0.01190609  0.29572282]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01269564 -0.19540832  0.01782055  0.29939605]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01660381 -0.19561008  0.02380847  0.30477581]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02051601 -0.19583138  0.02990398  0.31173897]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02443264 -0.19602967  0.03613876  0.32011361]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02835323 -0.19614783  0.04254103  0.32966869]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 15.277661\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -8.52673831e-04  -1.95683920e-01  -7.42162884e-07   3.05301562e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00476635 -0.19568019  0.00610529  0.30529577]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00867996 -0.19574636  0.0122112   0.30710939]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01259488 -0.19587039  0.01835339  0.31068978]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01651229 -0.19602974  0.02456719  0.3159428 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02043289 -0.19619011  0.03088604  0.32272734]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02435669 -0.19630354  0.03734059  0.33084723]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 15.204885\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  1.19310126e-04  -1.95141615e-01  -4.95704215e-04   2.93115816e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00378352 -0.19513446  0.00536661  0.29295951]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00768621 -0.19520902  0.0112258   0.29464353]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01159039 -0.19535559  0.01711867  0.29812452]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0154975  -0.19555556  0.02308116  0.30332485]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01940861 -0.19578016  0.02914766  0.31012749]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02332422 -0.1959887   0.03535021  0.31836804]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02724399 -0.19612623  0.04171757  0.32782465]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 15.142836\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00066921 -0.19546034 -0.00078059  0.30021606]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00324    -0.19544817  0.00522373  0.29997382]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00714896 -0.19551185  0.0112232   0.30156472]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0110592  -0.19564129  0.0172545   0.3049437 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01497202 -0.19581662  0.02335337  0.31002766]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01888836 -0.19600707  0.02955393  0.31669044]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0228085  -0.19616913  0.03588773  0.32475494]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02673188 -0.19624438  0.04238283  0.33398323]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 15.081408\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00056681 -0.19497256  0.00082264  0.28941139]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00446626 -0.19498558  0.00661086  0.28967515]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00836597 -0.19508162  0.01240437  0.29177471]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0122676  -0.19524952  0.01823986  0.29566133]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01617259 -0.19546941  0.02415309  0.30125296]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02008198 -0.19571136  0.03017815  0.30842852]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02399621 -0.19593341  0.03634672  0.31701944]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02791488 -0.19607925  0.04268711  0.32679908]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 15.020594\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  2.32850760e-04  -1.94503318e-01  -4.29447938e-04   2.79312858e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00365722 -0.19449937  0.00515681  0.27917557]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0075472  -0.19458648  0.01074032  0.28088023]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01143893 -0.19475642  0.01635793  0.2843895 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01533406 -0.19499364  0.02204572  0.28963893]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01923393 -0.19527405  0.02783849  0.29653198]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02313941 -0.19556329  0.03376913  0.30493239]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02705068 -0.19581442  0.03986778  0.31465407]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03096697 -0.19596528  0.04616086  0.32544929]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 14.970388\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00077604 -0.19529108 -0.00091409  0.29642544]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00312978 -0.19527763  0.00501442  0.29613961]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00703534 -0.19534357  0.01093721  0.29769274]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01094221 -0.19547946  0.01689107  0.30104236]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0148518  -0.19566658  0.02291192  0.30611017]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01876513 -0.19587579  0.02903412  0.31277712]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02268264 -0.19606577  0.03528966  0.32087561]\n",
      "aprob: nan\n",
      "action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02660396 -0.19618073  0.04170717  0.33017955]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 14.910684\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  3.19103949e-04  -1.95639113e-01  -1.75387692e-04   3.04274458e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00359368 -0.19563362  0.0059101   0.30421662]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00750635 -0.1956993   0.01199443  0.30598137]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01142034 -0.19582456  0.01811406  0.30951777]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01533683 -0.19598744  0.02430442  0.3147341 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01925658 -0.19615441  0.0305991   0.32149247]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02317966 -0.19627845  0.03702895  0.3296008 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02710523 -0.19629698  0.04362096  0.33880293]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 14.851577\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00068016 -0.19533676  0.00071858  0.29744352]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00458689 -0.19534503  0.00666745  0.29766389]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0084938  -0.19542986  0.01262073  0.29971332]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01240239 -0.19557913  0.018615    0.30353906]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01631397 -0.19577107  0.02468578  0.30905079]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0202294  -0.19597292  0.03086679  0.31611481]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02414885 -0.19613894  0.03718909  0.32454561]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02807163 -0.19620819  0.04368     0.33409552]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 14.793061\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00036965 -0.19486017  0.00070337  0.28696952]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00352755 -0.19487233  0.00644276  0.28719813]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.007425   -0.19496943  0.01218672  0.28926414]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01132439 -0.19514082  0.01797201  0.29312081]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0152272  -0.19536743  0.02383442  0.29868947]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01913455 -0.19562045  0.02980821  0.30585391]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02304696 -0.19585942  0.03592529  0.31445199]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02696415 -0.19602981  0.04221433  0.32426509]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03088475 -0.19606052  0.04869963  0.33500641]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 14.745131\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  2.06179897e-04  -1.94436656e-01   5.81672313e-04   2.77896740e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00368255 -0.19444983  0.00613961  0.27809503]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00757155 -0.19455379  0.01170151  0.2801297 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01146263 -0.19473921  0.0173041   0.28395941]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01535741 -0.19498938  0.02298329  0.28951561]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0192572  -0.19527895  0.0287736   0.29669714]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02316278 -0.19557205  0.03470754  0.30536215]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02707422 -0.19581994  0.04081479  0.31531761]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03099062 -0.19595828  0.04712114  0.32630733]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 14.697679\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  3.14213092e-04  -1.95189191e-01  -2.76289224e-04   2.94165489e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00358957 -0.19518493  0.00560702  0.29407823]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00749327 -0.19526128  0.01148859  0.29582929]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01139849 -0.19540809  0.01740517  0.29937356]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01530666 -0.19560614  0.02339264  0.3046309 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01921878 -0.19582584  0.02948526  0.31148093]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0231353  -0.19602549  0.03571488  0.31975494]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02705581 -0.1961489   0.04210998  0.32922575]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 14.640702\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.0006304  -0.19449921  0.00071178  0.27922486]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00325959 -0.19451413  0.00629628  0.2794649 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00714987 -0.19461895  0.01188557  0.28154138]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01104225 -0.19480399  0.0175164   0.28541166]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01493833 -0.19505204  0.02322464  0.29100511]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01883937 -0.19533707  0.02904474  0.29821769]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02274611 -0.1956223   0.03500909  0.30690367]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02665856 -0.19585786  0.04114716  0.31686514]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03057572 -0.19597807  0.04748447  0.32784   ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 14.594295\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00095483 -0.19487886 -0.00030984  0.28737486]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00485241 -0.19487549  0.00543765  0.2872772 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00874992 -0.19495796  0.0111832   0.28902207]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01264908 -0.19511696  0.01696364  0.29256784]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01655142 -0.19533494  0.022815    0.29784156]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02045812 -0.19558483  0.02877183  0.30473375]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02436981 -0.19582826  0.0348665   0.31309056]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02828638 -0.19601324  0.04112831  0.32270348]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03220664 -0.19607156  0.04758238  0.33329775]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 14.548352\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00084714 -0.19572001 -0.00081958  0.30613346]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00306726 -0.19570645  0.00530309  0.30588282]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00698139 -0.1957629   0.01142075  0.30745409]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01089664 -0.19587861  0.01756983  0.31079963]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01481422 -0.19603233  0.02378582  0.31583033]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01873486 -0.19619114  0.03010243  0.32241065]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02265869 -0.19630872  0.03655064  0.33035078]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 14.482869\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  6.58346943e-04  -1.94545440e-01   9.75889518e-05   2.80209983e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00323256 -0.19455     0.00570179  0.2802466 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00712356 -0.19464457  0.01130672  0.28212318]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01101645 -0.19482016  0.01694918  0.2857995 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01491286 -0.19506021  0.02266517  0.29120737]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01881406 -0.19533945  0.02848932  0.2982454 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02272085 -0.19562197  0.03445423  0.30677108]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02663329 -0.19585892  0.04058965  0.31659043]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03055047 -0.19598588  0.04692146  0.32744616]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 14.438040\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  2.01205126e-04  -1.95623863e-01   4.86581199e-04   3.03926163e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00371127 -0.19562646  0.0065651   0.3040678 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0076238  -0.19569972  0.01264646  0.30602889]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0115378  -0.19583098  0.01876704  0.3097544 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01545442 -0.19599718  0.02496213  0.31514819]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01937436 -0.1961635   0.03126509  0.32206735]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02329763 -0.1962815   0.03770644  0.33031394]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 14.373660\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00038897 -0.19442499  0.0009697   0.27764797]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00427747 -0.19444472  0.00652266  0.27797534]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00816636 -0.19455493  0.01208217  0.28013691]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01205746 -0.19474581  0.01768491  0.28408965]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01595237 -0.19500017  0.0233667   0.28976316]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01985238 -0.19529205  0.02916196  0.29705406]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02375822 -0.19558486  0.03510304  0.3058177 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02766992 -0.19582899  0.0412194   0.31585759]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0315865  -0.19595907  0.04753655  0.32691332]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 14.329923\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00054342 -0.19566062  0.00072579  0.30476791]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00445663 -0.1956657   0.00682115  0.30498033]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00836995 -0.19574023  0.01292076  0.30700895]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01228475 -0.19587104  0.01906094  0.31079663]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01620217 -0.19603438  0.02527687  0.31624451]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02012286 -0.19619461  0.03160176  0.32320617]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02404675 -0.19630224  0.03806588  0.33147928]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 14.266624\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00038327 -0.19527537 -0.00081633  0.29607592]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00428878 -0.19526329  0.00510519  0.29582031]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00819405 -0.19533082  0.0110216   0.29740361]\n",
      "aprob: nan\n",
      "action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01210066 -0.19546837  0.01696967  0.30078295]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01601003 -0.19565716  0.02298533  0.30587974]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01992318 -0.195868    0.02910292  0.31257471]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02384054 -0.19605948  0.03535442  0.32070011]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02776172 -0.19617578  0.04176842  0.33002968]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 14.213958\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  7.95707270e-04  -1.95188932e-01  -1.98228143e-04   2.94159747e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00310807 -0.19518576  0.00568497  0.29409698]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00701179 -0.19526312  0.01156691  0.29587214]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01091705 -0.19541075  0.01748435  0.29943967]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01482526 -0.19560927  0.02347314  0.30471894]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01873745 -0.19582898  0.02956752  0.31158897]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02265403 -0.19602797  0.0357993   0.31988033]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02657459 -0.19614985  0.04219691  0.32936498]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 14.161818\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  8.29124899e-04  -1.94665145e-01  -1.27999510e-04   2.82768348e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00306418 -0.19466551  0.00552737  0.28273013]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00695749 -0.19475457  0.01118197  0.28453372]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01085258 -0.19492333  0.01687264  0.28813876]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01475105 -0.195155    0.02263542  0.29347581]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01865415 -0.1954238   0.02850494  0.30044116]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02256262 -0.19569314  0.03451376  0.30888895]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02647649 -0.19591324  0.04069154  0.3186209 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03039475 -0.1960186   0.04706396  0.32937455]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 14.120200\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -1.74720508e-04  -1.94713463e-01   1.09020066e-04   2.83805303e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00406899 -0.19471736  0.00578513  0.28384407]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00796334 -0.19480904  0.01146201  0.28572365]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01185952 -0.19497907  0.01717648  0.289402  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0157591  -0.19521005  0.02296452  0.29480727]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0196633  -0.19547543  0.02886067  0.30183253]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02357281 -0.19573759  0.03489732  0.31032769]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02748756 -0.19594552  0.04110387  0.3200892 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03140647 -0.19603224  0.04750565  0.33084819]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 14.078998\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  9.36030222e-04  -1.94493644e-01   4.87673204e-05   2.79107492e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00295384 -0.19449765  0.00563092  0.27912842]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0068438  -0.19459235  0.01121349  0.28098903]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01073564 -0.19476893  0.01683327  0.28464985]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01463102 -0.1950112   0.02252626  0.29004404]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01853125 -0.19529431  0.02832714  0.29707219]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02243713 -0.19558297  0.03426859  0.30559445]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02634879 -0.19582913  0.04038048  0.31542025]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03026537 -0.19596927  0.04668888  0.32629642]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 14.038208\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00062072 -0.19552986  0.00065323  0.30178715]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00328987 -0.19553541  0.00668898  0.30198177]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00720058 -0.19561354  0.01272861  0.30399899]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01111285 -0.19575161  0.01880859  0.30778392]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01502789 -0.19592682  0.02496427  0.31324172]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01894642 -0.19610485  0.0312291   0.32023177]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02286852 -0.19623794  0.03763374  0.32855932]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02679328 -0.19626262  0.04420493  0.33796536]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 13.987826\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -6.04310788e-04  -1.95624569e-01   1.64570140e-04   3.03941918e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0045168  -0.19562328  0.00624341  0.30398657]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00842927 -0.19569306  0.01232314  0.30585258]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01234313 -0.19582181  0.01844019  0.30948698]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01625957 -0.19598704  0.02462993  0.31479595]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02017931 -0.1961546   0.03092585  0.3216393 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0241024  -0.19627684  0.03735864  0.32982229]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 13.927948\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  2.73785823e-04  -1.95731589e-01   6.64595260e-05   3.06398954e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00364085 -0.19572828  0.00619444  0.30641265]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00755541 -0.19579361  0.01232269  0.30824287]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01147128 -0.1959153   0.01848755  0.31183594]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01538959 -0.19607038  0.02472427  0.31709596]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.019311   -0.19622399  0.03106619  0.32387937]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02323548 -0.19632744  0.03754377  0.33198681]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 13.868668\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00032007 -0.19488454  0.00042996  0.28749796]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00421776 -0.19489237  0.00617992  0.28763812]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00811561 -0.19498511  0.01193268  0.28961703]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01201531 -0.19515241  0.01772502  0.29338912]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01591836 -0.19537552  0.02359281  0.29887683]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01982587 -0.19562594  0.02957034  0.3059651 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02373839 -0.19586357  0.03568965  0.31449315]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02765566 -0.19603434  0.04197951  0.32424397]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03157635 -0.19606762  0.04846439  0.33493269]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 13.829982\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  1.24626508e-04  -1.95515180e-01   4.15591098e-04   3.01454306e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00378568 -0.1955179   0.00644468  0.30157706]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00769604 -0.19559384  0.01247622  0.30352445]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01160791 -0.19573082  0.01854671  0.3072433 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01552253 -0.19590654  0.02469157  0.31264082]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01944066 -0.19608731  0.03094439  0.31957898]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02336241 -0.19622611  0.03733597  0.32786616]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02728693 -0.19626038  0.04389329  0.33724707]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 13.781682\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00030286 -0.194689    0.00072108  0.28327936]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00419664 -0.19470273  0.00638666  0.28351796]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0080907  -0.19480387  0.01205702  0.28559414]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01198677 -0.19498222  0.01776891  0.28946305]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01588642 -0.19521959  0.02355817  0.29504986]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01979081 -0.19548848  0.02945916  0.30224409]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02370058 -0.19575017  0.03550405  0.3108914 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02761558 -0.19595233  0.04172187  0.32078294]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03153463 -0.19602639  0.04813753  0.33164354]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 13.743865\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00066704 -0.19516214 -0.00032047  0.2935683 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00457028 -0.19515738  0.0055509   0.2934672 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00847343 -0.19523378  0.01142024  0.29520517]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0123781  -0.19538132  0.01732435  0.29873767]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01628573 -0.19558098  0.0232991   0.30398547]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02019735 -0.19580351  0.02937881  0.31082947]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02411342 -0.19600757  0.0355954   0.31910268]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02803357 -0.19613747  0.04197745  0.32858005]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 13.696426\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -5.58227484e-04  -1.95581615e-01   3.02158090e-05   3.02962219e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00446986 -0.19557902  0.00608946  0.30296691]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00838144 -0.19564866  0.0121488   0.30479567]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01229441 -0.19577878  0.01824471  0.30839695]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01620999 -0.1959474   0.02441265  0.31367901]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02012894 -0.19612103  0.03068623  0.32050445]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02405136 -0.19625284  0.03709632  0.32868209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aprob: nan\n",
      "action 0\n",
      "[-0.02797641 -0.19628045  0.04366996  0.337957  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 13.649462\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -4.66776456e-04  -1.95680341e-01   1.59882399e-05   3.05219356e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00438038 -0.19567684  0.00612038  0.30521861]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00829392 -0.19574329  0.01222475  0.30703737]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01220879 -0.19586766  0.01836549  0.31062292]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01612614 -0.19602738  0.02457795  0.31588109]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02004669 -0.19618816  0.03089558  0.32267076]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02397045 -0.19630204  0.03734899  0.33079579]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 13.592967\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -5.39512374e-04  -1.95800877e-01   2.10048394e-05   3.08002817e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00445553 -0.1957965   0.00618106  0.30800211]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00837146 -0.19585907  0.0123411   0.3098143 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01228864 -0.19597618  0.01853739  0.31338511]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01620816 -0.19612453  0.02480509  0.31861715]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02013066 -0.19626869  0.03117743  0.32536449]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02405603 -0.19635932  0.03768472  0.33342456]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 13.537038\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  3.32964328e-05  -1.95266294e-01   9.74618898e-04   2.95874257e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00387203 -0.1952787   0.0068921   0.29617635]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0077776  -0.19536869  0.01281563  0.29830792]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01168498 -0.19552399  0.01878179  0.30221559]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01559546 -0.19572278  0.0248261   0.30780909]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01950991 -0.19593237  0.03098228  0.31495532]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02342856 -0.19610723  0.03728139  0.32346983]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0273507  -0.19618664  0.04375079  0.33310633]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 13.491667\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00039807 -0.19493001  0.00042294  0.28848533]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00429668 -0.19493742  0.00619264  0.28862238]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00819542 -0.19502904  0.01196509  0.2905979 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.012096   -0.1951944   0.01777705  0.2943658 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01599989 -0.19541451  0.02366436  0.29984752]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01990818 -0.19566054  0.02966131  0.3069265 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02382139 -0.19589193  0.03579984  0.31543986]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02773923 -0.196054    0.04210864  0.32516801]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03166031 -0.19607548  0.048612    0.33582299]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 13.456751\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00044499 -0.19563417 -0.00036342  0.30416168]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00435767 -0.19562644  0.00571981  0.30404726]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0082702  -0.19569023  0.01180076  0.30575667]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.012184   -0.19581427  0.01791589  0.30924027]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01610029 -0.19597699  0.0241007   0.31440781]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02001983 -0.19614526  0.03038885  0.32112318]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02394273 -0.19627261  0.03681132  0.32919642]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02786819 -0.19629704  0.04339524  0.33837391]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 13.412183\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00090343 -0.19565512  0.00046789  0.30464139]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00300967 -0.1956572   0.00656072  0.30477661]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00692281 -0.19572922  0.01265625  0.3067299 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0108374  -0.19585847  0.01879085  0.31044593]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01475457 -0.19602172  0.02499977  0.31582785]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.018675   -0.19618391  0.03131633  0.3227317 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02259868 -0.19629628  0.03777096  0.33095805]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 13.358061\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -2.42950626e-04  -1.95557740e-01  -7.86342500e-04   3.02420272e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00415411 -0.19554516  0.00526206  0.30217749]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00806501 -0.19560634  0.01130561  0.3037641 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01197714 -0.19573091  0.01738089  0.30713401]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01589175 -0.19589848  0.02352358  0.31220187]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01980972 -0.19607748  0.02976761  0.31883796]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02373127 -0.19622333  0.03614437  0.32686039]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02765574 -0.19627627  0.04268158  0.33602527]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 13.314481\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00060785 -0.19563215 -0.00067391  0.30411598]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00452049 -0.19562067  0.00540841  0.30390802]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0084329  -0.19568113  0.01148657  0.3055256 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01234653 -0.19580277  0.01759708  0.3089211 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01626258 -0.19596458  0.0237755   0.31400655]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02018187 -0.19613412  0.03005563  0.32064852]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02410455 -0.1962657   0.0364686   0.32866023]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02802987 -0.19629821  0.04304181  0.33779185]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 13.271336\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  8.13340257e-05  -1.95206512e-01   2.70632432e-04   2.94548463e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0038228  -0.19520977  0.0061616   0.29463244]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00772699 -0.19529268  0.01205425  0.29655147]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01163285 -0.19544421  0.01798528  0.3002571 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01554173 -0.19564412  0.02399042  0.3056652 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01945461 -0.19586161  0.03010373  0.31265052]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02337184 -0.19605351  0.03635674  0.32103835]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02729291 -0.19616187  0.0427775   0.33059421]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 13.228623\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00058412 -0.19538627  0.00078659  0.29855112]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00449184 -0.19539495  0.00675761  0.29879094]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00839974 -0.1954791   0.01273343  0.30085786]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01230932 -0.19562632  0.01875059  0.30469806]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01622185 -0.19581444  0.02484455  0.31021948]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02013814 -0.19601012  0.03104894  0.31728597]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02405834 -0.19616692  0.03739466  0.32570885]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02798168 -0.19622298  0.04390883  0.33523657]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 13.186336\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00091151 -0.19522374 -0.00040247  0.29492991]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00299296 -0.19521756  0.00549613  0.29480312]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00689731 -0.19529149  0.01139219  0.29651453]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01080314 -0.1954355   0.01732248  0.30001936]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01471185 -0.19563036  0.02332287  0.30523752]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01862446 -0.19584648  0.02942762  0.31204836]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02254139 -0.19604206  0.03566859  0.32028271]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02646223 -0.19616081  0.04207424  0.32971273]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 13.144473\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  2.87912036e-04  -1.95558181e-01  -7.31139143e-04   3.02430149e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00362325 -0.19554629  0.00531746  0.30220413]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00753418 -0.19560808  0.01136155  0.30380721]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01144634 -0.19573311  0.01743769  0.30719296]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.015361   -0.19590087  0.02358155  0.31227561]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01927902 -0.19607968  0.02982706  0.31892498]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02320061 -0.19622482  0.03620556  0.32695862]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02712511 -0.19627638  0.04274473  0.33613197]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 13.103028\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -2.63990329e-06  -1.94859805e-01  -5.96857479e-04   2.86961693e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00389984 -0.19485212  0.00514238  0.28677154]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00779688 -0.19493085  0.01087781  0.28842532]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0116955  -0.19508715  0.01664631  0.2918831 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01559724 -0.195304    0.02248398  0.29707404]\n",
      "aprob: nan\n",
      "action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01950332 -0.195555    0.02842546  0.30389138]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02341442 -0.19580263  0.03450328  0.31218464]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02733047 -0.19599589  0.04074698  0.32174956]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03125039 -0.19606778  0.04718197  0.33231643]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 13.071998\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00052097 -0.19527546  0.00080888  0.29607782]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00338454 -0.19528553  0.00673044  0.29632806]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00729025 -0.19537324  0.012657    0.29840855]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01119772 -0.19552652  0.01862517  0.3022668 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01510825 -0.19572382  0.02467051  0.3078134 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01902273 -0.1959327   0.03082677  0.31491625]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02294138 -0.1961079   0.0371251   0.32339206]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02686354 -0.19618907  0.04359294  0.3329959 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 13.031278\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -7.84852440e-04  -1.94782708e-01  -2.59105524e-04   2.85295826e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00468051 -0.19478051  0.00544681  0.28521462]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00857612 -0.19486552  0.0111511   0.28697601]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01247343 -0.1950286   0.01689062  0.2905391 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.016374   -0.19525261  0.02270141  0.29583271]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02027905 -0.19551111  0.02861806  0.30275019]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02418927 -0.19576661  0.03467306  0.3111416 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02810461 -0.1959682   0.0408959   0.32080338]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03202397 -0.19604899  0.04731196  0.33146675]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 13.000965\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  8.25227675e-04  -1.94663944e-01  -2.76969504e-04   2.82742521e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00306805 -0.19466193  0.00537788  0.2826556 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00696129 -0.19474879  0.01103099  0.28441117]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01085627 -0.19491571  0.01671922  0.28796964]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01475458 -0.19514614  0.02247861  0.2932624 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0186575  -0.19541459  0.02834386  0.30018683]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02256579 -0.19568477  0.03434759  0.30859841]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02647949 -0.19590734  0.04051956  0.31830051]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03039764 -0.19601728  0.04688557  0.32903268]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 12.970956\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00070743 -0.19476718  0.00092375  0.2849601 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00318791 -0.19478347  0.00662295  0.28526243]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00708358 -0.19488581  0.0123282   0.28740126]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0109813  -0.19506351  0.01807622  0.29132977]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01488257 -0.19529765  0.02390282  0.29697013]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01878852 -0.19555974  0.02984222  0.30420776]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02269971 -0.19580979  0.03592638  0.31288286]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02661591 -0.1959939   0.04218403  0.32277983]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03053579 -0.19604169  0.04863963  0.33361542]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 12.941246\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00036383 -0.19559516 -0.0006788   0.30327146]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00354808 -0.19558377  0.00538663  0.30306168]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00745975 -0.19564517  0.01144786  0.30467914]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01137266 -0.19576873  0.01754144  0.30807668]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01528803 -0.19593365  0.02370298  0.31316726]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0192067  -0.19610781  0.02996632  0.31981888]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02312886 -0.19624595  0.0363627   0.32784671]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02705378 -0.1962875   0.04291963  0.33700328]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 12.901834\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -6.28640859e-05  -1.95221410e-01   7.84562349e-04   2.94878427e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00396729 -0.19523166  0.00668213  0.29512276]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00787193 -0.19532061  0.01258459  0.29719885]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01177834 -0.19547641  0.01852856  0.30105504]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01568787 -0.19567785  0.02454966  0.30660345]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01960142 -0.195893    0.03068173  0.3137142 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02351928 -0.19607728  0.03695602  0.32220692]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02744083 -0.19617112  0.04340016  0.33184033]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 12.862815\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -6.70624253e-05  -1.94863112e-01   3.37049634e-04   2.87033523e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00396432 -0.19486967  0.00607772  0.28714417]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00786172 -0.19496158  0.0118206   0.2890942 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01176095 -0.19512868  0.01760249  0.29283876]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01566352 -0.19535248  0.02345926  0.29830134]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01957057 -0.19560482  0.02942529  0.30536832]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02348267 -0.19584605  0.03553266  0.31388073]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02739959 -0.19602261  0.04181027  0.32362388]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03132004 -0.1960645   0.04828275  0.3343156 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 12.834187\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -1.54037241e-04  -1.95360891e-01   3.15288348e-04   2.97982485e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00406126 -0.1953636   0.00627494  0.29807765]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00796853 -0.19544292  0.01223649  0.30000352]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01187739 -0.19558729  0.01823656  0.30370948]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01578913 -0.19577551  0.02431075  0.30910735]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01970464 -0.19597542  0.0304929   0.3160658 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02362415 -0.19614199  0.03681421  0.32440204]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02754699 -0.19621509  0.04330226  0.33387162]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 12.795845\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00044514 -0.19557189  0.00073735  0.30274174]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0034663  -0.19557805  0.00679219  0.30296056]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00737786 -0.19565572  0.0128514   0.30499965]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01129097 -0.195792    0.01895139  0.30880304]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01520681 -0.19596367  0.02512745  0.31427414]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01912609 -0.19613585  0.03141293  0.32127   ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0230488  -0.19626009  0.03783833  0.32959282]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 12.747887\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  2.76415406e-04  -1.95740059e-01   8.98073121e-04   3.06596344e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00363839 -0.19574624  0.00703     0.30685734]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00755331 -0.19581967  0.01316715  0.30892922]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0114697  -0.19594662  0.01934573  0.3127526 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01538864 -0.19610252  0.02560078  0.31822517]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01931069 -0.19625062  0.03196529  0.32519578]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0232357  -0.19634007  0.0384692   0.33345607]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 12.700408\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00056851 -0.19500292  0.00045759  0.29007401]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00333155 -0.19501033  0.00625907  0.29022072]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00723176 -0.19510071  0.01206349  0.29220495]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01113377 -0.19526336  0.01790759  0.29597958]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01503904 -0.19547884  0.02382718  0.30146414]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01894861 -0.19571766  0.02985646  0.30853925]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02286297 -0.1959384   0.03602725  0.31703825]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02678173 -0.19608533  0.04236801  0.32673684]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03070344 -0.19608594  0.04890275  0.33734148]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 12.673404\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00039735 -0.195578   -0.0009939   0.30288153]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00351421 -0.19556278  0.00506373  0.30257611]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00742547 -0.19562109  0.01111525  0.30410021]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01133789 -0.19574284  0.01719725  0.30740885]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01525275 -0.19590791  0.02334543  0.31241763]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01917091 -0.19608497  0.02959378  0.31899779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aprob: nan\n",
      "action 0\n",
      "[-0.02309261 -0.19622971  0.03597374  0.32696846]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0270172  -0.19628268  0.04251311  0.3360869 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 12.636670\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00029615 -0.19472771  0.00055199  0.2841112 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00419071 -0.1947385   0.00623421  0.28429388]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00808548 -0.19483636  0.01192009  0.28631511]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0119822  -0.19501122  0.01764639  0.29013046]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01588243 -0.19524494  0.023449    0.29566518]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01978733 -0.19551005  0.02936231  0.30280874]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02369753 -0.19576778  0.03541848  0.31140648]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02761288 -0.19596578  0.04164661  0.3212492 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0315322  -0.19603542  0.04807159  0.33206126]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 12.610303\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00034162 -0.19529955 -0.00057656  0.29661362]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00424761 -0.19529066  0.00535571  0.29643286]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00815342 -0.19536065  0.01128437  0.29808926]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01206064 -0.19549953  0.01724615  0.30153828]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01597063 -0.19568796  0.02327692  0.30669919]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01988439 -0.19589609  0.0294109   0.31345   ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02380231 -0.19608169  0.0356799   0.32161954]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02772394 -0.19618794  0.04211229  0.33097737]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 12.574200\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00032031 -0.19532202 -0.00047778  0.29711434]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00422675 -0.19531437  0.00546451  0.29696437]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00813304 -0.19538506  0.0114038   0.29865046]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01204074 -0.19552388  0.01737681  0.30212724]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01595122 -0.1957112   0.02341935  0.30731281]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01986544 -0.19591679  0.02956561  0.31408359]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02378378 -0.19609795  0.03584728  0.32226638]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02770574 -0.19619728  0.04229261  0.33162825]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 12.538458\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  5.79304609e-04  -1.95580444e-01   7.07119717e-06   3.02935552e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0033323  -0.19557757  0.00606578  0.30293325]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00724386 -0.19564699  0.01212445  0.30475521]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0111568  -0.19577699  0.01821955  0.30835003]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01507234 -0.19594563  0.02438655  0.31362616]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01899125 -0.19611949  0.03065908  0.32044646]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02291364 -0.19625181  0.037068    0.32862003]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02683867 -0.19628028  0.0436404   0.33789228]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 12.503073\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00077531 -0.19551066 -0.00088697  0.30135284]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0031349  -0.19549697  0.00514009  0.30107878]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00704484 -0.19555817  0.01116167  0.30263649]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01095601 -0.1956842   0.0172144   0.30598102]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01486969 -0.19585511  0.02333402  0.31102884]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01878679 -0.19603992  0.02955459  0.31765279]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02270759 -0.19619482  0.03590765  0.32567431]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02663149 -0.19626097  0.04242114  0.33485361]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 12.468043\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00052829 -0.19523162 -0.00072885  0.29510468]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00337634 -0.19522088  0.00517324  0.29487586]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00728076 -0.19529047  0.01107076  0.2964866 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01118657 -0.1954308   0.01700049  0.29989396]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01509518 -0.19562316  0.02299837  0.30501978]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01900765 -0.19583855  0.02909877  0.31174566]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02292442 -0.19603582  0.03533368  0.31990509]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02684513 -0.19615949  0.04173178  0.32927348]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 12.433362\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00072654 -0.19447353 -0.00034756  0.27867977]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00316293 -0.19447103  0.00522604  0.27856953]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00705235 -0.19455987  0.01079743  0.28030053]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01094355 -0.19473178  0.01640344  0.28383535]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01483818 -0.19497123  0.02208015  0.28910968]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01873761 -0.19525421  0.02786234  0.29602737]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02264269 -0.19554647  0.03378289  0.30445275]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02655362 -0.19580123  0.03987194  0.3142005 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03046965 -0.1959565   0.04615595  0.32502385]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 12.409029\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  3.00255679e-04  -1.95761999e-01   6.71212733e-04   3.07102670e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00361498 -0.19576534  0.00681327  0.30729549]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00753029 -0.19583572  0.01295918  0.30929945]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01144701 -0.19595971  0.01914516  0.3130564 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0153662  -0.19611305  0.02540629  0.3184651 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01928846 -0.19625927  0.0317756   0.32537552]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02321365 -0.19634782  0.03828311  0.33358046]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 12.364938\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00059739 -0.19450699  0.00086841  0.27938979]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00448753 -0.19452443  0.00645621  0.27968137]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00837802 -0.19463149  0.01204983  0.28180864]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01227065 -0.19481826  0.01768601  0.28572811]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01616702 -0.19506728  0.02340057  0.29136813]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02006836 -0.19535216  0.02922793  0.29862333]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0239754  -0.19563571  0.0352004   0.30734627]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02788812 -0.19586754  0.04134732  0.31733694]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03180547 -0.19598137  0.04769406  0.32833066]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 12.341289\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00032678 -0.19457331  0.00057426  0.28080385]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00356469 -0.19458549  0.00619034  0.28099697]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0074564  -0.19468679  0.01181028  0.2830279 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01135013 -0.19486753  0.01747084  0.28685383]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01524748 -0.19511033  0.02320792  0.2924033 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01914969 -0.19538883  0.02905598  0.29957078]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02305747 -0.19566582  0.0350474   0.3082084 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02697078 -0.19589085  0.04121157  0.31811556]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0308886  -0.19599757  0.04757388  0.3290269 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 12.317876\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00058096 -0.19516882  0.0009203   0.29371568]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00332242 -0.19518145  0.00679461  0.29400419]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00722605 -0.19527357  0.01267469  0.29612481]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01113152 -0.19543329  0.01859719  0.30002576]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01504019 -0.19563947  0.02459771  0.30561958]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01895298 -0.19586035  0.0307101   0.31277727]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02287018 -0.19605161  0.03696564  0.32131978]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02679122 -0.19615402  0.04339204  0.33100746]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 12.284697\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00088106 -0.19454031 -0.00096263  0.28009888]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00300975 -0.19452748  0.00463935  0.27978575]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0069003  -0.19460574  0.01023507  0.28131712]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01079241 -0.19476747  0.01586141  0.28465785]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01468776 -0.1949977   0.02155456  0.2897456 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01858772 -0.19527301  0.02734948  0.29648622]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02249318 -0.19555981  0.0332792   0.3047463 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02640437 -0.19581207  0.03937413  0.31434325]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03032061 -0.19596872  0.04566099  0.32503365]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 12.261850\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0007697  -0.19485838  0.00032354  0.28693115]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00312747 -0.19486477  0.00606216  0.28703753]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00702477 -0.19495659  0.01180291  0.28898338]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0109239  -0.19512373  0.01758258  0.29272398]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01482637 -0.19534772  0.02343706  0.29818301]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01873333 -0.19560049  0.02940072  0.30524711]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02264534 -0.19584245  0.03550566  0.31375766]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02656219 -0.19602015  0.04178082  0.32350037]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03048259 -0.1960637   0.04825082  0.3341936 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 12.239232\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -1.15680921e-04  -1.95527376e-01   6.39933788e-04   3.01730926e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00402623 -0.19553279  0.00667455  0.30192158]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00793688 -0.19561085  0.01271298  0.30393501]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0118491  -0.19574896  0.01879168  0.30771647]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01576408 -0.19592435  0.02494601  0.31317125]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01968257 -0.19610275  0.03120944  0.32015895]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02360462 -0.19623646  0.03761262  0.32848509]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02752935 -0.19626209  0.04418232  0.33789096]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 12.206840\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  1.44050821e-04  -1.95226780e-01  -6.39648345e-05   2.94997163e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00376048 -0.19522527  0.00583598  0.29497623]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00766499 -0.19530344  0.0117355   0.2967917 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01157106 -0.19545071  0.01767134  0.3003968 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01548007 -0.19564728  0.02367927  0.30570915]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01939302 -0.19586287  0.02979346  0.31260537]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02331028 -0.19605486  0.03604556  0.32091293]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02723137 -0.19616596  0.04246382  0.33039996]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 12.174771\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -1.00352840e-04  -1.94875817e-01   4.52572044e-04   2.87308748e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00399787 -0.19488405  0.00619875  0.28745634]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00789555 -0.1949773   0.01194787  0.28944262]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0117951  -0.19514521  0.01773673  0.29322199]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.015698   -0.19536903  0.02360117  0.29871694]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01960538 -0.19562031  0.0295755   0.30581258]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02351779 -0.19585898  0.03569176  0.3143483 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02743497 -0.19603101  0.04197872  0.32410737]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03135559 -0.19606584  0.04846087  0.33480522]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 12.153023\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.0009538  -0.19525215  0.00044283  0.29555979]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00295124 -0.19525744  0.00635402  0.2956967 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00685639 -0.1953413   0.01226796  0.29766661]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01076321 -0.19549231  0.01822129  0.3014195 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01467306 -0.19568967  0.02424968  0.30686902]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01858685 -0.19590188  0.03038706  0.31388685]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02250489 -0.19608483  0.0366648   0.3222944 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02642659 -0.19617949  0.04311068  0.33185244]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 12.121493\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00064319 -0.19437789 -0.00061595  0.27665198]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00324437 -0.19437114  0.00491709  0.27645205]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00713179 -0.19445706  0.01044613  0.27809313]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01102093 -0.19462796  0.01600799  0.28153989]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01491349 -0.19486911  0.02163879  0.28673131]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01881087 -0.19515762  0.02737341  0.29357589]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02271402 -0.19546072  0.03324493  0.30194419]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02662324 -0.19573347  0.03928381  0.31165882]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03053791 -0.19591614  0.04551699  0.32248269]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03445623 -0.19593146  0.05196664  0.33410654]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 11.000000. running mean: 12.110278\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  1.02398443e-04  -1.94798095e-01   8.76276536e-04   2.85627031e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00379356 -0.1948134   0.00658882  0.28591309]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00768983 -0.19491436  0.01230708  0.28803584]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01158812 -0.19509026  0.0180678   0.29194836]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01548992 -0.19532209  0.02390676  0.29757238]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01939637 -0.19558121  0.02985821  0.30479259]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02330799 -0.19582741  0.03595406  0.31344817]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02722454 -0.19600653  0.04222303  0.32332224]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03114467 -0.19604783  0.04868947  0.33413003]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 12.089175\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00054092 -0.19525274 -0.00067177  0.29557302]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00336413 -0.19524272  0.0052397   0.29536224]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00726899 -0.19531257  0.01114694  0.29699027]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01117524 -0.19545257  0.01708675  0.3004136 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01508429 -0.19564381  0.02309502  0.30555323]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01899717 -0.19585697  0.02920608  0.31228956]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02291431 -0.19605058  0.03545187  0.32045456]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02683532 -0.19616871  0.04186096  0.32982172]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 12.058284\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  1.61918628e-04  -1.94616739e-01  -3.50180642e-04   2.81731835e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00373042 -0.19461372  0.00528446  0.28162092]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00762269 -0.19470027  0.01091687  0.28335258]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0115167  -0.19486778  0.01658393  0.28688803]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01541405 -0.19510005  0.02232169  0.29216008]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01931605 -0.19537205  0.02816489  0.29906811]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02322349 -0.19564813  0.03414625  0.30747028]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02713646 -0.19587974  0.04029566  0.3171734 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03105405 -0.19600277  0.04663912  0.32792114]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 12.037701\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00090741 -0.19466761 -0.00083829  0.28282021]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00480077 -0.19465661  0.00481812  0.28254974]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0086939  -0.19473496  0.01046911  0.28412421]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0125886  -0.1948946   0.0161516   0.28750673]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01648649 -0.1951198   0.02190173  0.29263179]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02038888 -0.19538602  0.02775437  0.29940048]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02429661 -0.19565817  0.03374238  0.30767291]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02820977 -0.19588833  0.03989583  0.31725822]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03212754 -0.19601315  0.046241    0.32790289]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 12.017324\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00090363 -0.19553151 -0.0004747   0.30182431]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.003007   -0.19552294  0.00556178  0.30167602]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00691746 -0.19558835  0.0115953   0.30335665]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01082923 -0.19571695  0.01766244  0.30681843]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01474357 -0.19588795  0.02379881  0.31197445]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01866133 -0.19606934  0.03003829  0.31869342]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02258271 -0.1962161   0.03641216  0.32679172]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02650703 -0.19626796  0.042948    0.33602345]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 11.987151\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00056171 -0.19479102  0.00040354  0.28547507]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00333411 -0.19479907  0.00611304  0.28560839]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00723009 -0.19489346  0.01182521  0.287581  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01112796 -0.19506415  0.01757683  0.29134852]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01502924 -0.1952929   0.0234038   0.29683567]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0189351  -0.19555202  0.02934051  0.3039308 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02284614 -0.19580242  0.03541913  0.3124777 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02676219 -0.19599134  0.04166868  0.32226512]\n",
      "aprob: nan\n",
      "action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03068202 -0.19604964  0.04811398  0.33301501]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.967279\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00041814 -0.19575834  0.00039726  0.30701738]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0043333  -0.1957586   0.00653761  0.30712898]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00824848 -0.19582638  0.01268019  0.30905365]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.012165   -0.19594875  0.01886126  0.31273514]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01608398 -0.19610196  0.02511596  0.31807438]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02000602 -0.19625019  0.03147745  0.32492386]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02393102 -0.19634362  0.03797593  0.33307943]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 11.927606\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -4.35447746e-04  -1.94890208e-01   2.75285590e-04   2.87620919e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00433325 -0.19489566  0.0060277   0.28771129]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00823117 -0.19498611  0.01178193  0.28964121]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01213089 -0.19515143  0.01757475  0.29336583]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01603392 -0.19537307  0.02344207  0.29880843]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01994138 -0.19562278  0.02941824  0.30585489]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02385383 -0.19586077  0.03553534  0.31434556]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02777105 -0.19603328  0.04182225  0.32406482]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03169171 -0.19607011  0.04830354  0.33472945]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.908330\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00074938 -0.19498196 -0.00040229  0.28961662]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00315026 -0.19497679  0.00539005  0.28948943]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00704979 -0.19505593  0.01117983  0.2912044 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01095091 -0.19520996  0.01700392  0.29471932]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01485511 -0.19542094  0.02289831  0.29995954]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01876353 -0.19566118  0.0288975   0.30681281]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02267675 -0.19589145  0.03503376  0.31512135]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02659458 -0.19605866  0.04133618  0.32467167]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03051576 -0.19609334  0.04782962  0.3351831 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.889247\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -6.67229872e-04  -1.95024545e-01   1.09150883e-04   2.90546598e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00456772 -0.1950267   0.00592008  0.29058213]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00846825 -0.19511189  0.01173173  0.29245678]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01237049 -0.19526986  0.01758086  0.2961251 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01627589 -0.19548161  0.02350336  0.30150831]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02018552 -0.19571815  0.02953353  0.30848887]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02409988 -0.19593863  0.03570331  0.31690235]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02801866 -0.19608801  0.04204135  0.32652704]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03194042 -0.19609454  0.04857189  0.33707256]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.870354\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00087525 -0.19469618 -0.00068181  0.2834334 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00476917 -0.19468761  0.00498686  0.28321437]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00866292 -0.19476787  0.01065114  0.28483974]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01255828 -0.19492862  0.01634794  0.28827157]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01645685 -0.19515376  0.02211337  0.29344292]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02035993 -0.19541827  0.02798223  0.3002529 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02426829 -0.19568643  0.03398729  0.30855904]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02818202 -0.19590957  0.04015847  0.31816724]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03210021 -0.19602342  0.04652181  0.32882004]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.851651\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  2.04625444e-04  -1.95348801e-01   3.93542833e-04   2.97712222e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00370235 -0.19535265  0.00634779  0.2978318 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0076094  -0.19543324  0.01230442  0.299782  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01151807 -0.19557894  0.01830006  0.30351189]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01542965 -0.19576848  0.0243703   0.30893305]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01934502 -0.19596964  0.03054896  0.31591398]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02326441 -0.19613735  0.03686724  0.32427173]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02718716 -0.19621141  0.04335268  0.33376167]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 11.823134\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00042187 -0.19478044 -0.00037353  0.2852468 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00347374 -0.19477647  0.00533141  0.2851285 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00736927 -0.19485985  0.01103398  0.28685333]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01126647 -0.19502163  0.01677105  0.29038101]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0151669  -0.19524482  0.02257867  0.29564104]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0190718  -0.19550324  0.02849149  0.3025277 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02298186 -0.19575965  0.03454204  0.31089212]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02689705 -0.19596349  0.04075988  0.32053212]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03081632 -0.19604826  0.04717053  0.33118056]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.804903\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -8.52212571e-04  -1.95169622e-01   2.16601496e-04   2.93733326e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00475561 -0.19517239  0.00609127  0.29380093]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00865905 -0.19525554  0.01196729  0.29570469]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01256416 -0.19540825  0.01788138  0.29939686]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01647233 -0.19561056  0.02386932  0.30479459]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02038454 -0.19583209  0.02996521  0.31177435]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02430118 -0.19603019  0.0362007   0.32016377]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02822179 -0.19614758  0.04260397  0.32973122]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 11.776854\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.000787   -0.19572917  0.00043278  0.30634353]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00470158 -0.19573012  0.00655965  0.3064664 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00861619 -0.19579927  0.01268898  0.30840374]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01253217 -0.19592371  0.01885705  0.31209944]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01645065 -0.19607984  0.02509904  0.31745495]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02037224 -0.19623199  0.03144814  0.32432364]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02429688 -0.19633062  0.03793461  0.33250253]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 11.739086\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00055534 -0.19497338 -0.00080097  0.28942934]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00445481 -0.19496231  0.00498762  0.28917476]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00835406 -0.19503609  0.01077112  0.29076423]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01225478 -0.1951859   0.0165864   0.29415779]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01615849 -0.19539447  0.02246956  0.29928339]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02006638 -0.19563491  0.02845522  0.306032  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02397908 -0.195869    0.03457586  0.31424981]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02789646 -0.19604483  0.04086086  0.32372824]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03181736 -0.19609431  0.04733542  0.33419241]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.721695\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  9.76889818e-04  -1.94902053e-01   2.44767057e-04   2.87877967e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00292115 -0.19490697  0.00600233  0.28795837]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00681929 -0.19499674  0.01176149  0.28987839]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01071923 -0.19516124  0.01755906  0.29359324]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01462245 -0.19538191  0.02343093  0.29902608]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01853009 -0.19563046  0.02941145  0.30606263]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0224427  -0.19586705  0.0355327   0.31454295]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02636004 -0.19603785  0.04182356  0.32425108]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0302808  -0.19607257  0.04830858  0.33490336]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.704478\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -5.39606724e-04  -1.94622430e-01  -1.72238585e-04   2.81853700e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00443206 -0.19462227  0.00546484  0.28180115]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0083245  -0.19471141  0.01110086  0.2835904 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01221873 -0.19488102  0.01677267  0.28718175]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01611635 -0.19511459  0.0225163   0.29250689]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02001864 -0.19538674  0.02836644  0.2994638 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02392638 -0.19566139  0.03435571  0.30790889]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0278396  -0.19588943  0.04051389  0.31764675]\n",
      "aprob: nan\n",
      "action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03175739 -0.19600613  0.04686683  0.32841839]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.687433\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  4.46179043e-04  -1.95644092e-01   1.57524830e-04   3.04388384e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0034667  -0.19564256  0.00624529  0.30443061]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00737955 -0.19571166  0.0123339   0.3062933 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01129379 -0.19583922  0.01845977  0.30992329]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01521057 -0.19600265  0.02465824  0.31522631]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01913062 -0.19616766  0.03096276  0.32206147]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02305398 -0.19628638  0.03740399  0.33023306]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 11.650559\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00081167 -0.19562778 -0.00076093  0.30401633]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00310088 -0.19561526  0.0053194   0.3037821 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00701319 -0.19567488  0.01139504  0.30537405]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01092669 -0.19579604  0.01750252  0.30874516]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01484261 -0.19595791  0.02367743  0.3138082 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01876177 -0.19612826  0.02995359  0.32043061]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02268433 -0.19626166  0.0363622   0.32842673]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02660956 -0.19629732  0.04293074  0.33754799]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 11.624053\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -1.05923938e-04  -1.95049369e-01  -5.76787946e-04   2.91089721e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00400691 -0.19504138  0.00524501  0.29090727]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00790774 -0.19511678  0.01106315  0.29256698]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01181007 -0.19526623  0.01691449  0.29602692]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0157154  -0.1954717   0.02283503  0.30121203]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01962483 -0.19570534  0.02885927  0.30800905]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02353894 -0.19592759  0.03501945  0.31625866]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02745749 -0.19608496  0.04134462  0.32574536]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03137919 -0.19610749  0.04785953  0.33618609]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.607812\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -1.70628703e-04  -1.94702988e-01   8.43576861e-04   2.83579307e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00406469 -0.19471854  0.00651516  0.28385745]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00795906 -0.19482117  0.01219231  0.28597252]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01185548 -0.19500045  0.01791176  0.28987891]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01575549 -0.19523794  0.02370934  0.29550072]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01966025 -0.19550581  0.02961935  0.30272614]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02357037 -0.19576492  0.03567388  0.3113991 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02748567 -0.19596242  0.04190186  0.3213086 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03140491 -0.19602914  0.04832803  0.33217689]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.591734\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -4.16037130e-04  -1.95725317e-01   2.49146431e-04   3.06254416e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00433054 -0.19572418  0.00637423  0.30632266]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00824503 -0.19579159  0.01250069  0.30820668]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01216086 -0.19591497  0.01866482  0.31185168]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01607916 -0.19607107  0.02490186  0.31716055]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02000058 -0.19622467  0.03124507  0.32398842]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02392507 -0.19632672  0.03772483  0.3321344 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 11.555817\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  6.19719032e-04  -1.94995439e-01  -6.70264521e-05   2.89910754e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00328019 -0.19499517  0.00573119  0.28989047]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00718009 -0.19507862  0.011529    0.29171055]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01108167 -0.19523586  0.01736321  0.29532685]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01498638 -0.19544834  0.02326975  0.30066234]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01889535 -0.19568763  0.02928299  0.30760181]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0228091  -0.19591361  0.03543503  0.31598382]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02672737 -0.19607208  0.04175471  0.32559037]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03064882 -0.1960923   0.04826651  0.33613542]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.540259\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  1.40571313e-04  -1.95533418e-01  -2.77025035e-04   3.01867367e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0037701  -0.19552732  0.00576032  0.30177921]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00768064 -0.19559493  0.01179591  0.30351884]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01159254 -0.19572512  0.01786628  0.30703726]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01550704 -0.19589674  0.02400703  0.31224611]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01942498 -0.19607738  0.03025195  0.31901238]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02334653 -0.19622149  0.0366322   0.32715043]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02727096 -0.19626822  0.04317521  0.33641193]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 11.514856\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  6.57445914e-05  -1.94634244e-01   1.85687302e-04   2.82106458e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00382694 -0.19463979  0.00582782  0.28217111]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00771974 -0.19473409  0.01147124  0.28407592]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01161442 -0.19490784  0.01715276  0.28777932]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01551257 -0.19514391  0.02290834  0.29321072]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01941545 -0.19541621  0.02877256  0.30026526]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02332378 -0.19568775  0.03477786  0.30879575]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02723753 -0.19590833  0.04095378  0.31860229]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0311557  -0.19601192  0.04732582  0.32942043]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.499708\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00058246 -0.19492427  0.00036235  0.28836061]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00331603 -0.19493082  0.00612956  0.28847836]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00721464 -0.19502172  0.01189912  0.29043495]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01111508 -0.19518665  0.01770782  0.29418469]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01501881 -0.19540671  0.02359152  0.29964952]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01892694 -0.19565325  0.02958451  0.30671353]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02284001 -0.1958859   0.03571878  0.31521467]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02675773 -0.19605024  0.04202307  0.32493435]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03067873 -0.19607524  0.04852176  0.33558582]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.484711\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -8.39787291e-04  -1.94397367e-01  -2.52610616e-04   2.77064881e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00472773 -0.19439672  0.00528869  0.27698616]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00861567 -0.19448818  0.01082841  0.27874722]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01250543 -0.19466358  0.01640335  0.28231093]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0163987  -0.19490757  0.02204957  0.287614  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02029686 -0.19519653  0.02780185  0.294562  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02420079 -0.19549675  0.03369309  0.3030217 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02811072 -0.19576212  0.03975353  0.31281097]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03202596 -0.1959315   0.04600975  0.32368685]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03594459 -0.19592601  0.05248348  0.33533319]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 11.000000. running mean: 11.479864\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0006601  -0.19498734 -0.00062273  0.28973386]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00455985 -0.19497888  0.00517195  0.28953635]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00845943 -0.19505487  0.01096268  0.29118195]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01236052 -0.1952062   0.01678632  0.2946296 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01626465 -0.19541524  0.02267891  0.29980589]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02017295 -0.19565468  0.02867503  0.3066    ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02408605 -0.19588574  0.03480703  0.31485589]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02800376 -0.19605584  0.04110414  0.32436219]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03192488 -0.19609613  0.04759139  0.33484077]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.465065\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -5.06855084e-04  -1.94597176e-01   1.45194817e-05   2.81313901e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0043988  -0.19460014  0.0056408   0.28132276]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0082908  -0.19469254  0.01126725  0.28317239]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01218465 -0.19486537  0.0169307   0.28682244]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01608196 -0.19510195  0.02266715  0.29220407]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.019984   -0.19537676  0.02851123  0.29921481]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02389153 -0.19565356  0.03449553  0.30771058]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02780461 -0.19588308  0.04064974  0.31749539]\n",
      "aprob: nan\n",
      "action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03172227 -0.19600037  0.04699965  0.32830954]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.450414\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  1.46406373e-04  -1.94730132e-01  -5.34387396e-04   2.84163269e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0037482  -0.19472381  0.00514888  0.28399254]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00764267 -0.1948057   0.01082873  0.28566564]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01153879 -0.19496721  0.01654204  0.2891436 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01543813 -0.19519183  0.02232491  0.29435792]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01934197 -0.19545404  0.02821207  0.30120561]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02325105 -0.19571746  0.03423618  0.30954146]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0271654  -0.19593261  0.04042701  0.31916787]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03108405 -0.19603424  0.04681037  0.3298232 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.435910\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00042089 -0.1948638  -0.00072465  0.28704805]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00431816 -0.19485415  0.00501631  0.28681674]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00821525 -0.19493098  0.01075265  0.28842991]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01211387 -0.19508561  0.01652124  0.29184825]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01601558 -0.1953012   0.02235821  0.29700159]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0199216  -0.19555156  0.02829824  0.30378395]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02383263 -0.1957994   0.03437392  0.31204581]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02774862 -0.19599403  0.04061484  0.32158403]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0316685  -0.19606878  0.04704652  0.33213034]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.421551\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  4.15025460e-05  -1.94460259e-01   9.94819934e-05   2.78398242e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0038477  -0.19446526  0.00566745  0.27843624]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00773701 -0.1945613   0.01123617  0.28031329]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01162823 -0.19473959  0.01684244  0.28399003]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01552303 -0.19498401  0.02252224  0.28940001]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01942271 -0.19526988  0.02831024  0.29644457]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0233281  -0.19556213  0.03423913  0.30498485]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02723935 -0.19581298  0.04033883  0.31483162]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03115561 -0.19595925  0.04663546  0.32573327]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.407335\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00091309 -0.19448496 -0.00056368  0.27892234]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00480279 -0.19447884  0.00501477  0.27874053]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00869237 -0.19456411  0.01058958  0.28040102]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01258365 -0.19473279  0.0161976   0.28386729]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01647831 -0.19496957  0.02187495  0.28907594]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0203777  -0.19525073  0.02765646  0.2959319 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02428271 -0.19554239  0.0335751   0.30430081]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02819356 -0.19579817  0.03966112  0.31399895]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03210952 -0.19595659  0.0459411   0.32478154]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.393262\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  3.17369857e-04  -1.94895719e-01  -3.20944904e-05   2.87740543e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00358054 -0.19489649  0.00572272  0.28773212]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00747847 -0.19498253  0.01147736  0.28956477]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01137812 -0.19514412  0.01726865  0.29319524]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01528101 -0.19536316  0.02313256  0.29854851]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01918827 -0.19561196  0.02910353  0.30551256]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02310051 -0.19585134  0.03521378  0.31393025]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02701754 -0.19602834  0.04149239  0.32358903]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0309381  -0.19607361  0.04796417  0.33420935]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.379330\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  4.71541368e-04  -1.95497282e-01  -1.13749167e-04   3.01049182e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0034384  -0.19549346  0.00590723  0.30101092]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00734827 -0.19556394  0.01192745  0.30280101]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01125955 -0.19569743  0.01798347  0.30636984]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0151735  -0.1958727   0.02411087  0.3116288 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01909095 -0.19605731  0.03034345  0.31844491]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0230121  -0.19620574  0.03671234  0.32663275]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02693622 -0.19625716  0.043245    0.33594434]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 11.355536\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00094731 -0.19456739  0.00045345  0.28067775]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00483866 -0.19457765  0.006067    0.28083125]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00873021 -0.19467724  0.01168363  0.28282314]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01262375 -0.19485665  0.01734009  0.28661125]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01652089 -0.19509872  0.02307231  0.29212495]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02042286 -0.19537735  0.02891481  0.2992597 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02433041 -0.19565566  0.03490001  0.30786898]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02824352 -0.19588358  0.04105739  0.31775379]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03216119 -0.19599524  0.04741246  0.32865076]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.341981\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  1.83943236e-04  -1.94746033e-01  -8.12903806e-04   2.84504920e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00371098 -0.19473528  0.00487719  0.28424371]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00760568 -0.19481279  0.01056207  0.28582755]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01150194 -0.19497029  0.01627862  0.28921871]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01540134 -0.19519164  0.02206299  0.29434995]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01930518 -0.19545168  0.02794999  0.30111971]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02321421 -0.19571449  0.03397239  0.30938446]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0271285  -0.19593112  0.04016008  0.3189487 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03104712 -0.19603694  0.04653905  0.3295533 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.328561\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -3.31957097e-05  -1.94410856e-01   6.03783077e-04   2.77349847e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00392141 -0.19442456  0.00615078  0.27755599]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0078099  -0.19452933  0.0117019   0.27959806]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01170049 -0.19471587  0.01729386  0.28343488]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01559481 -0.19496757  0.02296256  0.28899834]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01949416 -0.19525923  0.02874253  0.29618796]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02339934 -0.19555519  0.03466628  0.30486282]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02731045 -0.19580696  0.04076354  0.31483111]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03122659 -0.19595055  0.04706016  0.32583807]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.315275\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00031326 -0.19559948 -0.00054404  0.30336982]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00359873 -0.19558973  0.00552335  0.30320081]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00751053 -0.19565252  0.01158737  0.30485818]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01142358 -0.19577697  0.01768453  0.30829383]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01533912 -0.19594203  0.02385041  0.31341967]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01925796 -0.19611526  0.0301188   0.32010243]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02318026 -0.19625103  0.03652085  0.32815572]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02710528 -0.19628832  0.04308397  0.33733022]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 11.292123\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00053978 -0.19528571 -0.00080862  0.29630582]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00336593 -0.19527371  0.0051175   0.29605273]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00727141 -0.1953411   0.01103855  0.29763827]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01117823 -0.19547828  0.01699132  0.30101939]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01508779 -0.19566639  0.0230117   0.30611723]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01900112 -0.19587613  0.02913405  0.3128121 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02291864 -0.19606599  0.03539029  0.32093566]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02683996 -0.19617995  0.041809    0.33026096]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 11.269201\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00043291 -0.19450025 -0.0003777   0.27924758]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00432292 -0.19449716  0.00520725  0.27912741]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00821286 -0.19458512  0.0107898   0.28084891]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01210456 -0.19475585  0.01640678  0.28437457]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01599968 -0.19499372  0.02209427  0.28963969]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01989955 -0.19527458  0.02788706  0.2965475 ]\n",
      "aprob: nan\n",
      "action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02380505 -0.19556399  0.03381801  0.30496144]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02771633 -0.19581493  0.03991724  0.31469504]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03163262 -0.19596509  0.04621114  0.32550013]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.256509\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00094032 -0.19543616  0.0003626   0.29967093]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00484904 -0.19543888  0.00635602  0.29977919]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00875782 -0.1955166   0.0123516   0.30171539]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01266815 -0.19565745  0.01838591  0.30542768]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0165813  -0.19583971  0.02449447  0.31082567]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02049809 -0.19603048  0.03071098  0.31777479]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0244187  -0.19618377  0.03706647  0.32608801]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02834238 -0.19623828  0.04358824  0.33551561]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 11.233944\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -1.75184990e-04  -1.94729010e-01  -2.89200240e-04   2.84139418e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00406977 -0.19472656  0.00539359  0.28404848]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0079643  -0.19481209  0.01107456  0.28580027]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01186054 -0.19497668  0.01679056  0.28935459]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01576007 -0.19520346  0.02257765  0.29464157]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01966414 -0.19546647  0.02847049  0.30155655]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02357347 -0.19572881  0.03450162  0.30995222]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02748805 -0.19594036  0.04070066  0.31962843]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03140685 -0.19603513  0.04709323  0.33032045]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.221605\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  5.76680088e-04  -1.95755040e-01   2.85920406e-04   3.06940801e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00333842 -0.19575406  0.00642474  0.3070194 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0072535  -0.19582083  0.01256512  0.30891193]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01116992 -0.19594264  0.01874336  0.31256295]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01508877 -0.19609596  0.02499462  0.31787429]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01901069 -0.19624523  0.03135211  0.32469956]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02293559 -0.19634096  0.0378461   0.33283592]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 11.189389\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  7.36321887e-04  -1.94508460e-01  -1.64838219e-04   2.79422539e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00315385 -0.19450887  0.00542361  0.27937275]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00704402 -0.19460001  0.01101107  0.28116379]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01093602 -0.19477332  0.01663434  0.28475705]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01483149 -0.19501282  0.02232948  0.29008653]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01873175 -0.19529395  0.02813121  0.29705378]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02263763 -0.19558172  0.03407229  0.30552011]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02654926 -0.19582845  0.04018269  0.31529637]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03046583 -0.19597107  0.04648862  0.32613113]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.177495\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00053905 -0.19449908  0.00056986  0.27922235]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00335093 -0.19451166  0.0061543   0.2794155 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00724116 -0.1946143   0.01174261  0.28144582]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01113345 -0.19479752  0.01737153  0.28527135]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0150294  -0.1950443   0.02307696  0.29082226]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01893029 -0.19532888  0.0288934   0.29799545]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02283686 -0.19561477  0.03485331  0.30664644]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02674916 -0.19585249  0.04098624  0.31657882]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03066621 -0.19597681  0.04731782  0.32753235]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.165720\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  1.99391428e-04  -1.95201179e-01   1.63263093e-04   2.94430490e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00370463 -0.19520298  0.00605187  0.29448093]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00760869 -0.19528467  0.01194149  0.29636713]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01151439 -0.19543538  0.01786883  0.30004131]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01542309 -0.19563509  0.02386966  0.3054202 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01933579 -0.19585327  0.02997806  0.31237956]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02325286 -0.19604703  0.03622566  0.32074597]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0271738  -0.19615882  0.04264057  0.33028651]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 11.144063\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  1.68398171e-04  -1.94453469e-01   1.64610575e-04   2.78254090e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00372067 -0.19445959  0.00572969  0.27831375]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00760986 -0.19455676  0.01129597  0.28021207]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.011501   -0.19473613  0.01690021  0.28390945]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01539572 -0.19498151  0.0225784   0.28933924]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01929535 -0.19526816  0.02836518  0.29640254]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02320071 -0.19556094  0.03429323  0.30496027]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02711193 -0.19581198  0.04039244  0.31482287]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03102817 -0.195958    0.0466889   0.32573836]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.132622\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00072287 -0.19486149  0.0008328   0.28699795]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00317436 -0.19487561  0.00657276  0.28726816]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00707187 -0.19497448  0.01231812  0.28937505]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01097136 -0.19514727  0.01810562  0.29327115]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0148743  -0.1953747   0.02397105  0.29887698]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0187818  -0.1956277   0.02994859  0.30607533]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02269435 -0.1958655   0.03607009  0.31470281]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02661166 -0.19603321  0.04236415  0.32453929]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03053232 -0.19605928  0.04885494  0.33529614]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.121296\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00080607 -0.19448795  0.00072346  0.27898543]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00469583 -0.19450315  0.00630317  0.2792296 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00858589 -0.19460835  0.01188776  0.28131002]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01247806 -0.19479392  0.01751396  0.28518413]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01637393 -0.19504269  0.02321765  0.29078148]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02027479 -0.19532867  0.02903328  0.29799833]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02418136 -0.19561518  0.03499324  0.30668933]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02809366 -0.19585246  0.04112703  0.31665708]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03201071 -0.19597497  0.04746017  0.32764011]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.110083\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00080589 -0.1954242  -0.0009623   0.29940284]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00310259 -0.19540977  0.00502576  0.2991043 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00701079 -0.19547215  0.01100784  0.30064098]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01092023 -0.1956016   0.01702066  0.30396935]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01483226 -0.19577879  0.02310005  0.30900838]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01874784 -0.19597361  0.02928022  0.31563467]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02266731 -0.19614337  0.03559291  0.32367464]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02659018 -0.19623065  0.0420664   0.33289468]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 11.088982\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00089527 -0.19513143  0.00035799  0.29289162]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0047979  -0.19513646  0.00621583  0.29300433]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00870063 -0.19522239  0.01207591  0.29495314]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01260508 -0.19537829  0.01797497  0.29868999]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01651265 -0.19558416  0.02394877  0.30413199]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02042433 -0.19580969  0.03003141  0.31115591]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02434052 -0.19601228  0.03625453  0.31958988]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02826077 -0.19613478  0.04264633  0.32920298]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 11.068092\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00076186 -0.19450198 -0.00055033  0.27928408]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00312818 -0.19449603  0.00503535  0.2791068 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0070181  -0.19458127  0.01061749  0.28077195]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01090973 -0.19474963  0.01623293  0.2842428 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01480472 -0.19498573  0.02191778  0.28945556]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01870444 -0.19526571  0.02770689  0.29631453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aprob: nan\n",
      "action 0\n",
      "[-0.02260975 -0.19555548  0.03363318  0.30468451]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02652086 -0.19580842  0.03972687  0.31438074]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03043703 -0.19596276  0.04601449  0.32515712]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.057411\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -9.36420278e-04  -1.95488140e-01   3.49851710e-05   3.00842578e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00484618 -0.19548627  0.00605184  0.30084979]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00875591 -0.1955587   0.01206883  0.30268488]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01266708 -0.19569396  0.01812253  0.30629742]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01658096 -0.19587058  0.02424848  0.311598  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02049837 -0.1960559   0.03048044  0.31845275]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02441949 -0.19620414  0.03684949  0.32667523]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02834357 -0.19625419  0.043383    0.33601633]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 11.036837\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.000521   -0.19445271  0.00053494  0.27823737]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00441006 -0.194465    0.00609968  0.27841985]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00829936 -0.19456795  0.01166808  0.28043916]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01219072 -0.19475224  0.01727686  0.28425398]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01608576 -0.19500114  0.02296194  0.28979569]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01998578 -0.19528928  0.02875786  0.29696292]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02389157 -0.19558072  0.03469712  0.30561352]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02780318 -0.19582665  0.04080939  0.31555406]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03171972 -0.19596264  0.04712047  0.32652786]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 11.026469\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  8.51285297e-04  -1.95784412e-01   2.16653542e-04   3.07620845e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0030644  -0.19578238  0.00636907  0.30767832]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00698005 -0.19584746  0.01252264  0.30954848]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.010897   -0.19596693  0.01871361  0.31317595]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01481634 -0.19611726  0.02497713  0.31846231]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01873868 -0.19626274  0.03134637  0.32526058]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02266394 -0.19635372  0.03785158  0.33336706]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 10.996204\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -2.66273358e-04  -1.94992726e-01  -4.73500059e-04   2.89851432e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00416613 -0.19498646  0.00532353  0.28970156]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00806586 -0.1950644   0.01111756  0.29139405]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01196715 -0.19521721  0.01694544  0.294887  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01587149 -0.195427    0.02284318  0.30010595]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01978003 -0.19566614  0.0288453   0.30693879]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02369335 -0.19589544  0.03498408  0.31522791]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02761126 -0.19606187  0.04128863  0.32475997]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0315325  -0.19609601  0.04778383  0.33525449]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.986242\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0009963  -0.19515988 -0.00095748  0.29351845]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0048995  -0.19514611  0.00491289  0.29321691]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00880242 -0.19521421  0.01077723  0.29475747]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01270671 -0.19535512  0.01667238  0.2980992 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01661381 -0.19555086  0.02263436  0.303167  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02052483 -0.19577344  0.0286977   0.30984671]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0244403  -0.19598302  0.03489464  0.31797733]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02835996 -0.19612568  0.04125418  0.32734108]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03228247 -0.19613097  0.04780101  0.33765219]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.976380\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00049841 -0.19507483 -0.00069184  0.29164766]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00439991 -0.19506508  0.00514111  0.29142892]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00830121 -0.19513842  0.01096969  0.29305251]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01220398 -0.19528559  0.01683074  0.29647687]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01610969 -0.19548864  0.02276028  0.3016271 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02001946 -0.19571972  0.02879282  0.30838993]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02393386 -0.19593927  0.03496062  0.31660591]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02785264 -0.19609379  0.04129274  0.32605933]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03177452 -0.19611328  0.04781392  0.33646684]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.966616\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00042693 -0.19538166 -0.00084567  0.29844811]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00433456 -0.19536889  0.0051233   0.29818483]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00824194 -0.19543366  0.01108699  0.29975762]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01215061 -0.19556618  0.01708215  0.30312266]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01606193 -0.19574715  0.0231446   0.30819913]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01997688 -0.19594655  0.02930858  0.31486423]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02389581 -0.19612191  0.03560587  0.32294534]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02781825 -0.19621605  0.04206477  0.3322101 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.946950\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00031114 -0.19439775  0.00086294  0.27707137]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00357681 -0.19441589  0.00640437  0.277364  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00746513 -0.19452495  0.01195165  0.27949102]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01135563 -0.19471534  0.01754147  0.28341022]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01524994 -0.19497014  0.02320967  0.28905236]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01914934 -0.1952638   0.02899072  0.29631565]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02305462 -0.19556024  0.03491703  0.30505758]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02696582 -0.19581044  0.04101818  0.3150843 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03088203 -0.19594979  0.04731987  0.32613861]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.937480\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -2.33465859e-04  -1.95260531e-01  -6.38034827e-04   2.95745962e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00413868 -0.19525094  0.00527688  0.29554577]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0080437  -0.19532105  0.0111878   0.29718404]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01195012 -0.19546105  0.01713148  0.30061699]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01585934 -0.19565194  0.02314382  0.30576521]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01977238 -0.19586427  0.02925912  0.31250857]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02368966 -0.1960564   0.0355093   0.32067836]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02761079 -0.19617221  0.04192286  0.33004718]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.918106\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00070396 -0.19534086  0.00090389  0.29753536]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00320285 -0.19535156  0.0068546   0.29781288]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00710988 -0.19543846  0.01281085  0.29991821]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01101865 -0.19558917  0.01880922  0.30379741]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01493044 -0.19578156  0.02488516  0.30935877]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01884607 -0.19598244  0.03107234  0.31646694]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02276572 -0.1961456   0.03740168  0.32493439]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02668863 -0.1962095   0.04390037  0.33451102]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.898924\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -7.28793232e-05  -1.95638759e-01  -2.04389185e-04   3.04266376e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00398565 -0.19563292  0.00588094  0.30419981]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00789831 -0.19569829  0.01196493  0.30595601]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01181228 -0.19582334  0.01808405  0.30948423]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01572875 -0.19598617  0.02427374  0.31469297]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01964847 -0.19615329  0.0305676   0.3214446 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02357153 -0.19627777  0.03699649  0.32954734]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02749709 -0.19629711  0.04358744  0.33874539]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.879935\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -8.54148708e-04  -1.95729789e-01   4.92976072e-05   3.06357415e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00476874 -0.1957263   0.00617645  0.30636602]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00868327 -0.19579151  0.01230377  0.30819135]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0125991  -0.19591318  0.01846759  0.31177985]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01651736 -0.1960684   0.02470319  0.31703583]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02043873 -0.19622233  0.03104391  0.32381591]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02436318 -0.19632637  0.03752023  0.33192103]\n",
      "aprob: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 10.851136\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00058365 -0.19468693  0.00062691  0.28323509]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00447739 -0.19469919  0.00629161  0.28344304]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00837137 -0.19479899  0.01196047  0.28548907]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01226735 -0.19497628  0.01767025  0.28932884]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01616687 -0.19521302  0.02345683  0.29488809]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02007114 -0.1954819   0.02935459  0.30205711]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02398077 -0.19574443  0.03539573  0.31068246]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02789566 -0.19594856  0.04160938  0.32055646]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03181463 -0.19602605  0.04802051  0.3314053 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.842625\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -1.93690690e-04  -1.95129649e-01  -1.73989370e-04   2.92852326e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00409628 -0.19512713  0.00568306  0.29279741]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00799883 -0.19520617  0.01153901  0.29458146]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01190295 -0.19535665  0.01743063  0.29815942]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01581008 -0.19555945  0.02339382  0.30345189]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01972127 -0.19578531  0.02946286  0.3103398 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02363698 -0.19599291  0.03566966  0.31865632]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02755684 -0.19612657  0.04204278  0.32817671]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.824198\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00046512 -0.1957     -0.00060633  0.305672  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00344888 -0.19568903  0.00550711  0.30548489]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00736266 -0.19574831  0.01161681  0.30711967]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01127763 -0.19586679  0.01775921  0.31052749]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01519496 -0.19602293  0.02396976  0.3156182 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01911542 -0.19618357  0.03028212  0.32225523]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02303909 -0.19630207  0.03672722  0.33024765]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 10.795956\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -8.15515816e-04  -1.95094752e-01  -1.00793243e-04   2.92085075e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00471741 -0.19509346  0.00574091  0.29205345]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00861928 -0.19517426  0.01158198  0.293861  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01252277 -0.195327    0.0174592   0.29746267]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01642931 -0.19553266  0.02340845  0.30277938]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02033996 -0.19576208  0.02946404  0.30969273]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0242552  -0.19597416  0.03565789  0.31803689]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02817468 -0.1961135   0.04201863  0.32758834]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.777997\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0009956  -0.19478467  0.00075286  0.2853375 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0048913  -0.19479817  0.00645961  0.28558401]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00878726 -0.19489768  0.01217129  0.28766794]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01268521 -0.1950727   0.01792464  0.29154316]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01658667 -0.19530447  0.02375551  0.29713246]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02049276 -0.1955647   0.02969816  0.30432188]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02440405 -0.1958136   0.03578459  0.31295237]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02832032 -0.1959975   0.04204364  0.32280919]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03224027 -0.19604629  0.04849983  0.33361013]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.770217\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -2.69836014e-04  -1.94727479e-01   9.54106116e-04   2.84105404e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00416439 -0.19474458  0.00663621  0.28441879]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00805928 -0.19484825  0.01232459  0.28656851]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01195624 -0.19502789  0.01805596  0.29050808]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0158568  -0.19526473  0.02386612  0.29616042]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01976209 -0.19553055  0.02978933  0.30341208]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02367271 -0.1957857   0.03585757  0.31210484]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02758842 -0.19597672  0.04209967  0.32202509]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03150795 -0.19603372  0.04854017  0.33289192]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.762515\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -4.94944502e-05  -1.95612308e-01  -5.01224064e-04   3.03662314e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00396174 -0.19560302  0.00557202  0.3035063 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0078738  -0.19566592  0.01164215  0.30517586]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01178712 -0.19579004  0.01774567  0.30862248]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01570292 -0.19595416  0.02391812  0.31375746]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.019622   -0.19612566  0.03019326  0.32044667]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02354452 -0.19625864  0.0366022   0.32850264]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02746969 -0.1962918   0.04317225  0.33767475]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.744889\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00084962 -0.19519518  0.0003532   0.29429794]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00475352 -0.19519968  0.00623916  0.29440797]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00865751 -0.19528392  0.01212732  0.29635285]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01256319 -0.1954368   0.01805438  0.30008376]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01647193 -0.195638    0.02405605  0.30551634]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02038469 -0.19585665  0.03016638  0.31252508]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02430182 -0.19604949  0.03641688  0.32093503]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02822281 -0.19615853  0.04283558  0.33051147]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.727441\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  8.98861400e-04  -1.95090165e-01   2.87341970e-04   2.91984334e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00300294 -0.19509448  0.00612703  0.29207546]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00690483 -0.1951805   0.01196854  0.29400379]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01080844 -0.19533753  0.01784861  0.29772215]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01471519 -0.19554591  0.02380306  0.30314909]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01862611 -0.1957758   0.02986604  0.3101634 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02254163 -0.19598522  0.03606931  0.31859586]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02646133 -0.19611777  0.04244122  0.32821886]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.710166\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -1.25072131e-04  -1.95552874e-01   9.60571910e-04   3.02310225e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00403613 -0.195562    0.00700678  0.30259729]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00794737 -0.19564272  0.01305872  0.30470403]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01186022 -0.19578186  0.0191528   0.30857329]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01577586 -0.1959559   0.02532427  0.31410739]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01969498 -0.19612966  0.03160642  0.3211622 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02361757 -0.19625436  0.03802966  0.3295387 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 10.683064\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00079192 -0.19555738 -0.00080092  0.30241214]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00311923 -0.19554462  0.00524732  0.30216493]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00703012 -0.19560565  0.01129062  0.30374719]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01094223 -0.19573011  0.01736556  0.30711294]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01485684 -0.19589765  0.02350782  0.31217693]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01877479 -0.19607673  0.02975136  0.31880957]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02269632 -0.1962228   0.03612755  0.32682915]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02662078 -0.19627616  0.04266414  0.33599194]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.666234\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -2.75475282e-04  -1.95788925e-01  -9.21142255e-04   3.07727595e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00419125 -0.19577395  0.00523341  0.30744778]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00810673 -0.1958274   0.01138237  0.30898663]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01202328 -0.19593848  0.0175621   0.31229636]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01594205 -0.19608574  0.02380802  0.31728692]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01986376 -0.19623588  0.03015376  0.32382097]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02378848 -0.19634202  0.03663018  0.33170616]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 10.639571\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00061607 -0.19557439  0.00039516  0.30279809]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00452756 -0.19557634  0.00645112  0.30291331]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00843909 -0.1956502   0.01250939  0.30485081]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01235209 -0.19578365  0.01860641  0.30855676]\n",
      "aprob: nan\n",
      "action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01626776 -0.19595408  0.02477754  0.313937  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02018684 -0.19612731  0.03105628  0.32085134]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02410939 -0.19625569  0.03747331  0.32910533]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0280345  -0.19627589  0.04405542  0.33844017]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.623176\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00087723 -0.19574318 -0.00059941  0.30666742]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00303764 -0.19573209  0.00553394  0.30648269]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00695228 -0.19579019  0.0116636   0.30811754]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01086808 -0.19590628  0.01782595  0.31152256]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01478621 -0.19605858  0.0240564   0.31660648]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01870738 -0.19621351  0.03038853  0.323231  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02263165 -0.19632393  0.03685315  0.33120288]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 10.596944\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  4.24440173e-04  -1.94705213e-01  -1.69417920e-04   2.83628058e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00346966 -0.19470475  0.00550314  0.28357617]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00736376 -0.19479248  0.01117467  0.28536642]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01125961 -0.19495936  0.01688199  0.28895823]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0151588  -0.19518848  0.02266116  0.29428156]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01906257 -0.19545382  0.02854679  0.30123168]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02297164 -0.19571848  0.03457142  0.30966131]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02688601 -0.1959323   0.04076465  0.31937036]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03080466 -0.19602928  0.04715206  0.33009416]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.590975\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  5.14007650e-04  -1.94438804e-01  -2.77556947e-04   2.77942860e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00337477 -0.19443759  0.0052813   0.27785583]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00726352 -0.19452805  0.01083842  0.27960928]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01115408 -0.19470192  0.0164306   0.2831658 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01504812 -0.19494372  0.02209392  0.28846141]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01894699 -0.19522956  0.02786315  0.29540057]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02285159 -0.19552539  0.03377116  0.30384851]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02676209 -0.19578468  0.03984813  0.31362109]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03067779 -0.19594572  0.04612055  0.32447292]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0345967  -0.19592904  0.05261001  0.33608508]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 11.000000. running mean: 10.595065\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00043395 -0.19479548 -0.00072899  0.28557093]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00346196 -0.19478593  0.00498243  0.28533752]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00735768 -0.19486387  0.01068918  0.28694879]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01125495 -0.19502079  0.01642815  0.29036614]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01515537 -0.19524018  0.02223548  0.29552081]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01906017 -0.19549637  0.02814589  0.30230909]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0229701  -0.19575278  0.03419207  0.31058455]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02688515 -0.19595958  0.04040377  0.32014798]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03080435 -0.19605116  0.04680672  0.33073581]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.589114\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -7.32906424e-05  -1.95626460e-01   3.50690584e-04   3.03985310e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00398582 -0.1956274   0.0064304   0.30408597]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00789837 -0.19569912  0.01251212  0.3060068 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01181235 -0.19582919  0.01863225  0.30969359]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01572893 -0.19599478  0.02482612  0.31505113]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01964883 -0.19616133  0.03112715  0.32193758]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02357206 -0.19628071  0.0375659   0.33015621]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 10.563223\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00048164 -0.19444026  0.00030719  0.27797374]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00340716 -0.19444883  0.00586666  0.27808086]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00729614 -0.19454845  0.01142828  0.28002578]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01118711 -0.19473012  0.0170288   0.28376839]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01508171 -0.19497752  0.02270416  0.28924154]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01898126 -0.19526575  0.02848899  0.2963458 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02288658 -0.1955595   0.03441591  0.30494146]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02679777 -0.19581069  0.04051474  0.31483819]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03071398 -0.1959558   0.0468115   0.32578308]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.557591\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -2.91635662e-04  -1.95121440e-01   6.32509726e-04   2.92671679e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00419406 -0.19513044  0.00648594  0.29287109]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00809667 -0.19522018  0.01234337  0.29490525]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01200108 -0.19537932  0.01824147  0.29872462]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01590866 -0.19558749  0.02421596  0.3042448 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01982041 -0.1958139   0.03030086  0.31134078]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02373669 -0.19601542  0.03652767  0.31983858]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.027657   -0.19613428  0.04292445  0.32950476]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.542015\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00089945 -0.19527182  0.00084898  0.29599691]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00300598 -0.19528247  0.00676892  0.29625974]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00691163 -0.19537077  0.01269411  0.29835267]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01081905 -0.19552461  0.01866116  0.30222301]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01472954 -0.19572239  0.02470562  0.30778118]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01864399 -0.1959316   0.03086125  0.31489491]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02256262 -0.19610696  0.03715915  0.32338068]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02648476 -0.19618803  0.04362676  0.33299334]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.526595\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00044486 -0.19577999 -0.00050687  0.30751885]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00436046 -0.19576977  0.0056435   0.30736184]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00827585 -0.19582772  0.01179074  0.30902187]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01219241 -0.19594236  0.01797118  0.3124485 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01611125 -0.19609153  0.02422015  0.31754883]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02003308 -0.19624113  0.03057112  0.32418232]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02395791 -0.19634335  0.03705477  0.3321529 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 10.501329\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  5.16809318e-07  -1.94807048e-01  -6.53528765e-04   2.85820698e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00389562 -0.19479864  0.00506289  0.28561183]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0077916  -0.19487748  0.01077512  0.28724731]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01168915 -0.19503493  0.01652007  0.29068801]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01558985 -0.19525431  0.02233383  0.29586453]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01949493 -0.19550973  0.02825112  0.30267223]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02340513 -0.19576432  0.03430456  0.3109635 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02732041 -0.1959679   0.04052383  0.32053769]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03123977 -0.19605447  0.04693459  0.33112946]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.496316\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00038154 -0.19438007 -0.00061937  0.27669816]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00426914 -0.19437326  0.00491459  0.27649711]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0081566  -0.1944591   0.01044454  0.27813711]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01204578 -0.19462989  0.01600728  0.28158285]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01593838 -0.19487091  0.02163894  0.28677326]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0198358  -0.19515925  0.0273744   0.29361681]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02373899 -0.19546213  0.03324674  0.30198399]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02764823 -0.1957346   0.03928642  0.31169733]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03156292 -0.1959169   0.04552036  0.32251965]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03548126 -0.19593172  0.05197076  0.33414156]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 11.000000. running mean: 10.501352\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  5.56684113e-05  -1.95385138e-01   8.80806186e-04   2.98525987e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00385203 -0.19539507  0.00685133  0.29879485]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00775994 -0.19548035  0.01282722  0.30089026]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01166954 -0.19562845  0.01884503  0.30475784]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01558211 -0.19581704  0.02494019  0.31030491]\n",
      "aprob: nan\n",
      "action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01949845 -0.19601258  0.03114628  0.31739457]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0234187  -0.19616842  0.03749417  0.32583729]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02734207 -0.19622247  0.04401092  0.33538046]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.486339\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  3.85081980e-04  -1.94931945e-01  -1.76535161e-05   2.88527478e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00351356 -0.19493274  0.0057529   0.28852342]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00741221 -0.19501823  0.01152336  0.2903601 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01131258 -0.19517857  0.01733057  0.29399378]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01521615 -0.19539545  0.02321044  0.29934858]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01912406 -0.19564088  0.02919741  0.3063111 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02303687 -0.19587526  0.03532364  0.3147224 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02695438 -0.19604511  0.04161808  0.32436768]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03087528 -0.1960805   0.04810544  0.33496466]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.481475\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00040919 -0.19449216 -0.00069848  0.27907494]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00429903 -0.19448378  0.00488302  0.27884854]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00818871 -0.19456683  0.01045999  0.28046509]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01208004 -0.19473348  0.0160693   0.28388861]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01597471 -0.19496858  0.02174707  0.28905629]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01987409 -0.19524861  0.02752819  0.29587372]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02377906 -0.19553987  0.03344567  0.30420734]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02768986 -0.19579626  0.03952982  0.31387446]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03160578 -0.1959566   0.0458073   0.32463148]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03552491 -0.19594199  0.05229993  0.33616167]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 11.000000. running mean: 10.486661\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00052604 -0.19442411 -0.00060395  0.27763059]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00441452 -0.19441745  0.00494866  0.277435  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00830287 -0.19450295  0.01049736  0.27908107]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01219293 -0.19467277  0.01607898  0.28253303]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01608639 -0.19491197  0.02172964  0.28772887]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01998463 -0.19519731  0.02748422  0.29457565]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02388857 -0.19549558  0.03337573  0.30294188]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02779848 -0.19576124  0.03943457  0.31264759]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03171371 -0.19593383  0.04568752  0.32345249]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03563239 -0.19593527  0.05215657  0.33504362]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 11.000000. running mean: 10.491794\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  7.62645298e-04  -1.95438924e-01  -2.12514394e-04   2.99733060e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00314613 -0.19543419  0.00578215  0.2996649 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00705482 -0.19550512  0.01177544  0.30142778]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01096492 -0.19564075  0.017804    0.30497337]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01487773 -0.19582037  0.02390347  0.31021519]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01879414 -0.19601222  0.03010777  0.31702327]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02271439 -0.19617168  0.03644824  0.32521607]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02663782 -0.19623902  0.04295256  0.33455041]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.476876\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -6.91919111e-04  -1.95579811e-01  -1.01982942e-04   3.02921165e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00460352 -0.1955756   0.00595644  0.30288587]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00851503 -0.19564384  0.01201416  0.30467547]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0124279  -0.19577299  0.01810767  0.30823927]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01634336 -0.19594131  0.02427245  0.31348653]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02026219 -0.19611562  0.03054218  0.32028102]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0241845  -0.19624943  0.0369478   0.32843298]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02810949 -0.19628075  0.04351646  0.33768914]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.462107\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  7.28410003e-04  -1.95659388e-01   5.69791876e-05   3.04738683e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00318478 -0.19565653  0.00615175  0.30475049]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00709791 -0.19572408  0.01224676  0.3065826 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01101239 -0.19584998  0.01837841  0.31018231]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01492939 -0.19601173  0.02458206  0.31545568]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01884962 -0.19617513  0.03089117  0.32226208]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02277313 -0.19629236  0.03733642  0.33040603]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 10.437486\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00084273 -0.19449296 -0.00039391  0.27909259]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00304713 -0.19448963  0.00518794  0.27896703]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00693693 -0.19457745  0.01076728  0.28068315]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01082847 -0.19474817  0.01638095  0.28420354]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01472344 -0.19498623  0.02206502  0.28946377]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01862316 -0.19526757  0.02785429  0.29636739]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02252851 -0.19555784  0.03378164  0.30477827]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02643967 -0.19581014  0.03987721  0.31451054]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03035587 -0.19596235  0.04616742  0.32531669]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.433111\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  3.32948492e-04  -1.94541805e-01  -4.56001547e-05   2.80132539e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00355789 -0.19454404  0.00555705  0.28012198]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00744877 -0.19463648  0.01115949  0.28195202]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0113415  -0.19481031  0.01679853  0.28558317]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0152377  -0.19504924  0.02251019  0.2909481 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01913869 -0.19532825  0.02832916  0.29794649]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02304525 -0.19561178  0.03428809  0.3064372 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02695749 -0.1958514   0.04041683  0.316228  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03087452 -0.19598319  0.04674139  0.32706368]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.428780\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00085246 -0.19538906 -0.00055788  0.29861346]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00305532 -0.19538006  0.00541439  0.29843904]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00696292 -0.19544815  0.01138317  0.30009907]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01087188 -0.19558306  0.01738516  0.30354793]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01478354 -0.19576494  0.02345611  0.30870267]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01869884 -0.19596316  0.02963017  0.31543795]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02261811 -0.19613448  0.03593893  0.32357802]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0265408  -0.1962208   0.04241049  0.33288679]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.414493\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00084775 -0.19454335 -0.00095284  0.28016375]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00304311 -0.19453068  0.00465043  0.27985389]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00693373 -0.19460905  0.01024751  0.28138854]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01082591 -0.19477083  0.01587528  0.28473246]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01472132 -0.19500101  0.02156993  0.2898232 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01862134 -0.19527615  0.0273664   0.29656648]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02252687 -0.19556259  0.03329773  0.30482865]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02643812 -0.19581425  0.0393943   0.31442687]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0303544  -0.19596999  0.04568284  0.32511738]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.410348\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00063104 -0.19488668  0.00068876  0.28754402]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00326669 -0.19489841  0.00643964  0.28776726]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00716466 -0.19499469  0.01219499  0.28982783]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01106455 -0.19516481  0.01799154  0.29367874]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01496785 -0.1953896   0.02386512  0.29924079]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01887564 -0.19564004  0.02984993  0.30639697]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02278844 -0.19587544  0.03597787  0.314984  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02670595 -0.19604096  0.04227755  0.32478187]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03062677 -0.19606513  0.04877319  0.33550214]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.406244\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00039233 -0.1948773   0.00095736  0.28734038]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00350521 -0.19489317  0.00670417  0.28765017]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00740308 -0.19499339  0.01245717  0.28979581]\n",
      "aprob: nan\n",
      "action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01130295 -0.1951669   0.01825309  0.29372899]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01520628 -0.19539414  0.02412767  0.2993691 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01911417 -0.19564568  0.03011505  0.30659744]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02302708 -0.19588028  0.036247    0.31524873]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02694469 -0.19604251  0.04255197  0.32510051]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03086554 -0.19606018  0.04905398  0.33586139]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.402182\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00086575 -0.19505111 -0.00063995  0.29112779]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00476677 -0.19504219  0.00518261  0.2909253 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00866761 -0.1951167   0.01100111  0.29256523]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01256995 -0.19526538  0.01685242  0.296006  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01647525 -0.19547031  0.02277254  0.30117288]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02038466 -0.19570371  0.028796    0.30795303]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02429873 -0.19592618  0.03495506  0.31618763]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02821726 -0.19608437  0.04127881  0.32566178]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03213895 -0.19610848  0.04779205  0.33609311]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.398160\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00083257 -0.19559369 -0.00090502  0.30323868]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00474445 -0.19557953  0.00515976  0.30296045]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00865604 -0.19563844  0.01121896  0.30451063]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01256881 -0.19576016  0.01730918  0.30784352]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01648401 -0.19592431  0.02346605  0.31287372]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0204025  -0.19609926  0.02972352  0.31947115]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02432448 -0.1962403   0.03611294  0.32745328]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02824929 -0.19628752  0.04266201  0.33657536]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.384178\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0008907  -0.19535073  0.00098496  0.297756  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00479771 -0.19536239  0.00694008  0.29805821]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00870496 -0.19544995  0.01290125  0.30018741]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01261396 -0.19560084  0.01890499  0.30408905]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01652598 -0.19579274  0.02498678  0.3096706 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02044183 -0.1959922   0.03118019  0.31679567]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02436168 -0.19615271  0.0375161   0.32527542]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02828473 -0.19621235  0.04402161  0.3348582 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.370336\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  7.38001267e-04  -1.94884469e-01   8.06150364e-05   2.87496496e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00315969 -0.19488701  0.00583054  0.28752438]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00705743 -0.19497486  0.01158103  0.28939285]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01095693 -0.19513818  0.01736889  0.29305817]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01485969 -0.19535876  0.02323005  0.2984449 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01876686 -0.19560876  0.02919895  0.30544055]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02267904 -0.19584889  0.03530776  0.31388751]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02659602 -0.196026    0.04158551  0.32357264]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03051654 -0.19607059  0.04805696  0.33421569]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.366633\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  2.28953955e-04  -1.95592678e-01   7.46064440e-04   3.03215163e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0036829  -0.19559873  0.00681037  0.30343593]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00759487 -0.1956758   0.01287909  0.30547599]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01150839 -0.1958109   0.01898861  0.30927902]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01542461 -0.19598068  0.02517419  0.31474783]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01934422 -0.19615005  0.03146914  0.32173854]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02326722 -0.1962703   0.03790391  0.33005221]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 10.342967\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -7.47542278e-05  -1.94524706e-01   5.30289501e-05   2.79768364e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00396525 -0.19452864  0.0056484   0.27979046]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00785582 -0.19462288  0.01124421  0.28165253]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01174828 -0.19479855  0.01687726  0.2853148 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01564425 -0.19503927  0.02258355  0.29070973]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01954504 -0.19531998  0.02839775  0.2977369 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02345143 -0.19560508  0.03435248  0.30625508]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02736354 -0.1958461   0.04047759  0.31607193]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03128046 -0.19597907  0.04679902  0.32693214]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.339537\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  3.59485422e-04  -1.94931328e-01  -1.74387980e-04   2.88514028e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00353914 -0.19492978  0.00559589  0.28845976]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00743774 -0.1950131   0.01136509  0.29024702]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.011338   -0.19517168  0.01717003  0.29383291]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01524143 -0.19538747  0.02304669  0.2991425 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01914918 -0.19563275  0.02902954  0.30606358]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02306184 -0.19586831  0.03515081  0.31443866]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0269792  -0.1960411   0.04143958  0.32405469]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03090002 -0.19608169  0.04792068  0.33463152]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.336142\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  3.00844464e-04  -1.95800990e-01   1.46444406e-04   3.08005491e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00361518 -0.19579802  0.00630655  0.30804189]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00753114 -0.19586183  0.01246739  0.30989044]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01144837 -0.19597979  0.0186652   0.313496  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01536797 -0.19612836  0.02493512  0.31876025]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01929054 -0.19627185  0.03131033  0.32553614]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02321597 -0.19636059  0.03782105  0.33361983]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 10.312780\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  6.92889294e-04  -1.95002228e-01   7.80786945e-05   2.90058968e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00320716 -0.19500406  0.00587926  0.29008485]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00710724 -0.19508933  0.01168096  0.29195029]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01100902 -0.1952479   0.01751996  0.29561026]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01491398 -0.19546092  0.02343217  0.30098667]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0188232  -0.19569965  0.0294519   0.30796302]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02273719 -0.19592355  0.03561116  0.31637618]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02665566 -0.19607796  0.04193868  0.32600616]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03057722 -0.19609156  0.04845881  0.33656452]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.309653\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  5.31588524e-04  -1.94530329e-01   4.85461924e-05   2.79888086e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00335902 -0.19453416  0.00564631  0.27990865]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0072497  -0.19462824  0.01124448  0.28176928]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01114227 -0.19480367  0.01687987  0.28543014]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01503834 -0.19504406  0.02258847  0.2908236 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01893922 -0.19532431  0.02840494  0.29784911]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02284571 -0.19560878  0.03436192  0.30636522]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02675788 -0.19584895  0.04048923  0.31617933]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03067486 -0.19598075  0.04681281  0.3270358 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.306556\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00099228 -0.19554394 -0.00039924  0.30210619]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0029186  -0.19553626  0.00564288  0.30198088]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00682932 -0.19560219  0.0116825   0.30368358]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01074137 -0.19573079  0.01775617  0.30716591]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01465598 -0.19590106  0.02389949  0.31234014]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.018574   -0.19608074  0.03014629  0.31907388]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02249562 -0.19622447  0.03652777  0.32718212]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02642011 -0.19627161  0.04307141  0.33641735]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.293490\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -1.79913315e-05  -1.94620483e-01   9.30032481e-04   2.81810683e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0039104  -0.19463806  0.00656625  0.28211938]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00780316 -0.19474372  0.01220863  0.28426427]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01169804 -0.19492718  0.01789392  0.28820025]\n",
      "aprob: nan\n",
      "action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01559658 -0.19517028  0.02365792  0.29385281]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01949999 -0.19544566  0.02953498  0.30111233]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0234089  -0.19571485  0.03555723  0.30982573]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0273232  -0.19592583  0.04175374  0.31978586]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03124171 -0.19601043  0.04814946  0.33071948]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.290556\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  2.95193672e-04  -1.95238123e-01   6.83993713e-04   2.95248750e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00360957 -0.19524684  0.00658897  0.2954612 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00751451 -0.19533407  0.01249819  0.29750561]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01142119 -0.19548808  0.0184483   0.30133069]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01533095 -0.19568772  0.02447492  0.30684882]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0192447  -0.19590114  0.0306119   0.31393031]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02316273 -0.19608379  0.0368905   0.32239492]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0270844  -0.19617618  0.0433384   0.33200149]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.277650\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  2.45586396e-04  -1.95760609e-01  -7.04131450e-04   3.07070633e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00366963 -0.19574823  0.00543728  0.30685488]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00758459 -0.19580473  0.01157438  0.30845829]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01150068 -0.19591904  0.01774354  0.31183197]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01541907 -0.19606946  0.02398018  0.31688495]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01934045 -0.1962225   0.03031788  0.32347915]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02326491 -0.19633106  0.03678747  0.3314215 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 10.254873\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00098987 -0.19552481 -0.00075086  0.30167306]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00490037 -0.1955128   0.0052826   0.30144068]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00881062 -0.19557522  0.01131141  0.30303884]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01272213 -0.19570176  0.01737219  0.30642163]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01663616 -0.19587214  0.02350062  0.3115042 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0205536  -0.196055    0.02973071  0.31815779]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0244747  -0.19620603  0.03609386  0.32620179]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02839882 -0.19626584  0.0426179   0.33539396]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.242325\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00067457 -0.19464857  0.00056016  0.28241276]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00456754 -0.19466003  0.00620841  0.28259973]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00846074 -0.19475963  0.01186041  0.28462501]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01235593 -0.19493752  0.01755291  0.28844503]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01625468 -0.19517595  0.02332181  0.29398676]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0201582  -0.19544802  0.02920154  0.30114224]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02406716 -0.1957158   0.03522439  0.30976039]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02798148 -0.1959279   0.04141959  0.31963643]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03190004 -0.19601688  0.04781232  0.33050008]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.239902\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00087378 -0.1945316   0.00072779  0.27991415]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00301686 -0.19454656  0.00632607  0.28015872]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00690779 -0.194651    0.01192925  0.28223996]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01080081 -0.19483513  0.01757404  0.28611478]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01469751 -0.19508156  0.02329634  0.29171177]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01859914 -0.19536398  0.02913058  0.29892571]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02250642 -0.19564526  0.03510909  0.30760928]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02641933 -0.19587506  0.04126128  0.31756259]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03033683 -0.19598719  0.04761253  0.32852111]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.237502\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  1.35325409e-04  -1.95110500e-01   3.90368164e-04   2.92431097e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00376688 -0.19511614  0.00623899  0.2925544 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00766921 -0.19520302  0.01209008  0.29451401]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01157327 -0.1953602   0.01798036  0.29826191]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01548047 -0.19556776  0.0239456   0.30371551]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01939183 -0.19579548  0.03001991  0.3107521 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02330774 -0.19600094  0.03623495  0.31920049]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02722776 -0.19612716  0.04261896  0.32883069]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.225127\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  7.88912081e-04  -1.94908484e-01  -1.25563541e-04   2.88017642e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00310926 -0.19490778  0.00563479  0.28797913]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00700741 -0.19499224  0.01139437  0.28978207]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01090726 -0.19515227  0.01719001  0.29338356]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0148103  -0.19536983  0.02305768  0.29870888]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0187177  -0.19561731  0.02903186  0.30564623]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02263005 -0.19585562  0.03514479  0.31403874]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02654716 -0.19603186  0.04142556  0.32367415]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0304678  -0.19607681  0.04789904  0.33427326]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.222876\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  9.79039685e-04  -1.94516299e-01   2.67595458e-04   2.79589257e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00291129 -0.1945238   0.00585938  0.27968228]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00680176 -0.19462149  0.01145303  0.28161416]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01069419 -0.19480022  0.01708531  0.28534419]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0145902  -0.19504335  0.02279219  0.29080384]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01849106 -0.19532551  0.02860827  0.2978915 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02239757 -0.1956107   0.0345661   0.3064645 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02630979 -0.19585001  0.04069539  0.31632869]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03022679 -0.19597891  0.04702196  0.32722656]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.220647\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00048434 -0.19456263  0.00093981  0.28057497]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00340691 -0.19458083  0.00655131  0.28088855]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00729853 -0.19468784  0.01216908  0.2830379 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01119229 -0.19487354  0.01782984  0.28697855]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01508976 -0.19512006  0.02356941  0.29263724]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01899216 -0.19540046  0.02942216  0.29990622]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02290017 -0.19567685  0.03542028  0.30863497]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02681371 -0.19589792  0.04159298  0.31861951]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03073166 -0.19599632  0.04796537  0.32959046]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.218441\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00082336 -0.19563593  0.00051726  0.30420217]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00473608 -0.19563879  0.0066013   0.30435271]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00864886 -0.19571197  0.01268835  0.30632196]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0125631  -0.19584274  0.01881479  0.3100545 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01647995 -0.1960079   0.02501588  0.31545365]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02040011 -0.19617247  0.03132495  0.32237577]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02432356 -0.19628777  0.03777247  0.33062195]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 10.196257\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00033068 -0.19553505  0.0005448   0.30190476]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00424138 -0.19553921  0.0065829   0.3020663 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00815217 -0.19561597  0.01262422  0.30405089]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01206449 -0.19575287  0.01870524  0.30780427]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01597954 -0.19592728  0.02486133  0.31323223]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01989809 -0.19610504  0.03112597  0.32019485]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02382019 -0.19623861  0.03752987  0.32849822]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02774496 -0.19626476  0.04409983  0.33788426]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.184294\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -5.40041466e-06  -1.94370727e-01   4.72670701e-04   2.76500860e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00389281 -0.19438246  0.00600269  0.27666409]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00778046 -0.19448586  0.01153597  0.2786633 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01167018 -0.19467191  0.01710924  0.28245837]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01556362 -0.19492436  0.0227584   0.2879827 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01946211 -0.19521855  0.02851806  0.29513797]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02336648 -0.19551948  0.03442082  0.30378611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aprob: nan\n",
      "action 0\n",
      "[-0.02727687 -0.19577952  0.04049654  0.31373889]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03119246 -0.19593566  0.04677132  0.32474592]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.182451\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -3.78586258e-05  -1.94837554e-01  -8.52095207e-04   2.86479729e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00393461 -0.194826    0.0048775   0.28620699]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00783113 -0.19490145  0.01060164  0.28777937]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01172916 -0.19505544  0.01635723  0.29115848]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01563027 -0.19527147  0.0221804   0.29627544]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0195357  -0.19552377  0.0281059   0.30302602]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02344617 -0.1957756   0.03416643  0.31126299]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02736168 -0.19597694  0.04039169  0.3207861 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03128122 -0.19606192  0.04680741  0.3313305 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.180627\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00044378 -0.19576325  0.00045325  0.30713096]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00435905 -0.1957641   0.00659587  0.30725906]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00827433 -0.19583226  0.01274105  0.30919961]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01219097 -0.1959547   0.01892504  0.31289591]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01611007 -0.19610754  0.02518296  0.31824834]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02003222 -0.19625477  0.03154792  0.3251087 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02395731 -0.1963464   0.0380501   0.333272  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 10.158820\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  7.99263921e-05  -1.95510400e-01   6.00876627e-04   3.01346384e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00383028 -0.19551549  0.0066278   0.30152564]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00774059 -0.19559365  0.01265832  0.30352862]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01165246 -0.19573242  0.01872889  0.30730101]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01556711 -0.19590919  0.02487491  0.31274885]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0194853  -0.19608992  0.03112989  0.31973273]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02340709 -0.1962272   0.03752454  0.32805944]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02733164 -0.196258    0.04408573  0.33747179]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.147232\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  1.44479732e-04  -1.95086286e-01  -4.35890940e-04   2.91899170e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00375725 -0.19508021  0.00540209  0.29176156]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00765885 -0.19515674  0.01123732  0.29346491]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01156198 -0.19530625  0.01710662  0.29696613]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01546811 -0.19551029  0.02304594  0.30218846]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01937832 -0.19574043  0.02908971  0.30901632]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02329312 -0.19595644  0.03527004  0.31728737]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02721225 -0.19610392  0.04161579  0.32678237]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03113433 -0.19611192  0.04815143  0.3372138 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.145760\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00084339 -0.19505271 -0.00035343  0.29116293]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00305766 -0.19504797  0.00546983  0.29105139]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00695862 -0.19512631  0.01129086  0.29278092]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01086115 -0.19527808  0.01714648  0.29630831]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01476671 -0.19548488  0.02307264  0.30155703]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01867641 -0.19571838  0.02910378  0.30841204]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02259077 -0.19593849  0.03527203  0.31671184]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02650954 -0.19609107  0.04160626  0.32623823]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03043136 -0.1961054   0.04813103  0.33670498]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.144302\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  1.68039700e-04  -1.95418599e-01   5.43228633e-04   2.99276339e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00374033 -0.19542381  0.00652876  0.29944042]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00764881 -0.19550414  0.01251756  0.30143198]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01155889 -0.1956475   0.0185462   0.3051983 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01547184 -0.19583195  0.02465017  0.31064815]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01938848 -0.19602436  0.03086313  0.31764617]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02330897 -0.19617852  0.03721606  0.32600442]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02723254 -0.19623283  0.04373614  0.33547219]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.132859\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00035549 -0.19578463 -0.00082147  0.30762747]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00427118 -0.1957708   0.00533108  0.30737716]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0081866  -0.1958254   0.01147862  0.30894525]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01210311 -0.19593746  0.01765752  0.31228336]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01602186 -0.19608538  0.02390319  0.3173008 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01994356 -0.19623569  0.03024921  0.32385955]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02386828 -0.19634131  0.0367264   0.33176647]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 10.111531\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00031448 -0.19567593  0.00036942  0.30511835]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.004228   -0.19567664  0.00647179  0.30522355]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00814153 -0.19574694  0.01257626  0.30714639]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01205647 -0.1958742   0.01871919  0.3108319 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01597396 -0.19603526  0.02493582  0.31618341]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01989466 -0.19619507  0.03125949  0.32305696]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02381856 -0.19630488  0.03772063  0.33125306]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 10.090415\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00088752 -0.19539935 -0.00034817  0.29884396]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0047955  -0.19539306  0.00562871  0.29873418]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00870336 -0.19546341  0.01160339  0.30045748]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01261263 -0.19559978  0.01761254  0.30396683]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01652463 -0.1957819   0.02369188  0.30917763]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02044027 -0.19597862  0.02987543  0.31596245]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02435984 -0.19614609  0.03619468  0.32414306]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02828276 -0.19622549  0.04267754  0.33348028]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.079511\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -2.81372279e-04  -1.94728463e-01   4.06942837e-04   2.84127542e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00417594 -0.19473697  0.00608949  0.28426305]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00807068 -0.19483271  0.01177475  0.28623787]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01196734 -0.1950058   0.01749951  0.2900083 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01586745 -0.19523833  0.02329968  0.29550044]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01977222 -0.19550307  0.02920969  0.30260474]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02368228 -0.1957616   0.03526178  0.31116781]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02759751 -0.19596193  0.04148514  0.32098198]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03151675 -0.19603588  0.04790478  0.33177348]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.078716\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00037771 -0.19510556 -0.00054445  0.29232254]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00427982 -0.19509785  0.005302    0.29215067]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00818178 -0.19517253  0.01114501  0.29381998]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01208523 -0.19532007  0.01702141  0.29728777]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01599163 -0.19552212  0.02296717  0.30247753]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01990207 -0.1957503   0.02901672  0.30927383]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02381708 -0.19596441  0.03520219  0.31751444]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02773636 -0.19611012  0.04155248  0.32698019]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03165857 -0.19611649  0.04809209  0.33738363]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.077929\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00097812 -0.19515431 -0.00037035  0.29339556]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00488121 -0.19514888  0.00549756  0.29327876]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00878419 -0.1952248   0.01136313  0.29500144]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01268868 -0.19537216  0.01726316  0.2985194 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01659613 -0.19557205  0.02323355  0.30375393]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02050757 -0.19579538  0.02930863  0.31058659]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02442348 -0.19600102  0.03552036  0.31885121]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0283435  -0.19613352  0.04189738  0.32832378]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.067150\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.09695097e-04  -1.95631917e-01  -7.57303642e-06   3.04109810e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00370294 -0.19562849  0.00607462  0.30410253]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00761551 -0.1956962   0.01215667  0.30591725]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01152944 -0.19582318  0.01827502  0.30950203]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0154459  -0.19598723  0.02446506  0.3147641 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01936565 -0.1961545   0.03076034  0.32156445]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02328874 -0.19627767  0.03719163  0.32970968]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 10.046478\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -2.35336456e-04  -1.94488351e-01  -6.38735950e-04   2.78994147e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0041251  -0.19448097  0.00494115  0.2787875 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00801472 -0.19456502  0.0105169   0.28042351]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01190602 -0.19473258  0.01612537  0.28386596]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01580067 -0.19496846  0.02180269  0.2890518 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01970004 -0.19524904  0.02758372  0.29588633]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02360502 -0.19554054  0.03350145  0.30423568]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02751584 -0.19579676  0.03958616  0.31391672]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03143177 -0.19595638  0.0458645   0.32468538]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0353509  -0.19594037  0.0523582   0.33622431]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 11.000000. running mean: 10.056013\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  1.94486157e-04  -1.95736198e-01   8.88985766e-04   3.06507176e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00372024 -0.19574233  0.00701913  0.30676562]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00763508 -0.19581581  0.01315444  0.30883522]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0115514  -0.19594295  0.01933115  0.31265672]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01547026 -0.19609922  0.02558428  0.31812796]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01939224 -0.19624793  0.03194684  0.32509805]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0233172  -0.19633829  0.0384488   0.33335893]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 10.035453\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  9.18048559e-05  -1.95191950e-01   6.50540117e-04   2.94226548e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00381203 -0.19520061  0.00653507  0.2944298 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00771605 -0.19528869  0.01242367  0.29646626]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01162182 -0.19544465  0.01835299  0.30028545]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01553071 -0.19564767  0.0243587   0.3058011 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01944367 -0.19586634  0.03047472  0.31288549]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02336099 -0.19605671  0.03673243  0.321361  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02728213 -0.19616001  0.04315965  0.33098969]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.025099\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00050055 -0.19570003 -0.00084132  0.30567353]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00341345 -0.19568629  0.00527215  0.30541609]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00732717 -0.19574307  0.01138047  0.30698173]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01124203 -0.1958597   0.01752011  0.31032312]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01515923 -0.1960151   0.02372657  0.31535185]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01907953 -0.19617657  0.03003361  0.32193329]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02300306 -0.19629805  0.03647227  0.3298789 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02692902 -0.19631799  0.04306985  0.33893647]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.014848\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  5.36407120e-04  -1.95651396e-01  -2.87640586e-04   3.04555721e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00337662 -0.19564447  0.00580347  0.30446407]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00728951 -0.19570858  0.01189276  0.30619504]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01120368 -0.19583226  0.01801666  0.30969827]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01512033 -0.19599371  0.02421062  0.31488253]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0190402  -0.19615949  0.03050827  0.32161041]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02296339 -0.19628276  0.03694048  0.32969032]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02688905 -0.19630104  0.04353429  0.33886664]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 10.004699\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00073857 -0.19454714  0.00099948  0.28024443]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00315237 -0.19456643  0.00660437  0.28057809]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0070437  -0.19467466  0.01221593  0.28274708]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01093719 -0.19486166  0.01787087  0.28670681]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01483443 -0.19510957  0.02360501  0.29238402]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01873662 -0.19539145  0.02945269  0.29967109]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02264445 -0.19566942  0.03544611  0.30841764]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02655784 -0.19589224  0.04161446  0.31841997]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03047568 -0.19599259  0.04798286  0.32940896]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 10.004652\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  2.77946658e-05  -1.95543227e-01   5.41756334e-04   3.02090192e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00388307 -0.19554727  0.00658356  0.30225059]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00779402 -0.19562373  0.01262857  0.30423372]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01170649 -0.19576014  0.01871325  0.30798523]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01562169 -0.19593381  0.02487295  0.3134107 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01954037 -0.19611053  0.03114117  0.32036995]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02346258 -0.19624265  0.03754856  0.32866866]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02738743 -0.19626686  0.04412194  0.33804826]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.994606\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  9.85150156e-04  -1.95270290e-01  -4.58520352e-05   2.95962554e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00292026 -0.19526877  0.0058734   0.29594694]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00682563 -0.19534609  0.01179234  0.29776656]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01073255 -0.19549151  0.01774767  0.30137407]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01464238 -0.19568497  0.02377515  0.30668591]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01855608 -0.1958958   0.02990887  0.31357698]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.022474   -0.19608084  0.03618041  0.32187247]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02639562 -0.19618218  0.04261786  0.33133767]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.984660\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -1.56960774e-04  -1.95347397e-01   1.39901163e-05   2.97680734e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00406391 -0.1953462   0.0059676   0.29768299]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00797083 -0.19542226  0.01192126  0.29951803]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01187928 -0.19556454  0.01791163  0.30313724]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01579057 -0.19575243  0.02397437  0.30845481]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01970562 -0.19595449  0.03014347  0.31534234]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02362471 -0.19612658  0.03645031  0.32362064]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02754724 -0.19620958  0.04292273  0.33304958]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.974813\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00082665 -0.19555331  0.00034409  0.30231893]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00473772 -0.19555481  0.00639047  0.30241913]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00864882 -0.19562878  0.01243885  0.30434283]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01256139 -0.19576302  0.01852571  0.30803679]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01647665 -0.19593517  0.02468645  0.31340777]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02039536 -0.19611131  0.0309546   0.32031683]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02431758 -0.19624419  0.03736094  0.32857113]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02824247 -0.1962709   0.04393236  0.33791379]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.965065\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -4.13982192e-04  -1.95145121e-01  -2.21565968e-05   2.93193039e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00431688 -0.19514467  0.0058417   0.29318586]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00821978 -0.19522534  0.01170542  0.29501658]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01212428 -0.19537672  0.01760575  0.29863911]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01603182 -0.19557937  0.02357854  0.30397273]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01994341 -0.19580361  0.02965799  0.31089663]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02385948 -0.1960076   0.03587592  0.31924186]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02777963 -0.19613503  0.04226076  0.328781  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.955414\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00099223 -0.19536186 -0.00077318  0.29800464]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00291501 -0.19535011  0.00518691  0.29776349]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00682201 -0.19541622  0.01114218  0.29935868]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01073034 -0.19555035  0.01712936  0.30274616]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01464134 -0.19573316  0.02318428  0.30784509]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01855601 -0.19593467  0.02934118  0.31453278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aprob: nan\n",
      "action 0\n",
      "[-0.0224747  -0.19611244  0.03563184  0.3226369 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02639695 -0.19620936  0.04208457  0.33192548]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.945860\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -3.61553433e-04  -1.94864110e-01   1.79327952e-04   2.87055225e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00425884 -0.19486826  0.00592043  0.28711509]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0081562  -0.19495793  0.01166273  0.28901515]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01205536 -0.19512318  0.01744304  0.29271137]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01595782 -0.19534575  0.02329726  0.29812818]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01986474 -0.19559779  0.02925983  0.30515307]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02377669 -0.19583997  0.03536289  0.31362845]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02769349 -0.19601917  0.04163546  0.32334131]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03161388 -0.19606587  0.04810229  0.33401149]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.946401\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00046454 -0.19574272  0.00069778  0.30665706]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0043794  -0.19574658  0.00683092  0.30685841]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00829433 -0.19581792  0.01296809  0.3088718 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01221069 -0.19594334  0.01914552  0.31263918]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01612956 -0.19609864  0.02539831  0.31805964]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02005153 -0.19624747  0.0317595   0.32498369]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02397648 -0.19633947  0.03825917  0.33320491]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 9.926937\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00093252 -0.19464463  0.00039057  0.28232866]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00482541 -0.1946534   0.00603714  0.28246023]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00871848 -0.19475057  0.01168634  0.28443098]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01261349 -0.1949265   0.01737496  0.28819821]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01651202 -0.19516374  0.02313893  0.29368995]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02041529 -0.19543573  0.02901273  0.30079958]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02432401 -0.19570493  0.03502872  0.30937765]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02823811 -0.19592046  0.04121627  0.31922147]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03215652 -0.1960155   0.0476007   0.33006321]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.927668\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00068006 -0.19571715 -0.00093309  0.30606807]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00459441 -0.19570227  0.00518827  0.30578346]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00850845 -0.1957576   0.01130394  0.30732148]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0124236  -0.19587258  0.01745037  0.31063525]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01634106 -0.19602618  0.02366307  0.31563657]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02026158 -0.19618577  0.02997581  0.32219095]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02418529 -0.19630531  0.03641962  0.33010987]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 9.908391\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  4.64189654e-05  -1.95215013e-01  -5.85585325e-04   2.94736690e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00385788 -0.19520632  0.00530915  0.29455256]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00776201 -0.19527811  0.0112002   0.29620769]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01166757 -0.19542062  0.01712435  0.29965849]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01557598 -0.19561501  0.02311752  0.30482624]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01948828 -0.19583209  0.02921405  0.31159202]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02340492 -0.1960306   0.03544589  0.31978878]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02732554 -0.19615486  0.04184166  0.3291913 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.899307\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00039791 -0.19551907  0.00063603  0.30154275]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00351247 -0.19552452  0.00666688  0.30173245]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00742296 -0.1956028   0.01270153  0.30374531]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01133501 -0.19574135  0.01877644  0.30752668]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01524984 -0.19591747  0.02492697  0.31298212]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01916819 -0.19609696  0.03118661  0.31997158]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02309013 -0.19623222  0.03758605  0.32830106]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02701477 -0.19626     0.04415207  0.33771241]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.890314\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00092772 -0.19492262  0.00040232  0.28832467]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00482617 -0.19492977  0.00616881  0.28845526]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00872476 -0.19502127  0.01193791  0.29042448]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01262519 -0.19518671  0.0177464   0.29418646]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01652892 -0.19540716  0.02363013  0.29966292]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02043707 -0.19565389  0.02962339  0.30673772]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02435014 -0.19588647  0.03575815  0.31524851]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02826787 -0.19605038  0.04206312  0.32497637]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03218888 -0.1960745   0.04856264  0.33563413]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.891411\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -5.53636814e-05  -1.94657994e-01  -5.38076546e-04   2.82614677e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00394852 -0.19465182  0.00511422  0.28244234]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00784156 -0.19473485  0.01076306  0.28411362]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01173626 -0.19489865  0.01644534  0.28759028]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01563423 -0.19512708  0.02219714  0.2928053 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01953677 -0.19539513  0.02805325  0.29965803]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02344467 -0.19566717  0.03404641  0.30800646]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02735802 -0.19589462  0.04020654  0.31765708]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03127591 -0.19601334  0.04655968  0.32835318]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.892497\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  1.92219318e-04  -1.94541048e-01   3.58417926e-04   2.80116183e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0036986  -0.19454991  0.00596074  0.28023882]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0075896  -0.19464854  0.01156552  0.28220011]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01148257 -0.19482763  0.01720952  0.28595862]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01537912 -0.19507028  0.02292869  0.29144482]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01928053 -0.19535076  0.02875759  0.29855569]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02318754 -0.19563266  0.0347287   0.30714666]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0271002  -0.19586649  0.04087164  0.31702127]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03101753 -0.19598708  0.04721206  0.32791913]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.893572\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -8.53228144e-04  -1.95367397e-01  -1.79277196e-04   2.98127993e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00476058 -0.19536351  0.00578328  0.29807038]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00866785 -0.19543671  0.01174469  0.29984597]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01257658 -0.19557621  0.01774161  0.30340709]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0164881  -0.19576162  0.02380975  0.30866875]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02040334 -0.19596171  0.02998313  0.31550337]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02432257 -0.1961326   0.03629319  0.32373262]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02824522 -0.19621543  0.04276785  0.33311739]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.884636\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  5.72233821e-04  -1.95796477e-01   1.49370711e-04   3.07900699e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0033437  -0.19579358  0.00630738  0.30793804]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00725957 -0.19585758  0.01246615  0.30978777]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01117672 -0.19597583  0.0186619   0.31339481]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01509624 -0.19612485  0.0249298   0.31866092]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01901873 -0.19626897  0.03130302  0.32543921]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02294411 -0.19635857  0.0378118   0.33352606]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 9.865790\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -6.35841810e-04  -1.94502873e-01   1.17326900e-04   2.79303719e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0045259  -0.19450797  0.0057034   0.27934724]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00841606 -0.19460357  0.01129035  0.28123022]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01230813 -0.19478077  0.01691495  0.28491277]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01620375 -0.19502321  0.02261321  0.29032748]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02010421 -0.19530587  0.02841976  0.2973742 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02401033 -0.19559322  0.03436724  0.30591209]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02792219 -0.19583691  0.04048548  0.31574936]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03183893 -0.19597307  0.04680047  0.32663131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.867132\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  9.54163597e-04  -1.94648057e-01  -6.44394085e-05   2.82402246e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0029388  -0.19464952  0.00558361  0.2823849 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00683179 -0.19473983  0.0112313   0.28420898]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01072658 -0.19490996  0.01691548  0.28783401]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01462478 -0.19514311  0.02267216  0.29319053]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01852765 -0.19541352  0.02853597  0.30017496]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02243592 -0.19568461  0.03453947  0.30864164]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02634961 -0.19590668  0.04071231  0.31839258]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03026774 -0.19601425  0.04708016  0.32916564]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.868461\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  1.89877073e-06  -1.95490925e-01   7.61234436e-04   3.00906296e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00390792 -0.19549823  0.00677936  0.30113499]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00781788 -0.19557881  0.01280206  0.30318717]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01172946 -0.19571998  0.0188658   0.3070078 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01564386 -0.195899    0.02500596  0.31250227]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01956184 -0.19608165  0.031256    0.31953058]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02348347 -0.19622035  0.03764662  0.32789894]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02740788 -0.19625188  0.0442046   0.3373495 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.859776\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  7.21565093e-04  -1.95133869e-01  -1.35275135e-04   2.92945209e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00318111 -0.19513188  0.00572363  0.29290248]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00708375 -0.19521133  0.01158168  0.29469843]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01098798 -0.19536203  0.01747565  0.29828777]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01489522 -0.19556478  0.0234414   0.30359073]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01880651 -0.19579021  0.02951322  0.31048779]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02272232 -0.19599685  0.03572297  0.31881159]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02664225 -0.19612888  0.0420992   0.32833666]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.851178\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00047841 -0.19544846  0.00050625  0.29994805]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00343056 -0.19545293  0.00650522  0.30010004]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00733962 -0.19553193  0.01250722  0.30207869]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01125026 -0.19567336  0.01854879  0.30583109]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01516373 -0.19585514  0.02466541  0.31126554]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01908083 -0.19604398  0.03089072  0.31824582]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02300171 -0.19619341  0.03725564  0.32658284]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02692558 -0.19624153  0.0437873   0.33602444]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.842667\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.000714   -0.19577152 -0.00062059  0.30732301]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00320143 -0.19576005  0.00552587  0.30713219]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00711663 -0.19581709  0.01166852  0.30875949]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01103297 -0.19593139  0.01784371  0.31215533]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0149516  -0.19608105  0.02408682  0.31722786]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01887322 -0.19623228  0.03043137  0.32383786]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02279787 -0.19633767  0.03690813  0.33179084]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 9.824240\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00087338 -0.19561521 -0.00051524  0.30372868]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00303892 -0.19560574  0.00555933  0.30356845]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00695104 -0.19566841  0.0116307   0.30523373]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01086441 -0.19579225  0.01773538  0.30867608]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01478025 -0.19595608  0.0239089   0.3138068 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01869937 -0.19612726  0.03018504  0.32049178]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02262192 -0.19625989  0.03659487  0.32854356]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02654712 -0.19629268  0.04316574  0.33771147]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.815998\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  1.49214628e-04  -1.94972355e-01  -9.25663541e-04   2.89406790e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00375023 -0.19495942  0.00486247  0.28911235]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00764942 -0.19503149  0.01064472  0.29066249]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01155005 -0.19517989  0.01645797  0.29401796]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01545365 -0.19538757  0.02233833  0.29910747]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0193614  -0.19562789  0.02832048  0.30582293]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02327396 -0.1958629   0.03443694  0.3140117 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02719122 -0.19604105  0.04071717  0.3234666 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03111204 -0.19609465  0.0471865   0.33391449]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.817838\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  1.92403508e-04  -1.95023045e-01  -7.63625862e-04   2.90513613e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00370806 -0.1950124   0.00504665  0.29027153]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00760831 -0.19508577  0.01085208  0.29187279]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01151002 -0.19523415  0.01668953  0.29527676]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0154147  -0.19543995  0.02259507  0.30041009]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0193235  -0.19567587  0.02860327  0.3071618 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02323702 -0.19590306  0.03474651  0.31537549]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02715508 -0.19606886  0.04105402  0.32483927]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03107646 -0.19610432  0.0475508   0.33527434]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.819659\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00042105 -0.19561683 -0.00038081  0.3037654 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00433339 -0.19560898  0.0056945   0.30364573]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00824557 -0.19567308  0.01176741  0.3053508 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01215903 -0.19579794  0.01787443  0.30883127]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01607499 -0.1959621   0.02405105  0.31399745]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01999423 -0.19613263  0.030331    0.32071404]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02391688 -0.19626332  0.03674528  0.32879216]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02784215 -0.19629244  0.04332112  0.33797946]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.811463\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -6.82495206e-04  -1.94562384e-01  -2.67259799e-04   2.80571116e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00457374 -0.19456091  0.00534416  0.28048744]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00846496 -0.1946496   0.01095391  0.28224557]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01235795 -0.1948199   0.01659882  0.28580685]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01625435 -0.19505573  0.02231496  0.29110475]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02015547 -0.1953323   0.02813705  0.29803979]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02406211 -0.19561433  0.03409785  0.30647182]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0279744  -0.19585372  0.04022729  0.31620979]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03189147 -0.19598694  0.04655148  0.32699995]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.813348\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00036334 -0.19459962 -0.00058184  0.28136551]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00425533 -0.1945929   0.00504547  0.28117846]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00814719 -0.19467619  0.01066904  0.28283488]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01204071 -0.19484124  0.01632574  0.28629727]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01593753 -0.19507225  0.02205168  0.29150006]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01983898 -0.19534473  0.02788168  0.29834473]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02374587 -0.1956237   0.03384858  0.30669218]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02765835 -0.19586142  0.03998242  0.31635259]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03157558 -0.19599477  0.04630947  0.32707375]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.815215\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00091072 -0.19481563  0.00056759  0.28600619]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00480704 -0.19482604  0.00628771  0.28619207]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00870356 -0.19492224  0.01201155  0.2882163 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.012602   -0.19509388  0.01777588  0.29203336]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01650388 -0.19532234  0.02361655  0.29756643]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02041033 -0.19557943  0.02956788  0.30470185]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02432191 -0.19582545  0.03566191  0.31328079]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02823842 -0.19600685  0.04192753  0.32308874]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03215856 -0.19605362  0.0483893   0.3338438 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.817062\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.62171493e-05  -1.94587348e-01  -2.87734092e-04   2.81103844e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00386553 -0.19458545  0.00533434  0.28101342]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00775724 -0.19467342  0.01095461  0.2827651 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01165071 -0.19484267  0.01660991  0.28632007]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01554756 -0.19507703  0.02233631  0.2916114 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0194491  -0.19535158  0.02816854  0.29853897]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02335613 -0.19563081  0.03413932  0.30696171]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02726875 -0.1958664   0.04027856  0.3166874 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03118608 -0.19599446  0.0466123   0.32746088]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.818892\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  2.51940960e-04  -1.95500078e-01  -7.46263049e-04   3.01113149e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00365806 -0.19548821  0.005276    0.30088188]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00756782 -0.19555131  0.01129364  0.30248211]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01147885 -0.19567912  0.01734328  0.30586814]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01539243 -0.1958515   0.02346064  0.3109557 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01930946 -0.19603726  0.02967976  0.31761689]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02323021 -0.19619239  0.03603209  0.3256723 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02715406 -0.19625781  0.04254554  0.33488116]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.810703\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.0007034  -0.19573062  0.00046383  0.30637705]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00321122 -0.19573191  0.00659137  0.30650914]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00712586 -0.19580133  0.01272155  0.30845542]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01104188 -0.1959259   0.01889066  0.31215956]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0149604  -0.19608195  0.02513385  0.31752274]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01888204 -0.19623374  0.03148431  0.32439801]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02280671 -0.19633163  0.03797227  0.33258198]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 9.792596\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -3.04774072e-04  -1.95727925e-01   9.91379773e-04   3.06316699e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00421933 -0.19573533  0.00711771  0.30660594]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00813404 -0.19581014  0.01324983  0.30870612]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01205024 -0.19593851  0.01942395  0.31255739]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01596901 -0.19609578  0.0256751   0.31805707]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01989093 -0.1962451   0.03203624  0.32505369]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02381583 -0.19633553  0.03853732  0.33333859]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 9.774670\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -1.61918045e-04  -1.94420299e-01  -1.57042364e-05   2.77550747e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00405032 -0.19442355  0.00553531  0.27755079]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0079388  -0.19451843  0.01108633  0.2793899 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01182916 -0.19469638  0.01667412  0.28302963]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01572309 -0.19494165  0.02233472  0.28840498]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01962192 -0.19523003  0.02810282  0.29541928]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02352652 -0.19552709  0.0340112   0.30393638]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02743707 -0.19578584  0.04008993  0.31377041]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03135278 -0.19594407  0.04636534  0.32467393]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.776923\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -1.89122974e-04  -1.95691923e-01  -2.41871474e-04   3.05485593e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00410296 -0.19568529  0.00586784  0.30540755]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00801667 -0.19574867  0.01197599  0.30714986]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01193164 -0.19587041  0.01811899  0.31066138]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01584905 -0.19602836  0.02433222  0.31584952]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01976962 -0.19618866  0.03064921  0.3225749 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02369339 -0.19630386  0.0371007   0.33064339]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 9.759154\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00057761 -0.19479818  0.00095292  0.2856288 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00331836 -0.19481467  0.0066655   0.28593963]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00721465 -0.19491671  0.01238429  0.28808672]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01111298 -0.19509348  0.01814603  0.29202273]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01501485 -0.19532586  0.02398648  0.29766895]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01892137 -0.19558506  0.02993986  0.30490948]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02283307 -0.19583069  0.03603805  0.31358283]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02674969 -0.19600838  0.04230971  0.32347124]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03066985 -0.19604715  0.04877913  0.33428892]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.761562\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.0009459  -0.19520443  0.00096773  0.2945026 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00295818 -0.19521737  0.00685778  0.29480474]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00686253 -0.19530908  0.01275388  0.29693793]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01076871 -0.19546748  0.01869264  0.30084963]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01467806 -0.19567114  0.02470963  0.30645119]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01859149 -0.19588792  0.03083865  0.3136119 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02250924 -0.19607297  0.03711089  0.32215047]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0264307  -0.19616646  0.0435539   0.33182453]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.753947\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -1.24561676e-04  -1.95101944e-01   2.54748351e-04   2.92243056e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0040266  -0.19510571  0.00609961  0.29232369]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00792871 -0.19519102  0.01194608  0.29424153]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01183254 -0.19534718  0.01783091  0.29794941]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01573948 -0.19555454  0.0237899   0.30336583]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01965057 -0.19578321  0.02985722  0.31036942]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02356623 -0.19599117  0.03606461  0.31879068]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02748606 -0.19612195  0.04244042  0.32840165]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.746407\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00046147 -0.19503456 -0.00056783  0.29076547]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00343922 -0.19502675  0.00524748  0.29058577]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00733976 -0.19510257  0.01105919  0.29224839]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01124181 -0.1952527   0.01690416  0.29571149]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01514686 -0.19545918  0.02281839  0.30090028]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01905605 -0.19569424  0.0288364   0.30770195]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02296993 -0.19591848  0.03499044  0.31595778]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0268883  -0.19607856  0.04130959  0.32545304]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03080987 -0.19610472  0.04781865  0.33590557]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.748943\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -5.78687378e-05  -1.95111881e-01  -6.67010604e-05   2.92461461e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00396011 -0.19511099  0.00578253  0.29244049]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00786233 -0.19519185  0.01163134  0.29425825]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01176616 -0.19534421  0.0175165   0.29786928]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01567305 -0.19554891  0.02347389  0.30319389]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01958403 -0.19577659  0.02953777  0.31011283]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02349956 -0.19598588  0.03574002  0.31845913]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02741927 -0.19612106  0.04210921  0.32800787]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.741454\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00058413 -0.19531704  0.00097429  0.29700371]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00332221 -0.19532891  0.00691437  0.29730386]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00722879 -0.19541738  0.01286044  0.29943209]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01113714 -0.19556999  0.01884908  0.30333434]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01504854 -0.19576465  0.02491577  0.30891905]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01896383 -0.19596822  0.03109415  0.3160512 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0228832  -0.19613459  0.03741518  0.32454376]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02680589 -0.19620234  0.04390605  0.3341473 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.734039\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00047464 -0.19519204  0.0006642   0.29422858]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0034292  -0.19520089  0.00654877  0.2944361 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00733322 -0.19528915  0.01243749  0.29647676]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.011239   -0.19544523  0.01836703  0.30029998]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01514791 -0.19564832  0.02437303  0.30581941]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01906087 -0.19586695  0.03048942  0.31290721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aprob: nan\n",
      "action 0\n",
      "[-0.02297821 -0.19605717  0.03674756  0.32138563]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02689936 -0.19616015  0.04317527  0.33101656]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.726699\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00030172 -0.19437585 -0.00046464  0.27660919]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0035858  -0.19437167  0.00506755  0.27645975]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00747323 -0.19446006  0.01059674  0.27815065]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01136244 -0.19463312  0.01615976  0.28164592]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0152551  -0.19487593  0.02179267  0.2868838 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01915262 -0.19516536  0.02753035  0.29377188]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02305592 -0.19546835  0.03340579  0.30217956]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02696529 -0.19573961  0.03944938  0.31192805]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03088008 -0.19591895  0.04568794  0.32277848]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03479846 -0.19592861  0.05214351  0.33441949]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 11.000000. running mean: 9.739432\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00097114 -0.19491743  0.00084855  0.28821147]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00292721 -0.19493131  0.00661278  0.28848512]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00682584 -0.19502906  0.01238248  0.29059496]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01072642 -0.19519965  0.01819438  0.29449278]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01463041 -0.19542347  0.02408424  0.30009766]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01853888 -0.19567098  0.03008619  0.30729031]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0224523  -0.19590076  0.036232    0.31590455]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02637032 -0.19605716  0.04255009  0.32571674]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03029146 -0.19606771  0.04906442  0.33643415]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.742038\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -1.86793516e-04  -1.95616811e-01   3.55735347e-04   3.03764883e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00409913 -0.1956179   0.00643103  0.30386727]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00801149 -0.19568998  0.01250838  0.30579025]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01192529 -0.19582066  0.01862418  0.3094797 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0158417  -0.19598714  0.02481378  0.31484064]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01976144 -0.19615496  0.03111059  0.32173155]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02368454 -0.19627606  0.03754522  0.32995617]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 9.724617\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  5.13487941e-05  -1.94785088e-01   9.24539005e-05   2.85347213e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00384435 -0.19478835  0.0057994   0.2853799 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00774012 -0.19487839  0.011507    0.28725348]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01163769 -0.19504562  0.01725207  0.29092524]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0155386  -0.19527231  0.02307057  0.29632187]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01944405 -0.19553138  0.02899701  0.30333416]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02335467 -0.19578453  0.03506369  0.31180894]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02727036 -0.19597987  0.04129987  0.3215387 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03118996 -0.19604938  0.04773064  0.33224991]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.727371\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00064967 -0.19569132  0.00084489  0.30547309]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00326415 -0.19569746  0.00695435  0.30572009]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0071781  -0.19577213  0.01306876  0.30778095]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01109354 -0.19590186  0.01922437  0.31159732]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01501158 -0.19606249  0.02545632  0.31706863]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01893283 -0.19621784  0.03179769  0.32404619]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02285719 -0.19631776  0.03827862  0.3323248 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 9.710097\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00057963 -0.19545025 -0.00088034  0.29998891]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00448864 -0.19543682  0.00511944  0.29971596]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00839738 -0.19549957  0.01111376  0.30127697]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01230737 -0.19562857  0.0171393   0.30462761]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01621994 -0.1958042   0.02323185  0.30968571]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02013602 -0.19599596  0.02942557  0.31632626]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02405594 -0.1961607   0.03575209  0.32437363]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02797916 -0.19624041  0.04223956  0.33359165]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.702996\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00059858 -0.19466105  0.00097173  0.28267928]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00449181 -0.19467898  0.00662532  0.28300041]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00838538 -0.19478438  0.01228532  0.28515767]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01228107 -0.19496681  0.01798848  0.28910527]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01618041 -0.19520784  0.02377058  0.29476753]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02008457 -0.19547971  0.02966593  0.30203317]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02399416 -0.19574345  0.0357066   0.31074688]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02790903 -0.19594641  0.04192153  0.3206987 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03182796 -0.19601964  0.04833551  0.33161208]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.705966\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00063189 -0.19458786  0.00055384  0.28111432]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00452364 -0.19459961  0.00617613  0.28130043]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00841563 -0.19470032  0.01180214  0.28332457]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01230964 -0.19488029  0.01746863  0.28714385]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01620725 -0.1951221   0.0232115   0.29268662]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02010969 -0.19539933  0.02906524  0.299847  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02401768 -0.19567466  0.03506218  0.30847666]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02793117 -0.1958975   0.04123171  0.31837437]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03184912 -0.19600134  0.0475992   0.32927408]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.708907\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  4.56337078e-05  -1.95053141e-01  -5.27702864e-04   2.91172358e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00385543 -0.19504586  0.00529574  0.29100551]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00775635 -0.19512185  0.01111585  0.29268055]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01165878 -0.19527168  0.01696947  0.29615523]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01556422 -0.19547726  0.02289257  0.3013541 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01947376 -0.19571058  0.02891965  0.3081634 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02338797 -0.19593194  0.03508292  0.31642321]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02730661 -0.19608767  0.04141138  0.32591724]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03122837 -0.1961076   0.04792973  0.33636152]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.711818\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00093465 -0.19518681  0.00088445  0.294113  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00296909 -0.19519877  0.00676671  0.29438968]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00687307 -0.19528994  0.0126545   0.29649829]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01077886 -0.19544842  0.01858447  0.30038705]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01468783 -0.19565303  0.02459221  0.30596827]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01860089 -0.19587194  0.03071157  0.31311258]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02251833 -0.19606071  0.03697382  0.32164035]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02643955 -0.19615997  0.04340663  0.33131128]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.704699\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00074104 -0.19561257  0.00039794  0.30366813]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00465329 -0.1956142   0.0064713   0.30378333]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00856558 -0.19568688  0.01254697  0.30571906]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01247932 -0.19581813  0.01866135  0.309421  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01639568 -0.19598512  0.02484977  0.31479394]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02031538 -0.19615332  0.03114565  0.32169621]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02423845 -0.19627464  0.03757957  0.3299313 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 9.687652\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.0009975  -0.19547973  0.00068138  0.30065327]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00291209 -0.19548614  0.00669445  0.30085795]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00682182 -0.19556617  0.01271161  0.30288706]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01073314 -0.19570733  0.01876935  0.30668619]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01464729 -0.19588706  0.02490307  0.31216159]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01856503 -0.19607142  0.03114631  0.31917439]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02248645 -0.19621315  0.03752979  0.32753216]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02641072 -0.19624942  0.04408044  0.33697869]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.680776\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  3.37684177e-04  -1.95224447e-01  -2.41707258e-04   2.94945502e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0035668  -0.19522049  0.0056572   0.294869  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00747121 -0.19529646  0.01155458  0.29662988]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01137714 -0.19544206  0.01748718  0.30018241]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01528598 -0.19563779  0.02349083  0.30544545]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01919874 -0.19585376  0.02959974  0.31229707]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02311582 -0.19604776  0.03584568  0.32056655]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02703677 -0.19616307  0.04225701  0.33002418]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.673968\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00050917 -0.19474469 -0.00051286  0.28447642]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00338573 -0.19473866  0.00517667  0.28431277]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0072805  -0.19482062  0.01086292  0.28599287]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01117691 -0.19498191  0.01658278  0.28947751]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01507655 -0.19520592  0.02237233  0.29469775]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01898067 -0.19546699  0.02826629  0.30154999]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02289001 -0.19572854  0.03429729  0.30988819]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02680458 -0.19594084  0.04049505  0.31951369]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0307234  -0.19603836  0.04688532  0.33016359]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.677229\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -1.50766903e-04  -1.95785705e-01   8.05453093e-04   3.07652370e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00406648 -0.1957903   0.0069585   0.30788415]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00798229 -0.19586112  0.01311618  0.30992483]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01189951 -0.19598444  0.01931468  0.31371501]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0158192  -0.19613559  0.02558898  0.31915179]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01974191 -0.19627758  0.03197202  0.32608297]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02366746 -0.19635926  0.03849368  0.3342987 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 9.660456\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  1.23381196e-04  -1.94785924e-01   7.43896981e-04   2.85364643e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00377234 -0.19479928  0.00645119  0.28560822]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00766832 -0.19489864  0.01216335  0.28768926]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0115663  -0.1950735   0.01791714  0.29156168]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01546777 -0.19530513  0.02374837  0.29714828]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01937387 -0.19556523  0.02969134  0.30433512]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02328517 -0.19581401  0.03577804  0.31296318]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02720145 -0.19599784  0.0420373   0.32281775]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03112141 -0.1960466   0.04849366  0.33361663]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.663852\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00054276 -0.19530082  0.00089223  0.2966423 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00444878 -0.19531177  0.00682508  0.29691759]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00835501 -0.19539974  0.01276343  0.29902193]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01226301 -0.19555247  0.01874387  0.30290199]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01617406 -0.1957481   0.02480191  0.30846716]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02008902 -0.1959538   0.03097125  0.3155837 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0240081  -0.19612386  0.03728293  0.32406623]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02793057 -0.19619729  0.04376425  0.33366729]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.657213\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -7.42598029e-04  -1.94963873e-01  -7.49032950e-06   2.89222408e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00464188 -0.19496465  0.00577696  0.28922135]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00854117 -0.1950496   0.01156138  0.29106069]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01244216 -0.19520878  0.0173826   0.2946963 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01634634 -0.19542371  0.02327652  0.3000515 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02025481 -0.1956661   0.02927755  0.30701173]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02416813 -0.19589602  0.03541779  0.31541647]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02808605 -0.19605953  0.04172612  0.32504893]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03200724 -0.19608619  0.0482271   0.33562447]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.660641\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00044862 -0.19439717 -0.00087133  0.27705903]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00343933 -0.19438605  0.00466985  0.27677413]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00732705 -0.19446762  0.01020533  0.27833155]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0112164  -0.19463444  0.01577196  0.28169694]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01510909 -0.19487207  0.0214059   0.28681023]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01900653 -0.1951579   0.0271421   0.29358097]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02290969 -0.19545952  0.03301372  0.30188099]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02681888 -0.1957324   0.03905134  0.31153445]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03073353 -0.1959173   0.04528203  0.32230621]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03465187 -0.19593754  0.05172816  0.33388932]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 11.000000. running mean: 9.674035\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -4.86902145e-04  -1.95048312e-01  -2.47614453e-04   2.91066650e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00438787 -0.19504513  0.00557372  0.2909887 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00828877 -0.195125    0.01139349  0.29275136]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01219127 -0.1952781   0.01724852  0.29631088]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01609683 -0.1954859   0.02317474  0.30159019]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02000655 -0.1957199   0.02920654  0.30847359]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02392095 -0.19593982  0.03537601  0.31679881]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02783975 -0.19609128  0.04171199  0.32634675]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03176157 -0.19610329  0.04823892  0.33683006]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.677294\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -7.87477007e-04  -1.95211724e-01  -3.26286035e-05   2.94663785e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00469171 -0.19521074  0.00586065  0.29465277]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00859593 -0.19528967  0.0117537   0.29647834]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01250172 -0.19543795  0.01768327  0.30009371]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01641048 -0.19563579  0.02368514  0.30541664]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02032319 -0.19585298  0.02979348  0.31232406]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02424025 -0.19604698  0.03603996  0.32064387]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02816119 -0.19616064  0.04245283  0.33014476]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.670521\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00052788 -0.19558477  0.00080247  0.30303512]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00338382 -0.1955916   0.00686317  0.30327319]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00729565 -0.19566953  0.01292864  0.30533055]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01120904 -0.19580554  0.01903525  0.30915062]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01512515 -0.1959762   0.02521826  0.31463601]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01904468 -0.19614639  0.03151098  0.32164269]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0229676  -0.19626733  0.03794383  0.32997153]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 9.653816\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -1.79522615e-04  -1.94400249e-01  -6.40684521e-04   2.77125102e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00406753 -0.19439303  0.00490182  0.2769171 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00795539 -0.19447826  0.01044016  0.27855056]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01184495 -0.19464822  0.01601117  0.28199007]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01573792 -0.19488811  0.02165097  0.2871743 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01963568 -0.19517495  0.02739446  0.29401124]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02353918 -0.19547579  0.03327468  0.30237072]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02744869 -0.1957455   0.0393221   0.3120744 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0313636  -0.19592407  0.04556359  0.32288405]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03528209 -0.19593396  0.05202127  0.33448905]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 11.000000. running mean: 9.667278\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -2.64421049e-04  -1.95174222e-01   1.97626071e-05   2.93834839e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00416791 -0.19517419  0.00589646  0.29384058]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00807139 -0.19525471  0.01177327  0.29568343]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01197648 -0.19540521  0.01768694  0.29931674]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01588459 -0.19560606  0.02367327  0.3046588 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01979671 -0.19582722  0.02976645  0.31158749]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02371325 -0.19602645  0.0359982   0.31993202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aprob: nan\n",
      "action 0\n",
      "[-0.02763378 -0.19614695  0.04239684  0.32946276]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.660605\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.000686   -0.19531344 -0.00062185  0.2969231 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00322027 -0.19530388  0.00531661  0.29672836]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00712635 -0.19537298  0.01125118  0.29837064]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01103381 -0.19551079  0.01721859  0.30180549]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01494402 -0.19569796  0.0232547   0.30695217]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01885798 -0.19590462  0.02939374  0.31368856]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02277607 -0.1960885   0.03566752  0.32184323]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02669784 -0.19619272  0.04210438  0.33118542]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.653999\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00045236 -0.19506732  0.00064758  0.29148314]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00344899 -0.19507699  0.00647724  0.29168869]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00735053 -0.19516832  0.01231102  0.2937298 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01125389 -0.19533011  0.01818561  0.29755754]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01516049 -0.19554228  0.02413676  0.3030887 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01907134 -0.19577444  0.03019854  0.31020012]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02298683 -0.19598403  0.03640254  0.3187203 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02690651 -0.19611395  0.04277694  0.32841892]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.647459\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00081908 -0.19572645  0.00087255  0.30628206]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00473361 -0.1957325   0.00699819  0.30653598]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00864826 -0.19580618  0.01312891  0.30860171]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01256438 -0.19593384  0.01930094  0.31242023]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01648306 -0.19609106  0.02554935  0.31788978]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02040488 -0.19624126  0.03190714  0.32486   ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0243297  -0.19633382  0.03840434  0.33312353]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 9.630985\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00078844 -0.19576443  0.0007693   0.30715934]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00312685 -0.19576886  0.00691249  0.30738118]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00704223 -0.19584012  0.01306011  0.30941338]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01095903 -0.19596461  0.01924838  0.3131971 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01487832 -0.19611786  0.02551232  0.31863029]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01880068 -0.19626317  0.03188493  0.32556196]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02272594 -0.19634972  0.03839617  0.33378376]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 9.614675\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -2.81378032e-07  -1.95216089e-01  -7.05354160e-04   2.94760553e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0039046  -0.19520572  0.00518986  0.29453892]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00780872 -0.19527594  0.01108064  0.2961571 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01171424 -0.19541718  0.01700378  0.29957216]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01562258 -0.19561076  0.02299522  0.30470614]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0195348  -0.19582775  0.02908934  0.311441  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02345135 -0.19602712  0.03531816  0.31961077]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02737189 -0.19615354  0.04171038  0.3289915 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.608528\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00083656 -0.19492797 -0.00039896  0.28844094]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00473512 -0.19492306  0.00536985  0.2883147 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00863358 -0.19500331  0.01113615  0.29003109]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01253365 -0.19515945  0.01693677  0.29354845]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01643684 -0.19537378  0.02280774  0.29879327]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02034431 -0.19561905  0.02878361  0.30565511]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0242567  -0.19585657  0.03489671  0.31397865]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02817383 -0.19603394  0.04117628  0.3235535 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03209451 -0.19608251  0.04764735  0.3341027 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.612443\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00077068 -0.19506996  0.00090136  0.29154086]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00313072 -0.19508326  0.00673217  0.29182664]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00703239 -0.19517783  0.01256871  0.29394647]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01093594 -0.19534212  0.01844764  0.29784993]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01484278 -0.19555558  0.02440464  0.30345212]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0187539  -0.19578731  0.03047368  0.31062785]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02266964 -0.19599414  0.03668623  0.31920309]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02658953 -0.19611821  0.0430703   0.32894444]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.606318\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00084103 -0.19543466  0.00090857  0.29963811]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00474972 -0.19544444  0.00690133  0.29991375]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00865861 -0.19552848  0.01289961  0.30201406]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01256918 -0.19567406  0.01893989  0.30588383]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01648266 -0.19585851  0.02505757  0.31142889]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02039983 -0.1960478   0.03128614  0.31851021]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02432079 -0.19619463  0.03765635  0.32693541]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02824468 -0.19623615  0.04419506  0.33644847]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.600255\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  6.01857422e-04  -1.95598722e-01   2.78117854e-04   3.03352078e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00331012 -0.19559902  0.00634516  0.30343142]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0072221  -0.19567085  0.01241379  0.30533265]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01113551 -0.19580197  0.01852044  0.30900238]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01505155 -0.19596986  0.02470049  0.31434666]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01897095 -0.19614037  0.03098742  0.32122534]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02289376 -0.19626585  0.03741193  0.32944389]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02681908 -0.19628297  0.04400081  0.33874332]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.594253\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  2.65163398e-04  -1.94555042e-01   9.66470841e-04   2.80412962e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00362594 -0.19457373  0.00657473  0.28073553]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00751741 -0.1946813   0.01218944  0.28289366]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01141104 -0.19486761  0.01784731  0.28684285]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01530839 -0.19511478  0.02358417  0.29250985]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01921069 -0.1953959   0.02943437  0.29978698]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0231186  -0.19567308  0.03543011  0.30852383]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02703207 -0.19589505  0.04160058  0.31851657]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03094997 -0.19599449  0.04797092  0.329496  ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.598310\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  1.31870334e-04  -1.95136659e-01  -7.13157938e-04   2.93006688e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00377086 -0.19512643  0.00514698  0.29278181]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00767339 -0.19519822  0.01100261  0.29439836]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01157736 -0.19534269  0.01689058  0.29781427]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01548421 -0.19554157  0.02284686  0.3029534 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01939504 -0.19576658  0.02890593  0.30970053]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02331037 -0.19597758  0.03509994  0.31789351]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02722992 -0.19612027  0.04145781  0.32731322]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.592327\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00053215 -0.1950269   0.00082375  0.2905978 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00443269 -0.19503946  0.00663571  0.29086031]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00833348 -0.19513414  0.01245292  0.29295797]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01223616 -0.19529961  0.01831208  0.29684132]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01614216 -0.19551571  0.0242489   0.30242702]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02005247 -0.19575204  0.03029744  0.30959202]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02396751 -0.19596608  0.03648928  0.31816513]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02788683 -0.19610076  0.04285259  0.32791643]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.586404\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00046922 -0.19462714 -0.00053401  0.28195406]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00342332 -0.19462112  0.00510507  0.28178287]\n",
      "aprob: nan\n",
      "action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00731575 -0.19470471  0.01074073  0.28345514]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01120984 -0.19486953  0.01640983  0.28693286]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01510723 -0.19509959  0.02214849  0.29214965]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01900922 -0.1953701   0.02799148  0.2990058 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02291662 -0.19564572  0.0339716   0.3073606 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02682954 -0.19587825  0.04011881  0.31702221]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0307471  -0.19600399  0.04645925  0.32773597]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.590540\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  2.41661695e-04  -1.94711204e-01  -6.09530079e-04   2.83756271e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00365256 -0.19470374  0.0050656   0.28356094]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00754664 -0.19478484  0.01073681  0.28520973]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01144233 -0.19494602  0.01644101  0.28866424]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01534125 -0.19517101  0.02221429  0.29385676]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01924467 -0.19543454  0.02809143  0.30068545]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02315337 -0.19570059  0.03410514  0.30900657]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02706738 -0.19592011  0.04028527  0.3186244 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03098578 -0.19602838  0.04665776  0.32927954]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.594634\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -1.61068500e-04  -1.95796966e-01  -2.92106024e-04   3.07912217e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00407701 -0.19578908  0.00586614  0.30781888]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00799279 -0.19584867  0.01202252  0.30954044]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01190976 -0.19596384  0.01821332  0.3130248 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01582904 -0.19611191  0.02447382  0.31817703]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01975128 -0.19625819  0.03083736  0.32485407]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02367644 -0.19635413  0.03733444  0.33285676]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 9.578688\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00095487 -0.19437302  0.00033095  0.2765497 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00484233 -0.19438235  0.00586195  0.27666564]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00872998 -0.19448346  0.01139526  0.2786183 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01261965 -0.19466752  0.01696763  0.28236815]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.016513   -0.19491848  0.02261499  0.28784932]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02041137 -0.19521189  0.02837197  0.29496434]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0243156  -0.19551303  0.03427126  0.30357621]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02822586 -0.19577462  0.04034279  0.31349806]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03214136 -0.19593404  0.04661275  0.32448115]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.582901\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  2.38915979e-04  -1.95114216e-01  -6.63965494e-04   2.92512788e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00366337 -0.19510476  0.00518629  0.29230322]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00756546 -0.19517767  0.01103235  0.29393524]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01146902 -0.19532357  0.01691106  0.29736674]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01537549 -0.19552426  0.02285839  0.30252176]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01928597 -0.19575152  0.02890883  0.30928548]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.023201   -0.19596532  0.03509454  0.31749636]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02712031 -0.19611156  0.04144447  0.32693604]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03104254 -0.19611955  0.04798319  0.33731807]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.587072\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  1.09797135e-04  -1.94733726e-01   3.73469131e-04   2.84240759e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00378488 -0.19474167  0.00605828  0.2843653 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00767971 -0.19483682  0.01174559  0.28632932]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01157645 -0.19500931  0.01747218  0.29008925]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01547663 -0.19524127  0.02327396  0.29557125]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01938146 -0.19550547  0.02918539  0.30266584]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02329157 -0.19576353  0.0352387   0.31121969]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02720684 -0.19596346  0.0414631   0.32102519]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03112611 -0.19603713  0.0478836   0.33180864]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.591201\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00085985 -0.19534665  0.00036042  0.29766412]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00304708 -0.19535007  0.0063137   0.2977735 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00695408 -0.19543033  0.01226917  0.29971377]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01086269 -0.19557584  0.01826345  0.3034342 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0147742  -0.1957654   0.02433213  0.30884667]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01868951 -0.19596688  0.03050907  0.31582001]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02260885 -0.19613532  0.03682547  0.32417172]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02653155 -0.19621063  0.0433089   0.33365768]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.585289\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  5.72721445e-05  -1.95520675e-01   2.81388623e-04   3.01578597e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00385314 -0.19552167  0.00631296  0.3016604 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00776357 -0.19559594  0.01234617  0.30356742]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01167549 -0.1957315   0.01841752  0.30724724]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01559012 -0.19590628  0.02456246  0.31260789]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01950825 -0.1960868   0.03081462  0.31951225]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02342998 -0.19622632  0.03720486  0.32776975]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02735451 -0.19626258  0.04376026  0.33712633]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.579436\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00051619 -0.19563068  0.00075763  0.30408274]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0044288  -0.19563647  0.00683929  0.30430573]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00834153 -0.19571237  0.0129254   0.30634616]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01225578 -0.19584525  0.01905232  0.31014712]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01617268 -0.19601151  0.02525527  0.31561031]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02009291 -0.19617569  0.03156747  0.32259025]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02401642 -0.1962886   0.03801928  0.33088586]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 9.563642\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00055586 -0.19577404 -0.00099639  0.30738285]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00335962 -0.19575825  0.00515127  0.30708043]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00727478 -0.19581134  0.01129288  0.30859787]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01119101 -0.1959227   0.01746483  0.31188808]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01510946 -0.19607108  0.0237026   0.31686192]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01903088 -0.19622349  0.03003983  0.32338327]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02295535 -0.1963334   0.0365075   0.3312613 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 8.000000. running mean: 9.548006\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ 0.00036579 -0.19453875  0.00082753  0.28006614]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00352499 -0.19455529  0.00642885  0.2803434 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0074161  -0.1946611   0.01203572  0.28245687]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01130932 -0.19484624  0.01768486  0.28636287]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01520624 -0.19509314  0.02341211  0.29198931]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0191081  -0.19537526  0.0292519   0.29923003]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02301561 -0.19565517  0.0352365   0.30793653]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02692871 -0.19588219  0.04139523  0.31790743]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03084636 -0.19598968  0.04775338  0.32887643]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.552525\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[  6.75234352e-04  -1.94416483e-01   2.74888464e-04   2.77469718e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0032131  -0.19442463  0.00582428  0.27756642]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00710159 -0.19452415  0.01137561  0.27950076]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01099207 -0.19470613  0.01696563  0.28323301]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01488619 -0.19495441  0.02263029  0.28869671]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01878528 -0.19524432  0.02840422  0.29579337]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02269017 -0.19554084  0.03432009  0.3043846 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02660098 -0.1957963   0.04040778  0.31428172]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03051691 -0.1959476   0.04669341  0.32523382]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.557000\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -1.25733932e-04  -1.95374187e-01  -5.54676093e-04   2.98280234e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00403322 -0.19536529  0.00541093  0.29810671]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00794052 -0.19543378  0.01137306  0.2997681 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0118492  -0.19556942  0.01736842  0.3032189 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aprob: nan\n",
      "action 0\n",
      "[-0.01576059 -0.19575245  0.0234328   0.30837651]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01967564 -0.19595234  0.02960033  0.31511609]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02359468 -0.19612601  0.03590265  0.3232626 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.0275172  -0.19621556  0.04236791  0.33258082]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.551430\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -7.92754282e-04  -1.94981021e-01  -2.03561023e-05   2.89596168e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00469237 -0.19498152  0.00577157  0.28959087]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00859201 -0.19506592  0.01156338  0.29142586]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01249332 -0.19522426  0.0173919   0.29505689]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01639781 -0.19543799  0.02329304  0.30040697]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02030657 -0.19567872  0.02930118  0.30736106]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02422014 -0.19590636  0.0354484   0.31575794]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02813827 -0.19606678  0.04176356  0.32537995]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.03205961 -0.19608931  0.04827116  0.33594145]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 10.000000. running mean: 9.555916\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[ -2.15754579e-04  -1.94959583e-01   8.81850991e-04   2.89128516e-01]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00411495 -0.19497359  0.00666442  0.28941156]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00801442 -0.19507075  0.01245265  0.2915302 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01191583 -0.19523986  0.01828326  0.29543552]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01582063 -0.19546103  0.02419197  0.30104542]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01972985 -0.1957043   0.03021288  0.30823884]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02364394 -0.19592773  0.03637765  0.31684727]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02756249 -0.19607501  0.0427146   0.32664419]\n",
      "aprob: nan\n",
      "action 0\n",
      "resetting env. episode reward total was 9.000000. running mean: 9.550357\n",
      "[ 0.  0.  0.  0.]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00082731 -0.1951384  -0.00049255  0.29304498]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00473008 -0.1951313   0.00536835  0.29288966]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.00863271 -0.19520597  0.01122615  0.2945747 ]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01253683 -0.19535271  0.01711764  0.29805678]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.01644388 -0.19555292  0.02307878  0.30325831]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02035494 -0.19577784  0.02914394  0.31006234]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02427049 -0.19598682  0.03534519  0.31830461]\n",
      "aprob: nan\n",
      "action 0\n",
      "[-0.02819023 -0.19612494  0.04171128  0.32776342]\n",
      "aprob: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1f6beb36385f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;31m# forward the policy network and sample an action from the returned probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0maprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"aprob:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0maprob\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# roll the dice!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"action\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0;31m# newlines imply flush in subprocesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mevent_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevent_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send (zmq/backend/cython/socket.c:7305)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send (zmq/backend/cython/socket.c:7048)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy (zmq/backend/cython/socket.c:2920)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc (zmq/backend/cython/socket.c:9621)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "observation = env.reset()\n",
    "\n",
    "xs,hs,dlogps,drs = [],[],[],[]\n",
    "running_reward = None\n",
    "reward_sum = 0\n",
    "episode_number = 0\n",
    "\n",
    "while True:\n",
    "  if render: env.render()\n",
    "\n",
    "  x = observation   # No need to preprop\n",
    "  print(x)\n",
    "\n",
    "  # forward the policy network and sample an action from the returned probability\n",
    "  aprob, h = policy_forward(x)\n",
    "  print(\"aprob:\",aprob)\n",
    "  action = 1 if np.random.uniform() < aprob else 0 # roll the dice!\n",
    "  print(\"action\",action)\n",
    "\n",
    "  # record various intermediates (needed later for backprop)\n",
    "  xs.append(x) # observation\n",
    "  hs.append(h) # hidden state\n",
    "  y = 1 if action == 1 else 0 # a \"fake label\"\n",
    "  dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n",
    "\n",
    "  # step the environment and get new measurements\n",
    "  observation, reward, done, info = env.step(action)\n",
    "  reward_sum += reward\n",
    "\n",
    "  drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n",
    "\n",
    "  if done: # an episode finished\n",
    "    episode_number += 1\n",
    "\n",
    "    # stack together all inputs, hidden states, action gradients, and rewards for this episode\n",
    "    epx = np.vstack(xs)\n",
    "    eph = np.vstack(hs)\n",
    "    epdlogp = np.vstack(dlogps)\n",
    "    epr = np.vstack(drs)\n",
    "    xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n",
    "\n",
    "    # compute the discounted reward backwards through time\n",
    "    discounted_epr = discount_rewards(epr)\n",
    "    # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n",
    "    discounted_epr -= np.mean(discounted_epr)\n",
    "    discounted_epr /= np.std(discounted_epr)\n",
    "\n",
    "    epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n",
    "    grad = policy_backward(eph, epdlogp)\n",
    "    for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n",
    "\n",
    "    # perform rmsprop parameter update every batch_size episodes\n",
    "    if episode_number % batch_size == 0:\n",
    "      for k,v in model.items():   # Update to python3.5 format\n",
    "        g = grad_buffer[k] # gradient\n",
    "        rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n",
    "        model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n",
    "        grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n",
    "\n",
    "    # boring book-keeping\n",
    "    running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "    print ('resetting env. episode reward total was %f. running mean: %f' % (reward_sum, running_reward))  # Update to python3.5 format\n",
    "    if episode_number % 100 == 0: pickle.dump(model, open('save.p', 'wb'))\n",
    "    reward_sum = 0\n",
    "    observation = env.reset() # reset env\n",
    "    prev_x = None\n",
    "  \n",
    "#  if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n",
    "#    print ('ep %d: game finished, reward: %f' % (episode_number, reward)) \n",
    "#    print ('' if reward == -1 else ' !!!!!!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring CartPole & Pong Environments\n",
    "\n",
    "** CartPole Environment **\n",
    "A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track.The system is controlled by applying a force of +1 or -1 to the cart. The pendulum starts upright, and the goal is to prevent it from falling over. A reward of +1 is provided for every timestep that the pole remains upright. The episode ends when the pole is more than 15 degrees from vertical, or the cart moves more than 2.4 units from the center.\n",
    "\n",
    "Good general-purpose agents don't need to know the semantics of the observations: they can learn how to map observations to actions to maximize reward without any prior knowledge.\n",
    "\n",
    "Cartpole-v0 observation's 4 parameters:\n",
    "[position of cart, velocity of cart, angle of pole, rotation rate of pole]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-01 11:27:20,265] Making new env: CartPole-v0\n",
      "[2017-09-01 11:27:20,269] Making new env: Pong-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(2)\n",
      "Discrete(2)\n",
      "Box(4,)\n",
      "[  4.80000000e+00   3.40282347e+38   4.18879020e-01   3.40282347e+38]\n",
      "[ -4.80000000e+00  -3.40282347e+38  -4.18879020e-01  -3.40282347e+38]\n",
      "Discrete(6)\n",
      "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n",
      "Box(210, 160, 3)\n",
      "[[[ 255.  255.  255.]\n",
      "  [ 255.  255.  255.]\n",
      "  [ 255.  255.  255.]\n",
      "  ..., \n",
      "  [ 255.  255.  255.]\n",
      "  [ 255.  255.  255.]\n",
      "  [ 255.  255.  255.]]\n",
      "\n",
      " [[ 255.  255.  255.]\n",
      "  [ 255.  255.  255.]\n",
      "  [ 255.  255.  255.]\n",
      "  ..., \n",
      "  [ 255.  255.  255.]\n",
      "  [ 255.  255.  255.]\n",
      "  [ 255.  255.  255.]]\n",
      "\n",
      " [[ 255.  255.  255.]\n",
      "  [ 255.  255.  255.]\n",
      "  [ 255.  255.  255.]\n",
      "  ..., \n",
      "  [ 255.  255.  255.]\n",
      "  [ 255.  255.  255.]\n",
      "  [ 255.  255.  255.]]\n",
      "\n",
      " ..., \n",
      " [[ 255.  255.  255.]\n",
      "  [ 255.  255.  255.]\n",
      "  [ 255.  255.  255.]\n",
      "  ..., \n",
      "  [ 255.  255.  255.]\n",
      "  [ 255.  255.  255.]\n",
      "  [ 255.  255.  255.]]\n",
      "\n",
      " [[ 255.  255.  255.]\n",
      "  [ 255.  255.  255.]\n",
      "  [ 255.  255.  255.]\n",
      "  ..., \n",
      "  [ 255.  255.  255.]\n",
      "  [ 255.  255.  255.]\n",
      "  [ 255.  255.  255.]]\n",
      "\n",
      " [[ 255.  255.  255.]\n",
      "  [ 255.  255.  255.]\n",
      "  [ 255.  255.  255.]\n",
      "  ..., \n",
      "  [ 255.  255.  255.]\n",
      "  [ 255.  255.  255.]\n",
      "  [ 255.  255.  255.]]]\n",
      "[[[ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " ..., \n",
      " [[ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "print(env.action_space)\n",
    "print(env.action_space)\n",
    "print(env.observation_space)\n",
    "print(env.observation_space.high)\n",
    "print(env.observation_space.low)\n",
    "\n",
    "env = gym.make(\"Pong-v0\")\n",
    "print(env.action_space)\n",
    "print(env.unwrapped.get_action_meanings())\n",
    "print(env.observation_space)\n",
    "print(env.observation_space.high)\n",
    "print(env.observation_space.low)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-01 15:14:43,581] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num steps before the pole tips: 10.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import time\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "done = False\n",
    "ob = env.reset()\n",
    "reward_sum = 0  \n",
    "while True:\n",
    "    # action = 1   # 1 - RIGHT\n",
    "    action = 0   # 0 - LEFT\n",
    "    env.render()\n",
    "    time.sleep(1)\n",
    "    ob, reward, done, _ = env.step(action)\n",
    "    reward_sum += reward\n",
    "    if done:\n",
    "        print(\"Num steps before the pole tips:\",reward_sum)\n",
    "        break\n",
    "        # Note there's no env.render() here. But the environment still can open window and\n",
    "        # render if asked by env.monitor: it calls env.render('rgb_array') to record video.\n",
    "        # Video is not recorded every episode, see capped_cubic_video_schedule for details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-01 12:35:00,547] Making new env: Pong-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: -21.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import time\n",
    "\n",
    "env = gym.make(\"Pong-v0\")\n",
    "\n",
    "done = False\n",
    "ob = env.reset()\n",
    "reward_sum = 0  \n",
    "while True:\n",
    "#    action = 2   # 2 - RIGHT (UP)\n",
    "    action = 3   # 3 - LEFT (DOWN)\n",
    "\n",
    "    env.render()\n",
    "    time.sleep(0.01)\n",
    "    ob, reward, done, _ = env.step(action)\n",
    "    reward_sum += reward\n",
    "    if done:\n",
    "        print(\"Total reward:\",reward_sum)\n",
    "        break\n",
    "        # Note there's no env.render() here. But the environment still can open window and\n",
    "        # render if asked by env.monitor: it calls env.render('rgb_array') to record video.\n",
    "        # Video is not recorded every episode, see capped_cubic_video_schedule for details.\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
